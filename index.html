<!doctypehtml><html lang=zh-CN><meta charset=UTF-8><meta content=width=device-width name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.0.0" name=generator><link href=/images/apple-touch-icon-next.png rel=apple-touch-icon sizes=180x180><link href=/images/favicon-32x32-next.png rel=icon sizes=32x32 type=image/png><link href=/images/favicon-16x16-next.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><style>:root{--body-bg-color:#eee;--content-bg-color:#fff;--card-bg-color:#f5f5f5;--text-color:#555;--blockquote-color:#666;--link-color:#555;--link-hover-color:#222;--brand-color:#fff;--brand-hover-color:#fff;--table-row-odd-bg-color:#f9f9f9;--table-row-hover-bg-color:#f5f5f5;--menu-item-bg-color:#f5f5f5;--theme-color:#222;--btn-default-bg:#fff;--btn-default-color:#555;--btn-default-border-color:#555;--btn-default-hover-bg:#222;--btn-default-hover-color:#fff;--btn-default-hover-border-color:#222;--highlight-background:#f3f3f3;--highlight-foreground:#444;--highlight-gutter-background:#e1e1e1;--highlight-gutter-foreground:#555;color-scheme:light}html{line-height:1.15;-webkit-text-size-adjust:100%}details,main{display:block}pre{font-size:1em;overflow:auto;padding:10px}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}.table-container,textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}summary{display:list-item}[hidden],template{display:none}::selection{background:#262a30;color:#eee}body,html{height:100%}body{margin:0;background:var(--body-bg-color);box-sizing:border-box;color:var(--text-color);font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1em;line-height:2;min-height:100%;position:relative;transition:padding .2s ease-in-out}h1,h2,h3,h4,h5,h6{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-weight:700;line-height:1.5;margin:30px 0 15px}h1{font-size:1.5em}h2{font-size:1.375em}h3{font-size:1.25em}h4{font-size:1.125em}h5{font-size:1em}h6{font-size:.875em}p{margin:0 0 20px}a{background:0 0;border-bottom:1px solid #999;color:var(--link-color);cursor:pointer;outline:0;text-decoration:none;overflow-wrap:break-word}a:hover{border-bottom-color:var(--link-hover-color);color:var(--link-hover-color)}embed,iframe,img,video{display:block;margin-left:auto;margin-right:auto;max-width:100%}hr{box-sizing:content-box;overflow:visible;background-image:repeating-linear-gradient(-45deg,#ddd,#ddd 4px,transparent 4px,transparent 8px);border:0;height:3px;margin:40px 0}blockquote{border-left:4px solid #ddd;color:var(--blockquote-color);margin:0;padding:0 15px}blockquote cite::before{content:'-';padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}table{border-collapse:collapse;border-spacing:0;font-size:.875em;margin:0 0 20px;width:100%}tbody tr:nth-of-type(odd){background:var(--table-row-odd-bg-color)}tbody tr:hover{background:var(--table-row-hover-bg-color)}caption,td,th{padding:8px}td,th{border:1px solid #ddd;border-bottom:3px solid #ddd}th{font-weight:700;padding-bottom:10px}td{border-bottom-width:1px}.btn{background:var(--btn-default-bg);border:2px solid var(--btn-default-border-color);border-radius:2px;color:var(--btn-default-color);display:inline-block;font-size:.875em;line-height:2;padding:0 20px;transition:background-color .2s ease-in-out}.btn:hover{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{text-align:left;width:1.285714285714286em}.toggle{line-height:0}.toggle .toggle-line{background:#fff;display:block;height:2px;left:0;position:relative;top:0;transition:.4s;width:100%}.toggle .toggle-line:first-child{margin-top:1px}.toggle .toggle-line:not(:first-child){margin-top:4px}.toggle.toggle-arrow :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}.toggle.toggle-arrow :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}.toggle.toggle-close :nth-child(2){opacity:0}.toggle.toggle-close :first-child{top:6px;transform:rotate(45deg)}.toggle.toggle-close :last-child{top:-6px;transform:rotate(-45deg)}/*!
  Theme: Default
  Description: Original highlight.js style
  Author: (c) Ivan Sagalaev <maniac@softwaremaniacs.org>
  Maintainer: @highlightjs/core-team
  Website: https://highlightjs.org/
  License: see project LICENSE
  Touched: 2021
*/pre code.hljs{display:block;overflow-x:auto;padding:1em}code.hljs{padding:3px 5px}.hljs{background:#f3f3f3;color:#444}.hljs-comment{color:#697070}.hljs-punctuation,.hljs-tag{color:#444a}.hljs-tag .hljs-attr,.hljs-tag .hljs-name{color:#444}.hljs-attribute,.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-name,.hljs-selector-tag{font-weight:700}.hljs-deletion,.hljs-number,.hljs-quote,.hljs-selector-class,.hljs-selector-id,.hljs-string,.hljs-template-tag,.hljs-type{color:#800}.hljs-section,.hljs-title{color:#800;font-weight:700}.hljs-link,.hljs-operator,.hljs-regexp,.hljs-selector-attr,.hljs-selector-pseudo,.hljs-symbol,.hljs-template-variable,.hljs-variable{color:#ab5656}.hljs-literal{color:#695}.hljs-addition,.hljs-built_in,.hljs-bullet,.hljs-code{color:#397300}.hljs-meta{color:#1f7199}.hljs-meta .hljs-string{color:#38a}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}code,figure.highlight,kbd,pre{background:var(--highlight-background);color:var(--highlight-foreground)}figure.highlight,pre{line-height:1.6;margin:0 auto 20px}figure.highlight figcaption,pre .caption,pre figcaption{background:var(--highlight-gutter-background);color:var(--highlight-foreground);display:flow-root;font-size:.875em;line-height:1.2;padding:.5em}figure.highlight figcaption a,pre .caption a,pre figcaption a{color:var(--highlight-foreground);float:right}figure.highlight figcaption a:hover,pre .caption a:hover,pre figcaption a:hover{border-bottom-color:var(--highlight-foreground)}code,pre{font-family:consolas,Menlo,monospace,'PingFang SC','Microsoft YaHei'}code{border-radius:3px;font-size:.875em;padding:2px 4px;overflow-wrap:break-word}kbd{border:2px solid #ccc;border-radius:.2em;box-shadow:.1em .1em .2em rgba(0,0,0,.1);font-family:inherit;padding:.1em .3em;white-space:nowrap}figure.highlight{overflow:auto;position:relative}figure.highlight pre{border:0;margin:0;padding:10px 0}figure.highlight table{border:0;margin:0;width:auto}figure.highlight td{border:0;padding:0}figure.highlight .gutter{-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none}figure.highlight .gutter pre{background:var(--highlight-gutter-background);color:var(--highlight-gutter-foreground);padding-left:10px;padding-right:10px;text-align:right}figure.highlight .code pre{padding-left:10px;width:100%}figure.highlight .marked{background:rgba(0,0,0,.3)}pre .caption,pre figcaption{margin-bottom:10px}.gist table{width:auto}.gist table td{border:0}pre code{background:0 0;padding:0;text-shadow:none}.blockquote-center{border-left:0;margin:40px 0;padding:0;position:relative;text-align:center}.blockquote-center::after,.blockquote-center::before{left:0;line-height:1;opacity:.6;position:absolute;width:100%}.blockquote-center::before{border-top:1px solid #ccc;text-align:left;top:-20px;content:'\f10d';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center::after{border-bottom:1px solid #ccc;bottom:-20px;text-align:right;content:'\f10e';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center div,.blockquote-center p{text-align:center}.group-picture{margin-bottom:20px}.group-picture .group-picture-row{display:flex;gap:3px;margin-bottom:3px}.group-picture .group-picture-column{flex:1}.group-picture .group-picture-column img{height:100%;margin:0;object-fit:cover;width:100%}.post-body .label{color:#555;padding:0 2px}.post-body .label.default{background:#f0f0f0}.post-body .label.primary{background:#efe6f7}.post-body .label.info{background:#e5f2f8}.post-body .label.success{background:#e7f4e9}.post-body .label.warning{background:#fcf6e1}.post-body .label.danger{background:#fae8eb}.post-body .link-grid{display:grid;grid-gap:1.5rem;gap:1.5rem;grid-template-columns:1fr 1fr;margin-bottom:20px;padding:1rem}.post-body .link-grid .link-grid-container{border:solid #ddd;box-shadow:1rem 1rem .5rem rgba(0,0,0,.5);min-height:5rem;min-width:0;padding:.5rem;position:relative;transition:background .3s}.post-body .link-grid .link-grid-container:hover{animation:.5s next-shake;background:var(--card-bg-color)}.post-body .link-grid .link-grid-container:active{box-shadow:.5rem .5rem .25rem rgba(0,0,0,.5);transform:translate(.2rem,.2rem)}.post-body .link-grid .link-grid-container .link-grid-image{border:1px solid #ddd;border-radius:50%;box-sizing:border-box;height:5rem;padding:3px;position:absolute;width:5rem}.post-body .link-grid .link-grid-container p{margin:0 1rem 0 6rem}.post-body .link-grid .link-grid-container p:first-of-type{font-size:1.2em}.post-body .link-grid .link-grid-container p:last-of-type{font-size:.8em;line-height:1.3rem;opacity:.7}.post-body .link-grid .link-grid-container a{border:0;height:100%;left:0;position:absolute;top:0;width:100%}@keyframes next-shake{0%{transform:translate(1pt,1pt) rotate(0)}10%{transform:translate(-1pt,-2pt) rotate(-1deg)}20%{transform:translate(-3pt,0) rotate(1deg)}30%{transform:translate(3pt,2pt) rotate(0)}40%{transform:translate(1pt,-1pt) rotate(1deg)}50%{transform:translate(-1pt,2pt) rotate(-1deg)}60%{transform:translate(-3pt,1pt) rotate(0)}70%{transform:translate(3pt,1pt) rotate(-1deg)}80%{transform:translate(-1pt,-1pt) rotate(1deg)}90%{transform:translate(1pt,2pt) rotate(0)}100%{transform:translate(1pt,-2pt) rotate(-1deg)}}.post-body .note{border-radius:3px;margin-bottom:20px;padding:1em;position:relative;border:1px solid #eee;border-left-width:5px}.post-body .note summary{cursor:pointer;outline:0}.post-body .note summary p{display:inline}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{border-bottom:initial;margin:0;padding-top:0}.post-body .note :first-child{margin-top:0}.post-body .note :last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .tabs{margin-bottom:20px}.post-body .tabs,.tabs-comment{padding-top:10px}.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{background:var(--content-bg-color);display:flex;display:flex;flex-wrap:wrap;justify-content:center;margin:0;padding:0;position:-webkit-sticky;position:sticky;top:0;z-index:5}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid #ddd;border-left:1px solid transparent;border-right:1px solid transparent;border-radius:0;border-top:3px solid transparent;flex-grow:1;list-style-type:none}@media (max-width:413px){.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{display:block;margin-bottom:5px}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid transparent;border-left:3px solid transparent;border-right:1px solid transparent;border-top:1px solid transparent;border-radius:0}}.post-body .tabs ul.nav-tabs li.tab a,.tabs-comment ul.nav-tabs li.tab a{border-bottom:initial;display:block;line-height:1.8;padding:.25em .75em;text-align:center;transition:.2s ease-out}.post-body .tabs ul.nav-tabs li.tab a i[class^=fa],.tabs-comment ul.nav-tabs li.tab a i[class^=fa]{width:1.285714285714286em}.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#fc6423 #ddd transparent}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#ddd #ddd #ddd #fc6423}}.post-body .tabs ul.nav-tabs li.tab.active a,.tabs-comment ul.nav-tabs li.tab.active a{cursor:default}.post-body .tabs .tab-content,.tabs-comment .tab-content{border:1px solid #ddd;border-radius:0;border-top-color:transparent}@media (max-width:413px){.post-body .tabs .tab-content,.tabs-comment .tab-content{border-radius:0;border-top-color:#ddd}}.post-body .tabs .tab-content .tab-pane,.tabs-comment .tab-content .tab-pane{padding:20px 20px 0}.post-body .tabs .tab-content .tab-pane:not(.active),.tabs-comment .tab-content .tab-pane:not(.active){display:none}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{display:inline-block;margin:-1px 10px 0;padding:0 10px}.pagination .page-number.current{background:#ccc;border-color:#ccc;color:var(--content-bg-color)}.pagination{border-top:1px solid #eee;margin:120px 0 0;text-align:center}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:0;border-top:1px solid #eee;transition:border-color .2s ease-in-out}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:var(--link-hover-color)}@media (max-width:767px){.post-body .link-grid{grid-template-columns:1fr}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}.pagination{border-top:0}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:1px solid #eee;border-top:0}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:var(--link-hover-color)}.site-meta{text-align:center}}.pagination .space{margin:0;padding:0}.comments{margin-top:60px;overflow:hidden}.comment-button-group{display:flex;display:flex;flex-wrap:wrap;justify-content:center;justify-content:center;margin:1em 0}.comment-button-group .comment-button{margin:.1em .2em}.comment-button-group .comment-button.active{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.comment-position{display:none}.comment-position.active{display:block}.tabs-comment{margin-top:4em;padding-top:0}.tabs-comment .comments{margin-top:0;padding-top:0}.headband{background:var(--theme-color);height:3px}@media (max-width:991px){.headband{display:none}}.site-brand-container{display:flex;flex-shrink:0;padding:0 10px}.use-motion .column,.use-motion .site-brand-container .toggle{opacity:0}.site-meta{flex-grow:1;text-align:center}.custom-logo-image{margin-top:20px}@media (max-width:991px){.custom-logo-image{display:none}}.brand{border-bottom:0;color:var(--brand-color);display:inline-block;padding:0}.brand:hover{color:var(--brand-hover-color)}.site-title{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1.375em;font-weight:400;line-height:1.5;margin:0}.site-subtitle{color:#ddd;font-size:.8125em;margin:10px 10px 0}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-right,.site-nav-toggle{display:none}.site-nav-right .toggle,.site-nav-toggle .toggle{color:var(--text-color);padding:10px;width:22px}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:var(--text-color);border-radius:1px}@media (max-width:767px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu{margin:0;padding:1em 0;text-align:center}.menu-item{display:inline-block;list-style:none;margin:0 10px}@media (max-width:767px){.menu-item{display:block;margin-top:10px}.menu-item.menu-item-search{display:none}}.menu-item a{border-bottom:0;display:block;font-size:.8125em;transition:border-color .2s ease-in-out}.menu-item a.menu-item-active,.menu-item a:hover{background:var(--menu-item-bg-color)}.menu-item i[class^=fa]{margin-right:8px}.menu-item .badge{display:inline-block;font-weight:700;line-height:1;margin-left:.35em;margin-top:.35em;text-align:center;white-space:nowrap}.use-motion .menu-item{visibility:hidden}.sidebar-inner{color:#999;padding:18px 10px;text-align:center;display:flex;flex-direction:column;justify-content:center}.cc-license .cc-opacity{border-bottom:0;opacity:.7}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}.site-author-image{border:1px solid #eee;max-width:120px;padding:2px}.site-author-name{color:var(--text-color);font-weight:600;margin:0}.site-description{color:#999;font-size:.8125em;margin-top:0}.links-of-author a{font-size:.8125em}.links-of-author i[class^=fa]{margin-right:2px}.sidebar .sidebar-button:not(:first-child){margin-top:15px}.sidebar .sidebar-button button{background:0 0;cursor:pointer;line-height:2;padding:0 15px;border-radius:4px}.sidebar .sidebar-button button i[class^=fa]{margin-right:5px}.links-of-blogroll{font-size:.8125em}.links-of-blogroll-title{font-size:.875em;font-weight:600}.links-of-blogroll-list{list-style:none;margin:0;padding:0}.sidebar-nav{font-size:.875em;height:0;margin:0;overflow:hidden;padding-left:0;pointer-events:none;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}.sidebar-nav-active .sidebar-nav{height:calc(2em + 1px);pointer-events:unset;visibility:unset}.sidebar-nav li{border-bottom:1px solid transparent;color:var(--text-color);cursor:pointer;display:inline-block;transition:border-bottom-color .2s ease-in-out,color .2s ease-in-out}.sidebar-nav li.sidebar-nav-overview{margin-left:10px}.sidebar-nav li:hover{color:#fc6423}.sidebar-overview-active .sidebar-nav-overview,.sidebar-toc-active .sidebar-nav-toc{border-bottom-color:#fc6423;color:#fc6423;transition-delay:0.2s}.sidebar-overview-active .sidebar-nav-overview:hover,.sidebar-toc-active .sidebar-nav-toc:hover{color:#fc6423}.sidebar-panel-container{align-items:start;display:grid;flex:1;overflow-x:hidden;overflow-y:auto;padding-top:0;transition:padding-top .2s ease-in-out}.sidebar-nav-active .sidebar-panel-container{padding-top:20px}.sidebar-panel{animation:.2s ease-in-out deactivate-sidebar-panel;grid-area:1/1;height:0;opacity:0;overflow:hidden;pointer-events:none;transform:translateY(0);transition:.2s ease-in-out;transition-property:opacity,transform,visibility;visibility:hidden}.sidebar-nav-active .sidebar-panel,.sidebar-overview-active .sidebar-panel.post-toc-wrap{transform:translateY(-20px)}.sidebar-overview-active:not(.sidebar-nav-active) .sidebar-panel.post-toc-wrap{transition-delay:0s,0.2s,0s}.sidebar-overview-active .sidebar-panel.site-overview-wrap,.sidebar-toc-active .sidebar-panel.post-toc-wrap{animation-name:activate-sidebar-panel;height:auto;opacity:1;pointer-events:unset;transform:translateY(0);transition-delay:0.2s,0.2s,0s;visibility:unset}.sidebar-panel.site-overview-wrap{display:flex;flex-direction:column;justify-content:center;gap:10px;justify-content:flex-start}@keyframes deactivate-sidebar-panel{from{height:var(--inactive-panel-height,0)}to{height:var(--active-panel-height,0)}}@keyframes activate-sidebar-panel{from{height:var(--inactive-panel-height,auto)}to{height:var(--active-panel-height,auto)}}.sidebar-toggle{bottom:61px;height:16px;padding:5px;width:16px;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;right:30px}.sidebar-toggle:hover{opacity:.8}@media (max-width:991px){.sidebar-toggle{right:20px;opacity:.8}}.sidebar-toggle:hover .toggle-line{background:#fc6423}@media (any-hover:hover){body:not(.sidebar-active) .sidebar-toggle:hover :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}body:not(.sidebar-active) .sidebar-toggle:hover :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}}.sidebar-active .sidebar-toggle :nth-child(2){opacity:0}.sidebar-active .sidebar-toggle :first-child{top:6px;transform:rotate(45deg)}.sidebar-active .sidebar-toggle :last-child{top:-6px;transform:rotate(-45deg)}.post-toc{font-size:.875em}.post-toc ol{list-style:none;margin:0;padding:0 2px 0 10px;text-align:left}.post-toc ol>:last-child{margin-bottom:5px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition:.2s ease-in-out}.post-toc .nav-item{line-height:1.8;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.post-toc .nav .nav-child{--height:0;height:0;opacity:0;overflow:hidden;transition:.2s ease-in-out;visibility:hidden}.post-toc .nav .active>.nav-child{height:var(--height,auto);opacity:1;visibility:unset}.post-toc .nav .active>a{border-bottom-color:#fc6423;color:#fc6423}.post-toc .nav .active-current>a,.post-toc .nav .active-current>a:hover{color:#fc6423}.site-state{display:flex;flex-wrap:wrap;justify-content:center;line-height:1.4}.site-state-item a{border-bottom:0;display:block}.site-state-item-count{display:block;font-size:1em;font-weight:600}.site-state-item-name{color:#999;font-size:.8125em}.footer{color:#999;font-size:.875em;padding:20px 0;transition:left .2s ease-in-out,right .2s ease-in-out}.footer.footer-fixed{bottom:0;left:0;position:absolute;right:0}.footer-inner{box-sizing:border-box;text-align:center;display:flex;flex-direction:column;justify-content:center;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.menu-item .badge{float:right;margin-left:0}.footer-inner{width:auto}}@media (min-width:1200px){.footer-inner{width:1160px}}@media (min-width:1600px){.footer-inner{width:73%}}.use-motion .footer{opacity:0}.languages{display:inline-block;font-size:1.125em;position:relative}.languages .lang-select-label span{margin:0 .5em}.languages .lang-select{height:100%;left:0;opacity:0;position:absolute;top:0;width:100%}.with-love{color:red;display:inline-block;margin:0 5px}@keyframes icon-animate{0%,100%{transform:scale(1)}10%,30%{transform:scale(.9)}20%,40%,50%,60%,70%,80%{transform:scale(1.1)}}.back-to-top{font-size:12px;align-items:center;bottom:-100px;color:#fff;display:flex;height:26px;transition:bottom .2s ease-in-out;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;right:30px}.back-to-top span{margin-right:8px;display:none}.back-to-top .fa{text-align:center;width:26px}.back-to-top:hover{opacity:.8;color:#fc6423}.back-to-top.back-to-top-on{bottom:30px}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.post-button{margin-top:40px;text-align:center}.use-motion .collection-header,.use-motion .comments,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{visibility:hidden}.posts-collapse .post-content{margin-bottom:35px;margin-left:35px;position:relative}@media (max-width:767px){.posts-collapse .post-content{margin-left:0;margin-right:0}}.posts-collapse .post-content .collection-title{font-size:1.125em;position:relative}.posts-collapse .post-content .collection-title::before{background:#999;border:1px solid #fff;margin-left:-6px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:10px;width:10px}.posts-collapse .post-content .collection-year{font-size:1.5em;font-weight:700;margin:60px 0;position:relative}.posts-collapse .post-content .collection-year::before{background:#bbb;margin-left:-4px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:8px;width:8px}.posts-collapse .post-content .collection-header{display:block;margin-left:20px}.posts-collapse .post-content .collection-header small{color:#bbb;margin-left:5px}.posts-collapse .post-content .post-header{border-bottom:1px dashed #ccc;margin:30px 2px 0;padding-left:15px;position:relative;transition:border .2s ease-in-out}.posts-collapse .post-content .post-header::before{background:#bbb;border:1px solid #fff;left:-6px;position:absolute;top:.75em;transition:background .2s ease-in-out;border-radius:50%;content:' ';height:6px;width:6px}.posts-collapse .post-content .post-header:hover{border-bottom-color:#666}.posts-collapse .post-content .post-header:hover::before{background:#222}.posts-collapse .post-content .post-meta-container{display:inline;font-size:.75em;margin-right:10px}.posts-collapse .post-content .post-title{display:inline}.posts-collapse .post-content .post-title a{border-bottom:0;color:var(--link-color)}.posts-collapse .post-content::before{background:#f5f5f5;content:' ';height:100%;margin-left:-2px;position:absolute;top:1.25em;width:4px}.post-body{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;overflow-wrap:break-word}@media (min-width:1200px){.post-body{font-size:1.125em}}@media (min-width:992px){.post-body{text-align:justify}}.post-body h1 .header-anchor,.post-body h1 .headerlink,.post-body h2 .header-anchor,.post-body h2 .headerlink,.post-body h3 .header-anchor,.post-body h3 .headerlink,.post-body h4 .header-anchor,.post-body h4 .headerlink,.post-body h5 .header-anchor,.post-body h5 .headerlink,.post-body h6 .header-anchor,.post-body h6 .headerlink{border-bottom-style:none;color:inherit;float:right;font-size:.875em;margin-left:10px;opacity:0}.post-body h1 .header-anchor::before,.post-body h1 .headerlink::before,.post-body h2 .header-anchor::before,.post-body h2 .headerlink::before,.post-body h3 .header-anchor::before,.post-body h3 .headerlink::before,.post-body h4 .header-anchor::before,.post-body h4 .headerlink::before,.post-body h5 .header-anchor::before,.post-body h5 .headerlink::before,.post-body h6 .header-anchor::before,.post-body h6 .headerlink::before{content:'\f0c1';font-family:'Font Awesome 6 Free';font-weight:900}.post-body h1:hover .header-anchor,.post-body h1:hover .headerlink,.post-body h2:hover .header-anchor,.post-body h2:hover .headerlink,.post-body h3:hover .header-anchor,.post-body h3:hover .headerlink,.post-body h4:hover .header-anchor,.post-body h4:hover .headerlink,.post-body h5:hover .header-anchor,.post-body h5:hover .headerlink,.post-body h6:hover .header-anchor,.post-body h6:hover .headerlink{opacity:.5}.post-body h1:hover .header-anchor:hover,.post-body h1:hover .headerlink:hover,.post-body h2:hover .header-anchor:hover,.post-body h2:hover .headerlink:hover,.post-body h3:hover .header-anchor:hover,.post-body h3:hover .headerlink:hover,.post-body h4:hover .header-anchor:hover,.post-body h4:hover .headerlink:hover,.post-body h5:hover .header-anchor:hover,.post-body h5:hover .headerlink:hover,.post-body h6:hover .header-anchor:hover,.post-body h6:hover .headerlink:hover{opacity:1}.post-body .exturl .fa{font-size:.875em;margin-left:4px}.post-body .fancybox+figcaption,.post-body img+figcaption{color:#999;font-size:.875em;font-weight:700;line-height:1;margin:-15px auto 15px;text-align:center}.post-body embed,.post-body iframe,.post-body img,.post-body video{margin-bottom:20px}.post-body .video-container{height:0;margin-bottom:20px;overflow:hidden;padding-top:75%;position:relative;width:100%}.post-body .video-container embed,.post-body .video-container iframe,.post-body .video-container object{height:100%;left:0;margin:0;position:absolute;top:0;width:100%}.post-gallery{display:flex;min-height:200px}.post-gallery .post-gallery-image{flex:1}.post-gallery .post-gallery-image:not(:first-child){clip-path:polygon(40px 0,100% 0,100% 100%,0 100%);margin-left:-20px}.post-gallery .post-gallery-image:not(:last-child){margin-right:-20px}.post-gallery .post-gallery-image img{height:100%;object-fit:cover;opacity:1;width:100%}.posts-expand .post-gallery{margin-bottom:60px}.posts-collapse .post-gallery{margin:15px 0}.posts-expand .post-header{font-size:1.125em;margin-bottom:60px;text-align:center}.posts-expand .post-title{font-size:1.5em;font-weight:400;margin:initial;overflow-wrap:break-word}.posts-expand .post-title-link{border-bottom:0;color:var(--link-color);display:inline-block;position:relative}.posts-expand .post-title-link::before{background:var(--link-color);bottom:0;content:'';height:2px;left:0;position:absolute;transform:scaleX(0);transition:transform .2s ease-in-out;width:100%}.posts-expand .post-title-link:hover::before{transform:scaleX(1)}.posts-expand .post-title-link .fa{font-size:.875em;margin-left:5px}.post-sticky-flag{display:inline-block;margin-right:8px;transform:rotate(30deg)}.posts-expand .post-meta-container{color:#999;font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:.75em;margin-top:3px}.posts-expand .post-meta-container .post-description{font-size:.875em;margin-top:2px}.posts-expand .post-meta-container time{border-bottom:1px dashed #999}.post-meta{display:flex;flex-wrap:wrap;justify-content:center}:not(.post-meta-break)+.post-meta-item::before{content:'|';margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (max-width:991px){.back-to-top{right:20px;opacity:.8}.post-body{text-align:justify}.post-meta-item-text{display:none}}.post-meta-break{flex-basis:100%;height:0}.post-nav{border-top:1px solid #eee;display:flex;gap:30px;justify-content:space-between;margin-top:1em;padding:10px 5px 0}.post-nav-item{flex:1}.post-nav-item a{border-bottom:0;display:block;font-size:.875em;line-height:1.6}.post-nav-item a:active{top:2px}.post-nav-item .fa{font-size:.75em}.post-nav-item:first-child .fa{margin-right:5px}.post-nav-item:last-child{text-align:right}.post-nav-item:last-child .fa{margin-left:5px}.post-footer{display:flex;flex-direction:column;justify-content:center}.post-eof{background:#ccc;height:1px;margin:80px auto 60px;width:8%}.post-block:last-of-type .post-eof{display:none}.post-tags{margin-top:40px;text-align:center}.post-tags a{display:inline-block;font-size:.8125em}.post-tags a:not(:last-child){margin-right:10px}.social-like{border-top:1px solid #eee;font-size:.875em;margin-top:1em;padding-top:1em;display:flex;flex-wrap:wrap;justify-content:center}.social-like a{border-bottom:none}.reward-container{margin:1em 0 0;padding:1em 0;text-align:center}.reward-container button{background:0 0;color:#fc6423;cursor:pointer;line-height:2;padding:0 15px;border:2px solid #fc6423;border-radius:2px;outline:0;transition:.2s ease-in-out;vertical-align:text-top}.reward-container button:hover{background:#fc6423;color:#fff}.post-reward{display:none;padding-top:20px}.post-reward.active{display:block}.post-reward div{display:inline-block}.post-reward div span{display:block}.post-reward img{display:inline-block;margin:.8em 2em 0;max-width:100%;width:180px}@keyframes next-roll{from{transform:rotateZ(30deg)}to{transform:rotateZ(-30deg)}}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{list-style:none;margin:0;padding:0}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{color:#bbb}.category-all-page .category-list-count::before{content:' ('}.category-all-page .category-list-count::after{content:') '}.category-all-page .category-list-child{padding-left:10px}.event-list hr{background:#222;margin:20px 0 45px}.event-list hr::after{background:#222;color:#fff;content:'NOW';display:inline-block;font-weight:700;padding:0 5px}.event-list .event{--event-background:#222;--event-foreground:#bbb;--event-title:#fff;background:var(--event-background);padding:15px}.event-list .event .event-summary{border-bottom:0;color:var(--event-title);margin:0;padding:0 0 0 35px;position:relative}.event-list .event .event-summary::before{animation:1s ease-in-out infinite alternate dot-flash;background:var(--event-title);left:0;margin-top:-6px;position:absolute;top:50%;border-radius:50%;content:' ';height:12px;width:12px}.event-list .event:nth-of-type(odd) .event-summary::before{animation-delay:.5s}.event-list .event:not(:last-child){margin-bottom:20px}.event-list .event .event-relative-time{color:var(--event-foreground);display:inline-block;font-size:12px;font-weight:400;padding-left:12px}.event-list .event .event-details{color:var(--event-foreground);display:block;line-height:18px;padding:6px 0 6px 35px}.event-list .event .event-details::before{color:var(--event-foreground);display:inline-block;margin-right:9px;width:14px;font-family:'Font Awesome 6 Free';font-weight:900}.event-list .event .event-details.event-location::before{content:'\f041'}.event-list .event .event-details.event-duration::before{content:'\f017'}.event-list .event .event-details.event-description::before{content:'\f024'}.event-list .event-past{--event-background:#f5f5f5;--event-foreground:#999;--event-title:#222}@keyframes dot-flash{from{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}ul.breadcrumb{font-size:.75em;list-style:none;margin:1em 0;padding:0 2em;text-align:center}ul.breadcrumb li{display:inline}ul.breadcrumb li:not(:first-child)::before{content:'/\00a0';font-weight:400;padding:.5em}ul.breadcrumb li:last-child{font-weight:700}.tag-cloud{text-align:center}.tag-cloud a{display:inline-block;margin:10px}.tag-cloud-0{border-bottom-color:#aaa;color:#aaa}.tag-cloud-1{border-bottom-color:#9a9a9a;color:#9a9a9a}.tag-cloud-2{border-bottom-color:#8b8b8b;color:#8b8b8b}.tag-cloud-3{border-bottom-color:#7c7c7c;color:#7c7c7c}.tag-cloud-4{border-bottom-color:#6c6c6c;color:#6c6c6c}.tag-cloud-5{border-bottom-color:#5d5d5d;color:#5d5d5d}.tag-cloud-6{border-bottom-color:#4e4e4e;color:#4e4e4e}.tag-cloud-7{border-bottom-color:#3e3e3e;color:#3e3e3e}.tag-cloud-8{border-bottom-color:#2f2f2f;color:#2f2f2f}.tag-cloud-9{border-bottom-color:#202020;color:#202020}.tag-cloud-10{border-bottom-color:#111;color:#111}.search-active{overflow:hidden}.search-pop-overlay{background:rgba(0,0,0,0);display:flex;height:100%;left:0;position:fixed;top:0;transition:visibility .4s,background .4s;visibility:hidden;width:100%;z-index:40}.search-active .search-pop-overlay{background:rgba(0,0,0,.3);visibility:visible}.search-popup{background:var(--card-bg-color);border-radius:5px;height:80%;margin:auto;transform:scale(0);transition:transform .4s;width:700px}.search-active .search-popup{transform:scale(1)}@media (max-width:767px){.search-popup{border-radius:0;height:100%;width:100%}}.search-popup .popup-btn-close,.search-popup .search-icon{color:#999;font-size:18px;padding:0 10px}.search-popup .popup-btn-close{cursor:pointer}.search-popup .popup-btn-close:hover .fa{color:#222}.search-popup .search-header{background:#eee;border-top-left-radius:5px;border-top-right-radius:5px;display:flex;padding:5px}.search-popup input.search-input{background:0 0;border:0;outline:0;width:100%}.search-popup input.search-input::-webkit-search-cancel-button{display:none}.search-popup .search-result-container{height:calc(100% - 55px);overflow:auto;padding:5px 25px}.search-popup .search-result-container hr{margin:5px 0 10px}.search-popup .search-result-container hr:first-child{display:none}.search-popup .search-result-list{margin:0 5px;padding:0;width:100%}.search-popup a.search-result-title{font-weight:700}.search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.search-popup .search-input-container{flex-grow:1;padding:2px}.search-popup .no-result{display:flex}.search-popup .search-result-icon{color:#ccc;margin:auto}mark.search-keyword{background:0 0;border-bottom:1px dashed #ff2a2a;color:#ff2a2a;font-weight:700}.has-jax,mjx-container[jax=CHTML][display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}.use-motion .animated{animation-fill-mode:none;visibility:inherit}.use-motion .sidebar .animated{animation-fill-mode:both}header.header{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12)}.main{align-items:stretch;display:flex;justify-content:space-between;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.main{width:auto}}@media (min-width:1200px){.main{width:1160px}}@media (min-width:1600px){.main{width:73%}}@media (max-width:991px){header.header{border-radius:initial}.main{display:block;width:auto}}.main-inner{border-radius:initial;box-sizing:border-box;width:calc(100% - 252px)}.footer-inner{padding-left:252px}@media (max-width:991px){.main-inner{border-radius:initial;width:100%}.footer-inner{padding-left:0;padding-right:0;width:auto}}.column{width:240px}.site-brand-container{background:var(--theme-color)}.site-meta{padding:20px 0}.site-nav-right .toggle,.site-nav-toggle .toggle{color:#fff}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:#fff}@media (min-width:768px) and (max-width:991px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu .menu-item{display:block;margin:0}.menu .menu-item a{padding:5px 20px;position:relative;text-align:left;transition-property:background-color}.menu .menu-item .badge{background:#ccc;border-radius:10px;color:var(--content-bg-color);float:right;padding:2px 5px;text-shadow:1px 1px 0 rgba(0,0,0,.1)}.main-menu .menu-item-active::after{background:#bbb;border-radius:50%;content:' ';height:6px;margin-top:-3px;position:absolute;right:15px;top:50%;width:6px}.sub-menu{margin:0;padding:6px 0}.sub-menu .menu-item{display:inline-block}.sub-menu .menu-item a{background:0 0;margin:5px 10px;padding:initial}.sub-menu .menu-item a:hover{background:0 0;color:#fc6423}.sub-menu .menu-item-active{border-bottom-color:#fc6423;color:#fc6423}.sub-menu .menu-item-active:hover{border-bottom-color:#fc6423}.sidebar{position:-webkit-sticky;position:sticky;top:12px}@media (max-width:991px){.column{width:auto}.site-nav-on .site-brand-container{box-shadow:0 0 16px rgba(0,0,0,.5)}.menu .menu-item.menu-item-search,.sidebar{display:none}}.sidebar-inner{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);box-sizing:border-box;color:var(--text-color);margin-top:12px;max-height:calc(100vh - 24px);visibility:hidden}.site-state-item{padding:0 10px}.sidebar .sidebar-button{border-bottom:1px dotted #ccc;border-top:1px dotted #ccc}.sidebar .sidebar-button button{border:0;color:#fc6423;display:block;width:100%}.sidebar .sidebar-button button:hover{background:0 0;border:0;color:#e34603}.links-of-author{display:flex;flex-wrap:wrap;justify-content:center}.links-of-author-item{margin:5px 0 0;width:50%}.links-of-author-item a{box-sizing:border-box;max-width:100%;overflow:hidden;padding:0 5px;text-overflow:ellipsis;white-space:nowrap;border-bottom:0;border-radius:4px;display:block}.links-of-author-item a:hover{background:var(--body-bg-color)}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .post-block,.main-inner .sub-menu,.main-inner .tabs-comment,.main-inner>.comments{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12)}.main-inner .post-block:not(:first-child):not(:first-child){border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);margin-top:12px}@media (min-width:768px) and (max-width:991px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:10px}}@media (max-width:767px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:8px}}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);margin-top:12px}@media (min-width:768px) and (max-width:991px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:10px}}@media (max-width:767px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:8px}}.comments,.post-block{padding:40px}.post-eof{display:none}.pagination{border-top:initial;padding:10px 0}.post-body h1,.post-body h2{border-bottom:1px solid #eee}.post-body h3{border-bottom:1px dotted #eee}@media (min-width:768px) and (max-width:991px){.main-inner{padding:10px}.posts-expand .post-button{margin-top:20px}.post-block{padding:20px}.comments{padding:10px 20px}}@media (max-width:767px){.main-inner{padding:8px}.posts-expand .post-button{margin:12px 0}.post-block{padding:12px}.comments{padding:10px 12px}}</style><link crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity=sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU= rel=stylesheet><link crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css integrity=sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE= rel=stylesheet><script class=next-config data-name=main type=application/json>{"hostname":"zjyfdu.coding.me","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}}</script><script src=/js/config.js></script><meta content=website property=og:type><meta content=努力～奋斗～ property=og:title><meta content=https://zjyfdu.coding.me/index.html property=og:url><meta content=努力～奋斗～ property=og:site_name><meta content=zh_CN property=og:locale><meta content=翟大翟 property=article:author><meta content=summary name=twitter:card><link href=https://zjyfdu.coding.me/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script><script class=next-config data-name=calendar type=application/json>""</script><title>努力～奋斗～</title><noscript><link href=/css/noscript.css rel=stylesheet></noscript><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <h1 class=site-title>努力～奋斗～</h1> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="archive fa-fw"></i>归档</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-overview-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=翟大翟 class=site-author-image itemprop=image src=/images/11989810.jpg><p class=site-author-name itemprop=name>翟大翟<div class=site-description itemprop=description></div></div><div class="site-state-wrap animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>71</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>17</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>57</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author animated"><span class=links-of-author-item> <a rel="noopener me" title="Github → https://github.com/zjyfdu" href=https://github.com/zjyfdu target=_blank><i class="github fa-fw"></i>Github</a> </span></div></div></div></div></aside></div><div class="main-inner index posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/26/VL%E6%A8%A1%E5%9E%8BAPI%E7%9A%84token%E6%80%8E%E4%B9%88%E7%AE%97/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/26/VL%E6%A8%A1%E5%9E%8BAPI%E7%9A%84token%E6%80%8E%E4%B9%88%E7%AE%97/ itemprop=url>VL模型API的token怎么算</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-26 15:09:20 / 修改时间：07:33:23" datetime=2025-10-26T15:09:20+00:00>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>梳理从 GPT-4.1 到 GPT-5，再到 Qwen3-VL 的核心 API 知识点，帮助你真正驾驭这些强大的工具。<h3 id=1-API-的第一课：Token，以及那个神秘的-reasoning-tokens><a title="1. API 的第一课：Token，以及那个神秘的 reasoning_tokens" class=headerlink href=#1-API-的第一课：Token，以及那个神秘的-reasoning-tokens></a>1. API 的第一课：Token，以及那个神秘的 <code>reasoning_tokens</code></h3><p>你的每一次 API 调用都会返回一个 <code>usage</code> 对象，理解它就是理解你账单的第一步：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    "id": "chatcmpl-xxx",</span><br><span class=line>    "object": "chat.completion",</span><br><span class=line>    "created": xxx,</span><br><span class=line>    "model": "gpt-4.1-2025-04-14",</span><br><span class=line>    "choices": [</span><br><span class=line>        {</span><br><span class=line>            "index": 0,</span><br><span class=line>            "message": {</span><br><span class=line>                "role": "assistant",</span><br><span class=line>                "content": "xxx",</span><br><span class=line>                "refusal": null,</span><br><span class=line>                "annotations": []</span><br><span class=line>            },</span><br><span class=line>            "logprobs": null,</span><br><span class=line>            "finish_reason": "stop"</span><br><span class=line>        }</span><br><span class=line>    ],</span><br><span class=line>    "usage": {</span><br><span class=line>        "prompt_tokens": 11840,</span><br><span class=line>        "completion_tokens": 489,</span><br><span class=line>        "total_tokens": 12329,</span><br><span class=line>        "prompt_tokens_details": {</span><br><span class=line>            "cached_tokens": 0,</span><br><span class=line>            "audio_tokens": 0</span><br><span class=line>        },</span><br><span class=line>        "completion_tokens_details": {</span><br><span class=line>            "reasoning_tokens": 0,</span><br><span class=line>            "audio_tokens": 0,</span><br><span class=line>            "accepted_prediction_tokens": 0,</span><br><span class=line>            "rejected_prediction_tokens": 0</span><br><span class=line>        }</span><br><span class=line>    },</span><br><span class=line>    "service_tier": "default",</span><br><span class=line>    "system_fingerprint": "xxx"</span><br><span class=line>}</span><br></pre></table></figure><ul><li><strong><code>prompt_tokens</code> (输入 Token):</strong> 你<strong>发送给模型</strong>的所有内容的成本。这<strong>不是</strong>指你刚刚输入的那句话，而是你 <code>messages</code> 数组中的<strong>全部内容</strong>，包括：<ol><li>系统提示 (System Prompt)<li>所有的历史对话 (如果你为了保持上下文而传入了)<li>你当前发送的所有文本<li>你当前发送的所有<strong>图片</strong>（这往往是大头！）</ol><li><strong><code>completion_tokens</code> (输出 Token):</strong> 模型<strong>生成并返回给</strong>你的内容的成本。<li><strong><code>total_tokens</code> (总 Token):</strong> <code>prompt</code> + <code>completion</code>，你本次调用的总计费 Token。</ul><p><strong>那么 <code>reasoning_tokens</code> (思考 Token) 是什么？</strong><p>在 <code>gpt-4.1</code> 调用中，这个值是 <code>0</code>。这并不代表模型“没有思考”，而是代表它的架构是一站式生成最终答案的。<p>这个字段是为 <strong>GPT-5</strong> 这样的新模型准备的。GPT-5 引入了“思考深度”机制。当它处理复杂问题时，会先“打草稿”或进行中间推理，这个过程消耗的 Token 就算作 <code>reasoning_tokens</code>。在 GPT-5 的计费中，总输出成本 = <code>completion_tokens</code> + <code>reasoning_tokens</code>。<h3 id=2-API-的核心原则：它是“无状态”的><a title="2. API 的核心原则：它是“无状态”的" class=headerlink href=#2-API-的核心原则：它是“无状态”的></a>2. API 的核心原则：它是“无状态”的</h3><p>这是新手最容易犯的错误：<strong>API 调用本身不具备上下文记忆。</strong><p>你不能像在 ChatGPT 网页版那样，先问“这是什么？”，再问“它是什么颜色的？”。服务器不会“记住”你上一次的调用。<p><strong>“上下文”是你作为开发者“手动”实现的。</strong><p>你必须在你的程序中维护一个 <code>messages</code> 列表（即对话历史），并且在<strong>每一次</strong>新请求中，都把<strong>完整的历史记录</strong>再次发送给 API。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br></pre><td class=code><pre><span class=line><span class=comment># 你的程序需要自己维护这个列表</span></span><br><span class=line>messages = [</span><br><span class=line>    {<span class=string>"role"</span>: <span class=string>"system"</span>, <span class=string>"content"</span>: <span class=string>"你是一个助手。"</span>}</span><br><span class=line>]</span><br><span class=line></span><br><span class=line><span class=comment># 第一次提问</span></span><br><span class=line>messages.append({<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>"你好，GPT-4.1 的上下文窗口多大？"</span>})</span><br><span class=line>response = client.chat.completions.create(model=<span class=string>"gpt-4.1"</span>, messages=messages)</span><br><span class=line>messages.append(response.choices[<span class=number>0</span>].message) <span class=comment># 把 AI 的回答也存入历史</span></span><br><span class=line></span><br><span class=line><span class=comment># 第二次提问</span></span><br><span class=line>messages.append({<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>"那 GPT-5 呢？"</span>})</span><br><span class=line><span class=comment># 这一次，你发送的是包含前 3 条消息的完整列表</span></span><br><span class=line>response = client.chat.completions.create(model=<span class=string>"gpt-4.1"</span>, messages=messages)</span><br><span class=line><span class=comment># AI 现在才能理解 "那 GPT-5 呢？" 是在和上一句做对比</span></span><br></pre></table></figure><h3 id=3-SDK-vs-手动请求：为什么你应该用-SDK><a title="3. SDK vs. 手动请求：为什么你应该用 SDK" class=headerlink href=#3-SDK-vs-手动请求：为什么你应该用-SDK></a>3. SDK vs. 手动请求：为什么你应该用 SDK</h3><p>使用 <code>openai</code> 官方库（SDK）远优于自己用 <code>requests</code> 库手搓 HTTP 请求：<ul><li><strong>流式处理 (Streaming):</strong> SDK 将复杂的 SSE (Server-Sent Events) 数据流自动转换成一个简单的 Python 生成器，你只需一个 <code>for</code> 循环就能处理。<li><strong>错误处理 (Error Handling):</strong> SDK 会将 API 的错误（如 <code>429</code> 速率限制、<code>401</code> 密钥错误）自动转换成明确的 Python 异常（如 <code>openai.RateLimitError</code>），方便你用 <code>try...except</code> 捕获。<li><strong>类型安全 (Type Safety):</strong> SDK 返回的是 Pydantic 对象 (如 <code>response.choices[0].message.content</code>)，而不是字典 (如 <code>resp_dict['choices'][0]['message']['content']</code>)。这能享受 IDE 自动补全，避免拼写错误。<li><strong>自动重试 (Auto-Retry):</strong> SDK 内置了对瞬时错误的指数退避重试逻辑。</ul><h3 id=4-深度指南：图片如何变成-Token><a title="4. 深度指南：图片如何变成 Token" class=headerlink href=#4-深度指南：图片如何变成-Token></a>4. 深度指南：图片如何变成 Token</h3><p>这可能是多模态 API 中最复杂的部分。图片 Token <strong>不看文件大小 (KB/MB)<strong>，而是看</strong>分辨率 (像素)</strong> 和<strong>你的设置</strong>。<h4 id=A-OpenAI-的可变成本-GPT-4-1-4o-5><a title="A. OpenAI 的可变成本 (GPT-4.1 / 4o / 5)" class=headerlink href=#A-OpenAI-的可变成本-GPT-4-1-4o-5></a>A. OpenAI 的可变成本 (GPT-4.1 / 4o / 5)</h4><p>通过 <code>detail</code> 参数控制成本：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>"image_url": {</span><br><span class=line>    "url": f"data:image/jpeg;base64,{base64_image}",</span><br><span class=line>    "detail": "low"</span><br><span class=line>}</span><br></pre></table></figure><ul><li><p><strong><code>detail: "low"</code> (低细节模式)</strong></p> <ul><li><strong>成本：</strong> 固定的 85 Token。<li><strong>原理：</strong> 无论图片多大，API 都会将其强制缩放到 512x512 像素再分析。<li><strong>适用：</strong> 识别主要物体、场景（“这是一只猫”）。</ul><li><p><strong><code>detail: "high"</code> (高细节模式)</strong></p> <ul><li><strong>成本：</strong> 可变，<code>85 + (170 * N)</code> 个 Token，<code>N</code> 是“瓦片”数量。<li><strong>原理：</strong><ol><li>API 先将图片缩放，使其最长边不超过 2048px (或放大到 512x512)。<li>然后用 512x512 的“瓦片”去切割这张缩放后的图片。<li>一张 1024x1800 的图片可能会被切成 2x3=6 个瓦片，成本就是 <code>85 + (170 * 6) = 1105</code> Token。</ol><li><strong>适用：</strong> 识别图表文字、精细细节。</ul></ul><h4 id=B-终极技巧：如何处理超长图片（如网页截图）><a title="B. 终极技巧：如何处理超长图片（如网页截图）" class=headerlink href=#B-终极技巧：如何处理超长图片（如网页截图）></a>B. 终极技巧：如何处理超长图片（如网页截图）</h4><p>如果你有一张 <code>1200 x 9000</code> 像素的长图，直接用 <code>detail: "high"</code> 发送会<strong>导致失败</strong>。API 会将其压缩成 <code>246 x 2048</code> 像素，所有细节都会丢失。<p><strong>正确的方法是“客户端手动切片”：</strong><ol><li><strong>在你的程序里</strong>，将 <code>1200 x 9000</code> 的长图切割成 8 张图（7 张 <code>1200x1200</code> + 1 张 <code>1200x600</code>）。<li>在<strong>同一次 API 调用</strong>中，按顺序传入这 8 张图片切片。<li>在<strong>文本提示</strong>中明确告知 AI：<code>"我提供了一张长图，已按顺序切成8片，请你按顺序分析..."</code>。</ol><h4 id=C-URL-vs-Base64：如何传入图片><a title="C. URL vs. Base64：如何传入图片" class=headerlink href=#C-URL-vs-Base64：如何传入图片></a>C. URL vs. Base64：如何传入图片</h4><p>API 两种都支持：<table><thead><tr><th align=left>方式<th align=left>优点<th align=left>缺点<tbody><tr><td align=left><strong>URL 链接</strong><td align=left>简单，API 请求体小<td align=left>图片必须是<strong>公网可访问</strong>的<tr><td align=left><strong>Base64 编码</strong><td align=left><strong>可以处理本地/私有图片</strong><td align=left>请求体变大 (数据膨胀约33%)</table><p><strong>Base64 格式：</strong> <code>url</code> 字段必须是 <code>data:[MIME_TYPE];base64,[你的Base64字符串]</code><h3 id=5-高级策略：如何区分不同角色的图片><a title="5. 高级策略：如何区分不同角色的图片" class=headerlink href=#5-高级策略：如何区分不同角色的图片></a>5. 高级策略：如何区分不同角色的图片</h3><p>假设你有一批“商品介绍图”（用来理解）和一批“备选缩略图”（用来选择）。你不能把它们混在一起丢给 AI。<ul><li><p><strong>方法一 (最可靠)：两次 API 调用</strong></p> <ol><li><strong>调用 1：</strong> 只发送“介绍图”，Prompt 是“请详细总结这个商品”。<li>拿到总结 <code>summary</code>。<li><strong>调用 2：</strong> 发送 <code>summary</code> 文本 + “备选缩略图”，Prompt 是“根据这份总结，请在以下图片中选出最好的缩略图”。</ol><li><p><strong>方法二 (最高效)：单次调用 + 文本图片交错</strong><br>利用 <code>messages</code> 数组可以混合 <code>text</code> 和 <code>image</code> 的特性，为图片“打标签”：</p> <figure class="highlight json"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line><span class=attr>"content"</span><span class=punctuation>:</span> <span class=punctuation>[</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 第一部分：商品介绍图 (用于理解) ---"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  </span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 第二部分：备选缩略图 (用于选择) ---"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"【备选缩略图 1】:"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"【备选缩略图 2】:"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  </span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 最终任务 --- \n 请根据第一部分的信息，从第二部分选择..."</span><span class=punctuation>}</span></span><br><span class=line><span class=punctuation>]</span></span><br></pre></table></figure></ul><h3 id=6-模型对比：GPT-vs-Qwen><a title="6. 模型对比：GPT vs. Qwen" class=headerlink href=#6-模型对比：GPT-vs-Qwen></a>6. 模型对比：GPT vs. Qwen</h3><p>最后，不同的模型家族有截然不同的特性：<table><thead><tr><th align=left>特性<th align=left>GPT-4.1<th align=left>GPT-5<th align=left>Qwen3-VL-30B<tbody><tr><td align=left><strong>最大上下文</strong><td align=left><strong>1,000,000</strong> (1M)<td align=left><strong>400,000</strong> (400K)<td align=left><strong>262,144</strong> (256K)<tr><td align=left><strong>思考机制</strong><td align=left>一站式生成<td align=left><strong>Reasoning 机制</strong> (自动/手动调节)<td align=left>一站式生成<tr><td align=left><strong>模型家族</strong><td align=left>单一模型<td align=left><strong>家族</strong> (Pro, Standard, Mini, Nano)<td align=left><strong>家族</strong> (Instruct, Thinking 等)<tr><td align=left><strong>图片计费</strong><td align=left><strong>可变</strong> (Low: 85, High: 1000+)<td align=left><strong>可变</strong> (类似 4.1，但成本更低)<td align=left><strong>固定</strong> (约 <strong>1,224</strong> Token/每张)<tr><td align=left><strong>图片限制</strong><td align=left>总 Token 限制<td align=left>总 Token 限制<td align=left>总 Token + <strong>50 张图片</strong>数量限制</table><p><strong>核心差异：</strong> OpenAI 的 <code>detail: "high"</code> 允许你通过消耗更多 Token 来获取超高图片细节，而 Qwen3-VL 采取了<strong>固定 1224 Token</strong> 的策略，这让成本非常可预测，但代价是（在 API 层面）无法对单张图片投入更多 Token 去“看清”微小细节。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/25/%E7%94%A8llama-cpp%E5%9C%A8mac%E4%B8%8A%E9%83%A8%E7%BD%B2qwen3vl-30B/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/25/%E7%94%A8llama-cpp%E5%9C%A8mac%E4%B8%8A%E9%83%A8%E7%BD%B2qwen3vl-30B/ itemprop=url>用llama.cpp在mac上部署qwen3vl-30B</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-25 14:44:31" datetime=2025-10-25T14:44:31+00:00>2025-10-25</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=引言：一个报错><a class=headerlink href=#引言：一个报错 title=引言：一个报错></a>引言：一个报错</h2><p>我目标是本地运行强大的 <strong>Qwen3-VL-30B</strong> 模型。我下载了编译了llama.cpp，但现在还不支持Qwen3系列<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>llama_model_load: error loading model: error loading model architecture: <span class=string>'qwen3vlmoe'</span></span><br></pre></table></figure><p>一个 <code>unknown model architecture</code> 报错。这意味着我的 <code>llama.cpp</code> 版本太老，还不认识这个新模型的架构。幸运的是，开源社区的行动总是神速，我很快找到了一个社区提供的解决方案，而这个修复过程，也带我进行了一次关于软件工程和模型架构的深度探索。<h2 id=1-解决方案-——-如何“打补丁”跑通-Qwen3-VL><a title="1: 解决方案 —— 如何“打补丁”跑通 Qwen3-VL" class=headerlink href=#1-解决方案-——-如何“打补丁”跑通-Qwen3-VL></a>1: 解决方案 —— 如何“打补丁”跑通 Qwen3-VL</h2><p>我找到的解决方案在 Hugging Face 的 <code>yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF</code> 仓库中。它的核心不是一个新程序，而是一个名为 <code>qwen3vl-implementation.patch</code> 的文件。<p>这个 <code>.patch</code> 文件就是“补丁”，它包含了让标准 <code>llama.cpp</code> 源代码支持 <code>qwen3vlmoe</code> 架构所需的所有代码更改。<p>以下是我的完整操作步骤：<p><strong>1. 下载并应用补丁</strong><p>先cd到llama.cpp目录下，<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>git <span class=built_in>clone</span> https://github.com/ggerganov/llama.cpp.git</span><br><span class=line><span class=built_in>cd</span> llama.cpp</span><br></pre></table></figure><p>我从社区仓库下载了 <code>.patch</code> 文件，并使用 <code>patch</code> 命令将其应用到刚克隆的源代码上：<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=comment># 下载补丁</span></span><br><span class=line>wget https://huggingface.co/yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF/raw/main/qwen3vl-implementation.patch</span><br><span class=line></span><br><span class=line><span class=comment># 应用补丁</span></span><br><span class=line>patch -p1 < qwen3vl-implementation.patch</span><br></pre></table></figure><p><code>patch -p1</code> 命令会智能地读取“更改说明书”，并自动修改我本地的源代码。<p><strong>3. 重新编译 <code>llama.cpp</code></strong><p>源代码更新后，必须重新编译。因为我用的是 Mac，所以我开启了 Metal GPU 加速：<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>cmake --build build --config Release -j 8</span><br></pre></table></figure><p><strong>4. 运行！</strong><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>build/bin/llama-server -hf yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF:Q4_K_S</span><br></pre></table></figure><p>运行后，会模型下载<strong>两个</strong> GGUF 文件：<ul><li><strong>主模型 (17.5 GB):</strong> <code>Qwen3-VL-30B-A3B-Q4_K_S.gguf</code><li><strong>多模态投影文件 (1.08 GB):</strong> <code>mmproj-Qwen3-VL-30B-A3B-F16.gguf</code></ul><p>这个命令同时会启动gui界面和api。<hr><h2 id=2-深入探索-——-Patch-和-mmproj-究竟是什么？><a title="2: 深入探索 —— Patch 和 mmproj 究竟是什么？" class=headerlink href=#2-深入探索-——-Patch-和-mmproj-究竟是什么？></a>2: 深入探索 —— Patch 和 mmproj 究竟是什么？</h2><h3 id=patch：一个-40-岁的“新”技术><a title="patch：一个 40 岁的“新”技术" class=headerlink href=#patch：一个-40-岁的“新”技术></a><code>patch</code>：一个 40 岁的“新”技术</h3><p><code>patch</code>（补丁）的概念几乎和编程一样古老。<ul><li><strong>物理起源 (1940s-1970s):</strong> 在使用“打孔卡片”编程的时代，修复 bug 意味着用胶带**物理地“贴住”（patch）**卡片上打错的孔。<li><strong>软件诞生 (1980s):</strong><ol><li><strong><code>diff</code> (1974年):</strong> Unix 系统诞生了 <code>diff</code> 命令，它可以比较两个文本文件并<strong>输出差异</strong>。<li><strong><code>patch</code> (1985年):</strong> 传奇程序员 <strong>Larry Wall</strong>（Perl 语言之父）发明了 <code>patch</code> 命令。它可以读取 <code>diff</code> 生成的“差异文件”，并<strong>自动将这些差异应用</strong>到旧文件上，将其“升级”成新版本。</ol></ul><p>所以，我刚才用的 <code>patch -p1</code> 命令，是一个在开源世界流传了近 40 年的经典工具，是软件协作和版本管理的基石。<h3 id=mmproj：连接视觉和语言的“翻译官”><a class=headerlink href=#mmproj：连接视觉和语言的“翻译官” title=mmproj：连接视觉和语言的“翻译官”></a><code>mmproj</code>：连接视觉和语言的“翻译官”</h3><p>为什么模型要分成两个文件（一个 17.5 GB 的主模型和一个 1.08 GB 的 <code>mmproj</code>）？为什么不合成一个？<p>答案在于<strong>模块化设计</strong>和<strong>效率</strong>。<p>一个视觉-语言模型（VLM）通常由两个“大脑”拼装而成：<ol><li><strong>视觉编码器 (Vision Encoder)：</strong> 专门“看”图片，把像素转换成一串复杂的数字（图像嵌入）。<li><strong>语言模型 (LLM)：</strong> 专门“思考和说”文本，它只懂语言。</ol><p>这两个“大脑”说的是不同的“语言”。而 <strong><code>mmproj</code> (Multi-Modal Projector，多模态投影器)</strong> 的唯一工作，就是充当它们之间的“翻译官”。<p>它是一个小型的神经网络，负责把“视觉编码器”输出的“图像语言”翻译成“LLM”能听懂的“文本语言”。<p><strong>为什么不合到一起？</strong><ul><li><strong>节省资源，按需加载：</strong> 这是最大的好处。如果我只想用 Qwen3-VL 聊天（纯文本），我<strong>不需要</strong>加载那 1.08 GB 的 <code>mmproj</code> 翻译官，从而节省了宝贵的 VRAM/RAM。只有当我需要处理图像时，我才通过 <code>--mmproj</code> 参数把它“插”上。<li><strong>训练和实验效率：</strong> 开发者可以“冻结”昂贵的 LLM，只单独训练和迭代这个小小的 <code>mmproj</code> 翻译官，极大降低了成本。</ul><hr><h2 id=Part-3-架构揭秘-——-Qwen3-VL-的“特殊”-RoPE><a title="Part 3: 架构揭秘 —— Qwen3-VL 的“特殊” RoPE" class=headerlink href=#Part-3-架构揭秘-——-Qwen3-VL-的“特殊”-RoPE></a>Part 3: 架构揭秘 —— Qwen3-VL 的“特殊” RoPE</h2><p>解决了运行问题，我开始好奇它的架构 <code>qwen3vlmoe</code> 到底特殊在哪。我了解到，它的核心优势之一在于使用了一种特殊的**旋转位置编码 (RoPE)**。<h3 id=为什么-RoPE-需要升级？><a title="为什么 RoPE 需要升级？" class=headerlink href=#为什么-RoPE-需要升级？></a>为什么 RoPE 需要升级？</h3><p>标准的 RoPE 是为<strong>一维 (1D)</strong> 文本设计的，它只关心“单词A在单词B前面多远”。<p>但是 <strong>Qwen3-VL 是一个视频-语言模型</strong>，它必须处理<strong>三维 (3D)</strong> 的数据块：<ol><li>$h$ (高度)<li>$w$ (宽度)<li>$t$ (时间，即视频的第几帧)</ol><p>早期的多模态模型 (如 Qwen2-VL) 使用 <strong>MRoPE</strong> (Multimodal RoPE)，它简单地把特征维度“分块”，比如：<ul><li>高频特征 $\leftarrow$ [所有时间 $t$ 的信息]<li>中频特征 $\leftarrow$ [所有高度 $h$ 的信息]<li>低频特征 $\leftarrow$ [所有宽度 $w$ 的信息]</ul><p>这种设计的<strong>致命缺陷</strong>是，所有“时间”信息都被困在了高频区，导致模型很难理解长距离的时间依赖（比如视频开头和结尾的联系），严重限制了长视频的理解。<h3 id=Qwen3-VL-的答案：Interleaved-MRoPE-交错式><a title="Qwen3-VL 的答案：Interleaved-MRoPE (交错式)" class=headerlink href=#Qwen3-VL-的答案：Interleaved-MRoPE-交错式></a>Qwen3-VL 的答案：Interleaved-MRoPE (交错式)</h3><p>Qwen3-VL 采用了更先进的 **Interleaved-MRoPE (I-MRoPE)**。<p>它不再“分块”，而是像发牌一样，把 $t, h, w$ 三个维度的信息**“交错”<strong>地、均匀地</strong>“轮询”<strong>（Round-Robin）分配到</strong>所有**的频率通道中（高、中、低频）。<p>这意味着，无论是 $t, h, $ 还是 $w$，都能访问到<strong>完整的频率频谱</strong>。<p>这种“全频率覆盖”的设计，使得 Qwen3-VL 在处理长视频和复杂空间关系时，能力远超前代。<p><strong>我输入的是静态图片，哪来的时间 $t$？</strong><p>答案是：<strong>Qwen3-VL 的架构是为更复杂的“视频”任务而设计的。</strong><ul><li><strong>当我输入视频时：</strong> 它在 3D 模式 ($t, h, w$) 下全速运行。<li><strong>当我输入图片时：</strong> 它只是在 2D 模式 ($h, w$) 下运行，这可以被看作是 $t=1$ 的一种特例。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/19/sping%E9%80%9F%E9%80%9A/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/19/sping%E9%80%9F%E9%80%9A/ itemprop=url>sping速通</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-19 22:32:24" datetime=2025-10-19T22:32:24+00:00>2025-10-19</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/java/ itemprop=url rel=index><span itemprop=name>java</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=一、-Java-基础：从-Go-Python-到-JVM><a title="一、 Java 基础：从 Go/Python 到 JVM" class=headerlink href=#一、-Java-基础：从-Go-Python-到-JVM></a>一、 Java 基础：从 Go/Python 到 JVM</h2><h3 id=1-语言范式的根本区别><a title="1. 语言范式的根本区别" class=headerlink href=#1-语言范式的根本区别></a>1. 语言范式的根本区别</h3><table><thead><tr><th align=left>特性<th align=left>C++/Python/Go 的习惯<th align=left>Java 的要求<th align=left>关键点<tbody><tr><td align=left><strong>代码结构</strong><td align=left>允许全局函数、模块级函数。<td align=left>所有的可执行代码（方法/逻辑）<strong>必须</strong>封装在一个 <code>class</code> (类) 或 <code>interface</code> (接口) 中。<td align=left>Java 是“纯血”的面向对象语言。你不能写一个脱离类的函数。<tr><td align=left><strong>数据类型</strong><td align=left>Python (动态)，Go (静态但有类型推断)。<td align=left><strong>强类型、静态类型</strong>。所有变量必须显式声明类型，一旦声明不能更改。<td align=left>避免 Go 语言中省略类型声明的习惯。<tr><td align=left><strong>内存管理</strong><td align=left>Go/Python 自动垃圾回收。<td align=left>**自动垃圾回收 (GC)**。无指针运算，内存错误率低。<td align=left>与 Go/Python 相似，无需手动管理内存。<tr><td align=left><strong>执行机制</strong><td align=left>编译成机器码 (Go/C++) 或解释执行 (Python)。<td align=left>编译成 **字节码 (<code>.class</code>)**，然后在 <strong>JVM (Java 虚拟机)</strong> 上运行。<td align=left>实现“一次编写，到处运行”。</table><h3 id=2-JDK-与版本生态><a title="2. JDK 与版本生态" class=headerlink href=#2-JDK-与版本生态></a>2. JDK 与版本生态</h3><ul><li>**Java 版本 (Specification) $\approx$ JDK 版本 (Implementation)**：Java SE 定义了语言特性和 API 规范。JDK (Java Development Kit) 是实现这些规范的工具包。<li><strong>多供应商实现 (OpenJDK):</strong> Java 规范由 <strong>JCP (Java Community Process)</strong> 维护。市面上的主流 JDK，如 <strong>Amazon Corretto</strong>、<strong>Eclipse Temurin</strong>、<strong>Oracle JDK</strong> 等，均基于开源的 <strong>OpenJDK</strong> 并通过兼容性测试 (TCK)。</ul><h2 id=二、构建工具对比：Gradle-的现代优势><a title="二、构建工具对比：Gradle 的现代优势" class=headerlink href=#二、构建工具对比：Gradle-的现代优势></a>二、构建工具对比：Gradle 的现代优势</h2><p>在 Java 世界中，构建工具负责依赖管理、编译、测试和打包。<table><thead><tr><th align=left>特性<th align=left>Maven (传统)<th align=left>Gradle (现代)<th align=left>优势点<tbody><tr><td align=left><strong>配置文件</strong><td align=left><code>pom.xml</code> (XML)<td align=left><code>build.gradle</code> (Groovy/Kotlin DSL)<td align=left><strong>可读性高，支持编程逻辑。</strong><tr><td align=left><strong>配置风格</strong><td align=left>纯声明式<td align=left><strong>编程式与声明式结合</strong><td align=left>极高的灵活性，可定义复杂的自定义任务。<tr><td align=left><strong>构建速度</strong><td align=left>每次执行全量构建<td align=left><strong>增量构建、构建缓存 (Cache)</strong><td align=left>对于大型和多模块项目，速度明显更快。</table><p><strong>结论：</strong> 对于 Spring Boot 新项目，<strong>Gradle</strong> 以其灵活性和性能优势，是更推荐的选择。<h2 id=三、-Spring-Boot-核心：依赖注入-DI-的魔法><a title="三、 Spring Boot 核心：依赖注入 (DI) 的魔法" class=headerlink href=#三、-Spring-Boot-核心：依赖注入-DI-的魔法></a>三、 Spring Boot 核心：依赖注入 (DI) 的魔法</h2><p>Spring Boot 的设计哲学是 <strong>“约定优于配置”</strong>，其核心是 **依赖注入 (DI)**。<h3 id=1-依赖注入-DI-与-IoC-容器><a title="1. 依赖注入 (DI) 与 IoC 容器" class=headerlink href=#1-依赖注入-DI-与-IoC-容器></a>1. 依赖注入 (DI) 与 IoC 容器</h3><table><thead><tr><th align=left>机制<th align=left>描述<th align=left>与传统开发的区别<tbody><tr><td align=left><strong>控制反转 (IoC)</strong><td align=left>将对象的创建、管理和生命周期的<strong>控制权</strong>交给 Spring 容器。<td align=left>你不再使用 <code>new MyService()</code> 手动创建对象。<tr><td align=left><strong>依赖注入 (DI)</strong><td align=left>应用程序所需的依赖（对象）由 Spring 容器自动<strong>注入</strong>到目标对象中。<td align=left>你只需声明你需要什么 (接口)，Spring 负责找到并提供具体的实现。</table><h3 id=2-核心注解速查><a title="2. 核心注解速查" class=headerlink href=#2-核心注解速查></a>2. 核心注解速查</h3><table><thead><tr><th align=left>注解<th align=left>作用范围<th align=left>功能描述<tbody><tr><td align=left><strong><code>@SpringBootApplication</code></strong><td align=left>主启动类<td align=left>整合配置、自动配置和组件扫描。<tr><td align=left><strong><code>@Autowired</code></strong><td align=left>构造函数/字段<td align=left>标记 Spring 容器应在此处自动注入依赖对象。<tr><td align=left><strong><code>@RestController</code></strong><td align=left>类<td align=left>标记为 Web 控制器，方法的返回值自动序列化为 JSON。<tr><td align=left><strong><code>@Service</code></strong><td align=left>类<td align=left>标记为业务逻辑组件 (Service Layer)。<tr><td align=left><strong><code>@Repository</code></strong><td align=left>类<td align=left>标记为数据访问组件 (DAO Layer)。</table><h2 id=四、-Spring-Boot-实战：分层与持久化-JPA><a title="四、 Spring Boot 实战：分层与持久化 (JPA)" class=headerlink href=#四、-Spring-Boot-实战：分层与持久化-JPA></a>四、 Spring Boot 实战：分层与持久化 (JPA)</h2><p>现代 Spring Boot 应用遵循经典的分层架构，DI 机制将它们解耦。<table><thead><tr><th align=left>层级<th align=left>技术/注解<th align=left>职责<th align=left>核心原理<tbody><tr><td align=left><strong>Controller (控制层)</strong><td align=left><code>@RestController</code>, <code>@RequestBody</code>, <code>@GetMapping</code><td align=left>接收 HTTP 请求，处理路由，调用 Service，序列化/反序列化 JSON。<td align=left>利用 <strong>Jackson</strong> 库自动完成 Java 对象与 JSON 格式的转换。<tr><td align=left><strong>Service (业务层)</strong><td align=left><code>@Service</code><td align=left>封装核心业务逻辑和事务管理。<td align=left>依赖注入 <code>Repository</code> 接口。<tr><td align=left><strong>Repository (数据层)</strong><td align=left><code>@Repository</code>, <code>JpaRepository</code><td align=left>与数据库交互。<td align=left>继承 <strong><code>JpaRepository&LTEntity, ID></code></strong> 后，Spring Data JPA 会在运行时自动生成基础的 CRUD (增删改查) 实现。<tr><td align=left><strong>Entity (数据模型)</strong><td align=left><code>@Entity</code>, <code>@Id</code>, <code>@GeneratedValue</code><td align=left>定义与数据库表对应的 Java 类。<td align=left>通过 <strong>JPA/Hibernate</strong> 实现 ORM (对象关系映射)。</table><h2 id=五、-配置管理与并发模型><a title="五、 配置管理与并发模型" class=headerlink href=#五、-配置管理与并发模型></a>五、 配置管理与并发模型</h2><h3 id=1-现代化配置：YAML-与-Profiles><a title="1. 现代化配置：YAML 与 Profiles" class=headerlink href=#1-现代化配置：YAML-与-Profiles></a>1. 现代化配置：YAML 与 Profiles</h3><ul><li><strong>YAML (Yet Another Markup Language):</strong> 使用 <strong><code>.yml</code></strong> 文件替代 <code>.properties</code>，利用缩进实现清晰的层次结构，例如：<figure class="highlight yaml"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br></pre><td class=code><pre><span class=line><span class=attr>spring:</span></span><br><span class=line>  <span class=attr>datasource:</span></span><br><span class=line>    <span class=attr>url:</span> <span class=comment># ...</span></span><br></pre></table></figure><li><strong>Profiles (环境配置):</strong> 通过创建 <code>application-{profile}.yml</code> 文件来隔离不同环境（dev/test/prod）的配置。<li><strong>激活方式:</strong> 启动时使用命令行参数激活特定环境：<code>--spring.profiles.active=prod</code></ul><h3 id=2-并发模型：Spring-MVC-vs-WebFlux><a title="2. 并发模型：Spring MVC vs. WebFlux" class=headerlink href=#2-并发模型：Spring-MVC-vs-WebFlux></a>2. 并发模型：Spring MVC vs. WebFlux</h3><table><thead><tr><th align=left>模型<th align=left>Spring MVC (默认)<th align=left>Spring WebFlux (响应式)<th align=left>建议<tbody><tr><td align=left><strong>底层架构</strong><td align=left>Servlet API, <strong>Thread-per-Request</strong> (每个请求一个 Java 线程等待)<td align=left><strong>非阻塞 I/O</strong>，基于 <strong>Reactor</strong> 库 (类似 Event Loop)。<td align=left>针对 <strong>I/O 密集型/高并发</strong> 场景，性能更优。<tr><td align=left><strong>适用性</strong><td align=left>易于理解，CPU 密集型或传统应用。<td align=left><strong>高吞吐量微服务</strong>，类似 Go 的 Goroutine 优势。<td align=left>随着 <strong>Java 虚拟线程 (Virtual Threads)</strong> 的引入，Java 的并发能力正在发生革命性变化。</table><h2 id=六、开发环境-IDE-推荐><a title="六、开发环境 (IDE) 推荐" class=headerlink href=#六、开发环境-IDE-推荐></a>六、开发环境 (IDE) 推荐</h2><p>对于 Java 和 Spring Boot 开发，推荐：<ul><li><strong>IntelliJ IDEA Community Edition (社区版):</strong> 免费且功能强大，提供对 Spring Boot 和 Gradle 最完善、最智能的集成支持，能极大地提高你的开发效率。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/07/claude-code/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/07/claude-code/ itemprop=url>claude code</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-07 20:07:06" datetime=2025-10-07T20:07:06+00:00>2025-10-07</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/claude/ itemprop=url rel=index><span itemprop=name>claude</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=claude-code命令行><a class=headerlink href=#claude-code命令行 title=claude-code命令行></a>claude-code命令行</h1><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>npm install -g @anthropic-ai/claude-code --registry=https://registry.npmmirror.com</span><br></pre></table></figure><p>通过环境变量修改成kimi的模型<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>export ANTHROPIC_BASE_URL=https://api.moonshot.cn/anthropic</span><br><span class=line>export ANTHROPIC_AUTH_TOKEN=${YOUR_MOONSHOT_API_KEY}</span><br><span class=line>export ANTHROPIC_MODEL=kimi-k2-turbo-preview</span><br><span class=line>export ANTHROPIC_SMALL_FAST_MODEL=kimi-k2-turbo-preview</span><br></pre></table></figure><p>或者在claude配置文件中添加环境变量<br><code>~/.claude/settings.json</code><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    "env": {</span><br><span class=line>        "ANTHROPIC_BASE_URL": "https://www.sophnet.com/api/open-apis/7TxazXiOf8xHVzgbxY2o6w/anthropic",</span><br><span class=line>        "ANTHROPIC_AUTH_TOKEN": "${YOUR_API_KEY}",</span><br><span class=line>        "ANTHROPIC_MODEL": "Kimi-K2-0905",</span><br><span class=line>        "ANTHROPIC_SMALL_FAST_MODEL": "Kimi-K2-0905"</span><br><span class=line>    }</span><br><span class=line>}</span><br></pre></table></figure><p>添加mcp，<code>mcp-chrome-bridge</code>确实好用，就是费token<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>claude mcp add --transport http mcp-chrome-bridge http://127.0.0.1:12306/mcp</span><br></pre></table></figure><h1 id=claude-code的vscode插件><a class=headerlink href=#claude-code的vscode插件 title=claude-code的vscode插件></a>claude-code的vscode插件</h1><p>应用市场安装先安装一个<br>在设置中搜索<code>Claude Code: Environment Variables</code>，编辑<code>setting.json</code><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    ...</span><br><span class=line>    "claude-code.environmentVariables": [</span><br><span class=line>        { "name": "ANTHROPIC_BASE_URL", "value": "https://www.sophnet.com/api/open-apis/7TxazXiOf8xHVzgbxY2o6w/anthropic" },</span><br><span class=line>        { "name": "ANTHROPIC_AUTH_TOKEN", "value": "${YOUR_API_KEY}" },</span><br><span class=line>        { "name": "ANTHROPIC_MODEL", "value": "Kimi-K2-0905" },</span><br><span class=line>        { "name": "ANTHROPIC_SMALL_FAST_MODEL", "value": "Kimi-K2-0905" }</span><br><span class=line>    ]</span><br><span class=line>}</span><br></pre></table></figure><p>vscode的ai插件真多啊，有官方copilot，有早期的cline，claude code也有了</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/09/27/AIGC%E5%BD%92%E7%BA%B3/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/09/27/AIGC%E5%BD%92%E7%BA%B3/ itemprop=url>AIGC归纳</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-09-27 18:42:24" datetime=2025-09-27T18:42:24+00:00>2025-09-27</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><blockquote><p>失业的第一天，把现有的关于AIGC的乱七八糟的东西归纳一下</blockquote><h1 id=AI大善人们><a class=headerlink href=#AI大善人们 title=AI大善人们></a>AI大善人们</h1><h2 id=GPU><a class=headerlink href=#GPU title=GPU></a>GPU</h2><h3 id=腾讯cloud-studio><a title="腾讯cloud studio" class=headerlink href=#腾讯cloud-studio></a>腾讯cloud studio</h3><p><a href=https://cloudstudio.net/my-app>https://cloudstudio.net/my-app</a><p>我主要用的是这个平台，每天签到有2核时，大概A10可以用40分钟。有256g的存储，放一些图片和模型文件也够用。有一些现成的comfyUI的应用，还比较好用。<p>但感觉像没啥人维护了，文档不太好，怎么自己创建应用，在哪里写配置文件没找到。<p><img data-src=/images/image1.png><h3 id=腾讯cnb><a class=headerlink href=#腾讯cnb title=腾讯cnb></a>腾讯cnb</h3><p><a href=https://cnb.cool/?type=activities>https://cnb.cool/?type=activities</a><p>应该和上面用法差不多，只是我没怎么用。<h3 id=谷歌colab><a class=headerlink href=#谷歌colab title=谷歌colab></a>谷歌colab</h3><p><a href=https://colab.research.google.com/>https://colab.research.google.com</a><p>免费用户可以用T4大概4小时，我这两天基本都有，好处是不用搞签到啥的，坏处是每次环境都是新的，重新安装依赖，下一遍模型。我试了index-tts是在这上面部署的。<h2 id=API><a class=headerlink href=#API title=API></a>API</h2><h3 id=硅基流动><a class=headerlink href=#硅基流动 title=硅基流动></a>硅基流动</h3><p><a href=https://cloud.siliconflow.cn/me/models>https://cloud.siliconflow.cn/me/models</a><p>硅基流动还是挺好的，送我的14块钱一直用不完，模型也比较全，唯独api base<br>url不好找，<a href=https://api.siliconflow.cn/v1>https://api.siliconflow.cn/v1</a><h3 id=SophNet><a class=headerlink href=#SophNet title=SophNet></a>SophNet</h3><p><a href=https://sophnet.com//#/model/overview>https://sophnet.com/\#/model/overview</a><p>和硅基流动差不多，开源的模型挺全的，而且api很快，我claude<br>code用的就是SophNet部署的kimi v2<h2 id=应用><a class=headerlink href=#应用 title=应用></a>应用</h2><h3 id=LibLibAI><a class=headerlink href=#LibLibAI title=LibLibAI></a>LibLibAI</h3><p><a href=https://www.liblib.art/inspiration>https://www.liblib.art/inspiration</a><p>主要是来这里学生图提示词的，lora模型比较丰富，还可以训练，但没试过。<h1 id=index-tts><a class=headerlink href=#index-tts title=index-tts></a>index-tts</h1><p>看了b站的index-tts，类似的能实现声音克隆的还有阿里的CosyVoice，社区的GPT-SoVITS。<p>index-tts最大特点在于他把音色和情绪解耦了，你可以单独控制声音的情绪。<p>github.com/index-tts/index-tts.git，可以直接在colab上部署。<p>做声音有个现成的方式是用minimax.io 可以克隆音色<h1 id=comfyUI><a class=headerlink href=#comfyUI title=comfyUI></a>comfyUI</h1><p>最近比较流行的生图工具了，支持的模型很多，最早我是想去试用qwen-image的。网页部署唯一比较麻烦的是下载模型，这里附上一些huggingface的命令。<figure class="highlight shell"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>huggingface-cli list Kijai/flux-fp8\</span><br><span class=line>huggingface-cli download Kijai/flux-fp8 \--include flux1-dev-fp8.safetensor \--local-dir ./workspace/Comfyui/models/unet</span><br></pre></table></figure><p><img data-src=/images/image2.png><p>comfyUI也不用自己搭，有很多平台能用，阿里、LibLib、runninghub都有<p>对做视频比较好用的几个模型<ul><li><p><a href=https://wan.video/blog/wan2.2-animate>wan2.2-animate</a>，能做吴京视频。</p> <blockquote><p>Wan-Animate supports two modes: (1) Animation mode, which generates high-fidelity character animation videos by precisely replicating the facial expressions and body movements from the reference video; (2) Replacement mode, which seamlessly integrates the character into the reference video, replacing the original character while reproducing the scene’s lighting and color style to achieve natural environmental blending.</blockquote><li><p><a href=https://zhuanlan.zhihu.com/p/1949456021010510998>humo</a>，可以做数字人。</p></ul><h1 id=SillyTavern><a class=headerlink href=#SillyTavern title=SillyTavern></a>SillyTavern</h1><p><a href=https://github.com/SillyTavern/SillyTavern>https://github.com/SillyTavern/SillyTavern</a><p>这个就比较偏娱乐了，文字冒险游戏了，最基础的是对话，然后可以加入生图和tts，都是走api的，所以本地只有cpu的机器也可以跑。<p>角色卡可以自己捏，也可以到网上下，比如<a href=https://discord.com/channels/1124998756715216976/1165191657449332757>类脑</a>上的，大部分是NSFW。<p>要生图的话是走插件，需要安装这个插件<a href=https://github.com/wickedcode01/st-image-auto-generation%EF%BC%8C%E5%AE%89%E8%A3%85%E5%90%8E%E5%B0%B1%E4%BC%9A%E5%87%BA%E7%8E%B0%22Image>https://github.com/wickedcode01/st-image-auto-generation，安装后就会出现"Image</a><br>Auto<br>Generation”插件，这个插件会要求在每次生成内容后，再生成一段生图的prompt。<p>左侧我选的是ComfyUI，ComfyUI用的是前面腾讯cloud<br>studio部署的，也可以api调用。ComfyUI的dag图是这个json文件，我不太会改，只是把模型从sd1.5换到了3.5。<p>tts我没有配置。<p><img data-src=/images/image3.png><h1 id=CS336><a class=headerlink href=#CS336 title=CS336></a>CS336</h1><p>还是不能忘记学习，<a href=https://stanford-cs336.github.io/spring2025/%EF%BC%8C>https://stanford-cs336.github.io/spring2025/，</a><p><a href=https://www.bilibili.com/video/BV1YKhhzBE1M/?vd%5C_source=d4d45a41db226393d3b605dd30e2ffa8>https://www.bilibili.com/video/BV1YKhhzBE1M/?vd\_source=d4d45a41db226393d3b605dd30e2ffa8</a><h1 id=gemini的gem><a class=headerlink href=#gemini的gem title=gemini的gem></a>gemini的gem</h1><p><a href=https://gemini.google.com/gem/9c3b6882ff67?ref=jeffsu.org>Veo Visionary | Text-to-Video Generator</a><p><img alt=image-20251019112152102 data-src=/images/image-20251019112152102.png><p><img alt=image-20251019112549872 data-src=/images/image-20251019112549872.png></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/09/20/diffusion/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/09/20/diffusion/ itemprop=url>diffusion模型基础</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-09-20 10:28:06" datetime=2025-09-20T10:28:06+00:00>2025-09-20</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/diffusion/ itemprop=url rel=index><span itemprop=name>diffusion</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=auto-encoder><a title="auto encoder" class=headerlink href=#auto-encoder></a>auto encoder</h2><p>训练目标是：希望输入的图片经过两次转换和原来的图片越接近越好，也被称为“重构-reconstruction”(不需要有标签的数据)<br>常见的应用：原来的向量维度很高，经过encoder之后输出维度小的向量，再用这个低维度的向量去做后面的任务。<p>auto encoder严格来说不算生成模型，只是在重构，到VAE才算具备的生成能力。<p><img alt=img data-src=/images/v2-4fb6ce4972f4f716553b7d256a13c712_1440w.jpg><h2 id=VAE（变分自编码器）><a class=headerlink href=#VAE（变分自编码器） title=VAE（变分自编码器）></a>VAE（变分自编码器）</h2><p>VAE 是一种概率生成模型，通过编码器将输入数据映射到潜空间，再通过解码器从潜空间重构数据。<p>在VAE中，我们假设$p(Z|X)$后验分布是正态分布，给定一个真实的样本$X_k$，都有专属的分布$p(Z|X_k)$。训练生成器时，采样一个$Z_k$来还原$X_k$。<p>VAE 的损失函数由两部分组成：<ul><li>reconstruction loss（重构损失）：衡量重构输入 $\hat{X}$ 与原始输入 $X$ 的相似度，常用均方误差（MSE）：</ul><p>$$<br>\text{reconstruction loss} = | X - \hat{X} |^2<br>$$<p>其中 $\hat{X}$ 是解码器生成的重构结果。<ul><li>similarity loss（相似性损失）：即 KL 散度，衡量潜在分布 $\mathcal{N}(\mu, \sigma)$ 与标准正态分布 $\mathcal{N}(0, I)$ 的差异，可以当做是一个正则项。</ul><p>$$<br>\text{similarity loss} = D_{KL}(\mathcal{N}(\mu, \sigma) | \mathcal{N}(0, I)) \<br>=\frac{1}{2}(-log\sigma ^2+\mu ^2+\sigma ^ 2 - 1)<br>$$<p>VAE的训练过程本质上是重建损失和KL散度损失之间的权衡：重建损失希望编码器学习到区分度大、能精确重建的潜在表示，这可能倾向于让$\mu$分散、$\sigma$变小。KL散度损失则希望所有分布收缩到0和1，防止VAE退化成普通AE，失去生成新样本的能力。<p>$$<br>\text{loss} = \text{reconstruction loss} + \text{similarity loss}<br>$$<p><img alt=VAE结构与损失函数 data-src=/images/v2-36c7da0b2fe37bd021699532a2cff1e8_1440w.jpg><p><img alt=img data-src=/images/v2-784891edddff506ea1670c81767e993c_1440w.jpg><p>VAE存在一个固有问题，是用L2距离来衡量$\hat{X}$ 与 $X$ 的相似度，L2距离只是近似等于分布距离，会导致图片变得模糊（倾向于生成低频信号，这样L2 loss小）。<h2 id=GAN（生成对抗网络）><a class=headerlink href=#GAN（生成对抗网络） title=GAN（生成对抗网络）></a>GAN（生成对抗网络）</h2><p>GAN的思路是reconstruction loss不好衡量，我就用个模型来代替，多加了一个discriminator来判断图片是生成的还是真实的。训练过程是generator和discriminator交替进行。<p>我以前也写过<a href=/2019/01/27/GAN%E6%80%BB%E7%BB%93/ title=GAN总结>GAN</a>，当时GAN还很火。<p>$$<br>\min_G \max_D V(D,G) = E_{x \sim p_{\text{data}}(x)}[\log D(x)] + E_{z \sim p_{z}(z)}[\log(1 - D(G(z)))]<br>$$<p>这是<strong>生成对抗网络（GAN）</strong>的<strong>价值函数（Value Function）</strong>或<strong>目标函数（Objective Function）</strong>。<ul><li><strong>$G$</strong> 代表<strong>生成器（Generator）</strong>，其目标是<strong>最小化</strong>这个函数（$\min_G$）。<li><strong>$D$</strong> 代表<strong>判别器（Discriminator）</strong>，其目标是<strong>最大化</strong>这个函数（$\max_D$）。<li><strong>$V(D, G)$</strong> 是判别器 $D$ 和生成器 $G$ 之间的<strong>二人极小极大博弈</strong>的值。</ul><p><strong>公式组成部分：</strong><ol><li><p><strong>$E_{x \sim p_{\text{data}}(x)}[\log D(x)]$</strong>:</p> <ul><li>这是判别器<strong>正确判断真实数据</strong> $x$ 为真的期望。<li>$p_{\text{data}}(x)$ 是真实数据分布。<li>$D(x)$ 是判别器将真实数据 $x$ 判为真的概率。<li>判别器 $D$ 想要最大化这一项，使其接近 $1$（$\log(1)=0$）。</ul><li><p><strong>$E_{z \sim p_{z}(z)}[\log(1 - D(G(z)))]$</strong>:</p> <ul><li>这是判别器<strong>正确判断生成数据</strong> $G(z)$ 为假的期望。<li>$p_{z}(z)$ 是噪声输入 $z$ 的先验分布。<li>$G(z)$ 是生成器 $G$ 生成的假样本。<li>$D(G(z))$ 是判别器将假样本 $G(z)$ 判为真的概率。<li>判别器 $D$ 想要最大化这一项，即使 $D(G(z))$ 接近 $0$（$\log(1-0)=\log(1)=0$）。<li>生成器 $G$ 想要<strong>最小化</strong>这一项，即使 $D(G(z))$ 接近 $1$，从而骗过判别器。</ul></ol><h2 id=Diffusion（扩散模型）><a class=headerlink href=#Diffusion（扩散模型） title=Diffusion（扩散模型）></a>Diffusion（扩散模型）</h2><p>Diffusion 模型是一类基于概率扩散过程的生成模型。其核心思想是将数据逐步加噪声，最终变成纯噪声，然后训练一个模型学会如何一步步去噪，最终还原出原始数据。Diffusion 模型近年来在图像生成等任务上取得了极大成功，代表模型有 DDPM、Stable Diffusion 等。<p>Diffusion 模型包括两个过程：<strong>正向扩散过程（加噪声）</strong>和<strong>反向去噪过程（生成）</strong>。<h3 id=1-正向扩散（Forward-Process）><a title="1. 正向扩散（Forward Process）" class=headerlink href=#1-正向扩散（Forward-Process）></a>1. 正向扩散（Forward Process）</h3><p>正向过程将原始数据 $x_0$ 逐步加入高斯噪声，经过 $T$ 步后变成接近各向同性高斯分布的噪声 $x_T$。每一步的加噪过程如下：<p>$$<br>q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)<br>$$<p>其中 $\beta_t$ 是每一步的噪声强度。<h3 id=2-反向去噪（Reverse-Process）><a title="2. 反向去噪（Reverse Process）" class=headerlink href=#2-反向去噪（Reverse-Process）></a>2. 反向去噪（Reverse Process）</h3><p>反向过程的目标是从纯噪声 $x_T$ 开始，逐步去噪，最终还原出数据 $x_0$。反向过程同样是高斯过程，但均值和方差需要模型学习：<p>$$<br>p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))<br>$$<p>训练时，通常用一个神经网络（如 U-Net）预测噪声或数据的均值。<h3 id=Diffusion-模型的训练><a title="Diffusion 模型的训练" class=headerlink href=#Diffusion-模型的训练></a>Diffusion 模型的训练</h3><p>Diffusion 模型的训练目标是让模型学会在每一步准确地去噪。常见的训练方式是让模型预测每一步加到数据上的噪声 $\epsilon$，损失函数为：<p>$$<br>L_{simple} = E_{x_0, \epsilon, t} \left[ | \epsilon - \epsilon_\theta(x_t, t) |^2 \right]<br>$$<p>其中 $x_t$ 是在 $t$ 时刻加噪后的数据，$\epsilon$ 是实际加的噪声，$\epsilon_\theta$ 是模型预测的噪声。<p>训练流程如下：<ol><li>从数据集中采样一张图片 $x_0$。<li>随机采样一个时间步 $t$。<li>按照正向扩散公式加噪，得到 $x_t$。<li>用神经网络输入 $x_t$ 和 $t$，预测噪声 $\epsilon_\theta$。<li>计算损失并反向传播，更新模型参数。</ol><h3 id=Diffusion-模型的推理（采样）><a title="Diffusion 模型的推理（采样）" class=headerlink href=#Diffusion-模型的推理（采样）></a>Diffusion 模型的推理（采样）</h3><p>推理阶段，从高斯噪声 $x_T$ 开始，利用训练好的模型逐步去噪，最终生成一张图片。每一步的采样过程如下：<ol><li>初始化 $x_T \sim \mathcal{N}(0, I)$。<li>对 $t = T, T-1, …, 1$：<ul><li>用模型预测当前噪声 $\epsilon_\theta(x_t, t)$。<li>计算 $x_{t-1}$ 的均值和方差。<li>从高斯分布采样 $x_{t-1}$。</ul><li>最终得到 $x_0$，即生成的图片。</ol><p>推理过程可以理解为“逆过程”，逐步将噪声还原为清晰的样本。采样步数越多，生成质量越高，但速度越慢。近年来也有很多加速采样的改进方法。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/06/02/BLEU%E5%92%8CGLUE/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/06/02/BLEU%E5%92%8CGLUE/ itemprop=url>BLEU和GLUE</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-06-02 23:03:26" datetime=2025-06-02T23:03:26+00:00>2025-06-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E5%8F%91%E7%96%AF%E6%96%87%E5%AD%A6/ itemprop=url rel=index><span itemprop=name>发疯文学</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>攒了好多年的问题了，该了结一下了。<h1 id=BLEU-机器翻译指标><a title="BLEU 机器翻译指标" class=headerlink href=#BLEU-机器翻译指标></a>BLEU 机器翻译指标</h1><p>transormer那篇论文里提到了BLEU指标，但一直不知道这个指标是啥。<p>BLEU（Bilingual Evaluation Understudy），通过比较机器翻译的结果与<strong>参考译文</strong>之间的相似度来衡量翻译质量。<p>$$<br>BLEU=BP*exp(\sum_{n=1}^N\frac{1}{N}logP_n)<br>$$<ul><li><p>N取4，即最多4-gram</p><li><p>BP（Brevity Penalty）是长度惩罚因子，$l_c$代表表示机器翻译译文的长度，$l_s$表示参考答案的有效长度，避免机器翻译太短，hack了$P_n$指标，本质上还是$P_n$只考虑了准确率，没考虑召回率。<br>$$<br>BP = \begin{cases}<br>1 & l_c \ge l_s \<br>exp(1-\frac{l_c}{l_s}) & l_c < l_s<br>\end{cases}<br>$$</p><li><p>$P_n$，n-gram，比较译文和参考译文之间n组词的相似的占比。</p></ul><p>比较详细的可以参考<a href=https://www.cnblogs.com/by-dream/p/7679284.html>这里</a>。<h1 id=GLUE><a class=headerlink href=#GLUE title=GLUE></a>GLUE</h1><p>GLUE（General Language Understanding Evaluation）是一个综合性的GLU（自然语言理解）评估基准，通过9个英语任务测试模型的通用能力，取平均值。<ul><li><p>单句分类任务‌</p> <ul><li>CoLA‌：纽约大学发布的有关语法的数据集，该任务主要是对一个给定句子，判定其是否语法正确，因此CoLA属于单个句子的文本二分类任务<li>SST（情感分析）：是斯坦福大学发布的一个情感分析数据集，主要针对电影评论来做情感分类，因此SST属于单个句子的文本分类任务（SST-2是二分类，SST-5是五分类，SST-5的情感极性区分的更细致）</ul><li><p>相似性任务‌</p> <ul><li>MRPC/QQP‌（句子对语义等价判断）：判断两个给定句子，是否具有相同的语义，属于句子对的文本二分类任务<li>STS-B‌（句子相似度评分）：用1到5的分数来表征两个句子的语义相似性，本质上是一个回归问题，但依然可以用分类的方法做，因此可以归类为句子对的文本五分类任务</ul><li><p>推理任务‌</p> <ul><li>MNLI/QNLI/RTE/WNLI‌（文本蕴含与推理）</ul></ul><p>也是比较老的指标了，BERT、T5那个时代的。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/03/11/ads/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/03/11/ads/ itemprop=url>记一点广告的基础知识</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-03-11 20:42:24" datetime=2025-03-11T20:42:24+00:00>2025-03-11</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E6%8E%A8%E8%8D%90/ itemprop=url rel=index><span itemprop=name>推荐</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=MLE和MAP><a class=headerlink href=#MLE和MAP title=MLE和MAP></a>MLE和MAP</h2><ul><li>MLE最大化$P(Y|X,\theta)$<li>MAP最大化$P(\theta|X,Y) \propto P(Y|X,\theta)P(\theta)$</ul><p>特殊情况：<ul><li>如果$\theta$是均匀分布，两者等效<li>如果$P(\theta)$是高斯分布，等同于L2正则<li>如果$P(\theta)$是拉普拉斯分布，等同于L1正则</ul><h2 id=负采样纠偏><a class=headerlink href=#负采样纠偏 title=负采样纠偏></a>负采样纠偏</h2><p>训练时纠偏，训练输出就是无偏结果，inference时不需要纠偏。<p>用采样后的样本，预测输出的logit为$f’$，无偏的结果为$f$，$p’=\frac{1}{1+e^{-f’}}$，$p$同理。<p>$$<br>p=\frac{p’}{p’+\frac{1-p’}{r}}<br>$$<p>这里$r$是负样本采样率，把$p$都替换成$f$，可以得到：<p>$$<br>f=f’+ln(r)<br>$$<p>注：模型auc需要用这种纠偏之后，才能对比。<h2 id=Weighted-LR><a title="Weighted LR" class=headerlink href=#Weighted-LR></a>Weighted LR</h2><p>YouTube-DNN 时长建模，<br>参考：<a href=https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf>Deep Neural Networks for YouTube Recommendations</a><p>$$<br>-\sum_i [t_i y_i log(p_i) + (1-y_i) log(1-p_i)] \<br>p_i = \frac{1}{1+e^{-wz}} \<br>odds = \frac{P}{1-P} = e^{wz}=\frac{E(t)}{1-P}<br>$$<p>因为$P$比较小，所以$E(t)=e^{wz}$<p>如果把所有的样本都作为负例，对正样本加权，就不会有近似了，直接是无偏的。<p><strong>LR概率模型分析</strong><ul><li>常见的LR：假设数据服从伯努利分布，发生概率为$p$，不发生为$1-p$，$odds=p/(1-p)$为几率比<li>weighted LR：假设数据服从几何分布，假设用户看单位时长的概率为p，期望为$\frac{1}{1-p}-1=e^{wz}$（-1是因为几何概率一般是从1开始，我们这里是从0开始）</ul><h2 id=回归转分类><a class=headerlink href=#回归转分类 title=回归转分类></a>回归转分类</h2><p>把连续值分桶，softmax预测在每个桶的概率，不需要对label有啥分布的假设。<p>可以对label做软化，默认分桶是01 hard label，可以类似知识蒸馏，对标签做软化，但实际上我们没有teacher model，可以依赖一些先验假设，比如高斯分布。<h3 id=TPM><a class=headerlink href=#TPM title=TPM></a><a href=https://arxiv.org/pdf/2306.03392>TPM</a></h3><p>可以有级联的loss：softmax loss，每个桶内的连续loss。参考KDD23快手的TPM，Tree based Progressive Regression Model。<p>每个叶子节点是最后的分类，也对应了一条路径，每个叶子节点的概率是多层概率的乘积。<p><img alt=img data-src=/images/v2-9dd5a641dae8bcbe5d821337c956025f_1440w.jpg><h3 id=Ordinal-regression><a title="Ordinal regression" class=headerlink href=#Ordinal-regression></a><a href=https://en.wikipedia.org/wiki/Ordinal_regression>Ordinal regression</a></h3><p>把学习目标送PDF改为CDF，也是把连续值分成$K$个桶。预测的不是属于某个桶的概率，而是小于等于某个桶的概率。<br>$$<br>F(k)=P(f(x_i)\le t_k)=\sigma(t_k-f(x_i))<br>$$<p>$$<br>f(k)=F(k)-F(k-1)<br>$$<p>但这里对分布有假设，$\sigma$是一个CDF，可以是sigmoid函数，或者高斯分布的CDF$\Phi$。<p>还有一种方法，是变成$K$个二分类。<h2 id=ZILN-loss><a title="ZILN loss" class=headerlink href=#ZILN-loss></a>ZILN loss</h2><p>参考：<a href=https://arxiv.org/pdf/1912.07753>ZILN论文</a>（zero-inflated lognormal）<p>The ZILN loss can be similarly derived as the negative log-likelihood of a ZILN distributed random variable with p as the probability of being nonzero:<p>$$<br>L_{ZILN}(x; p, \mu, \sigma) = −1_{x=0} log(1 − p) − 1_{x>0}(log p − L_{Lognormal}(x; \mu, \sigma))<br>$$<p>where 1 denotes the indicator function.<p>The loss can be decomposed into two terms:<ol><li>分类loss：判断客户是否为回头客<li>回归loss：预测重复购买客户的LTV</ol><p>$$<br>L_{ZILN}(x; p, \mu, \sigma) = L_{CrossEntropy}(1_{x>0}; p) + 1_{x>0}L_{Lognormal}(x; \mu, \sigma)<br>$$<p>模型输出3个值，分别对应：$p$，$\mu$，$\sigma$<p>预估的LTV为：$p e^{\mu+\sigma^2/2}$<h2 id=多目标建模><a class=headerlink href=#多目标建模 title=多目标建模></a>多目标建模</h2><ul><li>MMOE<li>ESMM<li><a href=https://arxiv.org/pdf/1902.09154>DBMTL</a></ul><h2 id=双塔近似计算><a class=headerlink href=#双塔近似计算 title=双塔近似计算></a>双塔近似计算</h2><p>参考：<a href=https://zhuanlan.zhihu.com/p/656834772>Efficient Training on Very Large Corpora via Gramian Estimation</a></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2024/11/05/geekbench/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2024/11/05/geekbench/ itemprop=url>直观感受下摩尔定律</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2024-11-05 11:42:24" datetime=2024-11-05T11:42:24+00:00>2024-11-05</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E5%8F%91%E7%96%AF%E6%96%87%E5%AD%A6/ itemprop=url rel=index><span itemprop=name>发疯文学</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>数据来源，<a href=https://browser.geekbench.com/v6/cpu/search?utf8=%E2%9C%93&q=iphone+14>geekbench官网搜的</a>，geekbench6<del>，怀疑新cpu本身就占优</del><p>我这两天把老电脑又拿出来了，装了win11，然后想起来极客湾做的高通855刷win11，说有类似4代i5水平，还是挺出乎意料的，于是把我有的几个设别的geekbench分数查了一下<p><img alt=1749975940509 data-src=/images/1749975940509.png><h2 id=三星-q470bt04，2012><a title="三星 q470bt04，2012" class=headerlink href=#三星-q470bt04，2012></a>三星 q470bt04，2012</h2><p>Mobile DualCore Intel Core i5-3210M<p>Single-Core Score 523 Multi-Core Score 1116，TDP35w<blockquote><p>TDP（Thermal Design Power）是“热设计功耗”的缩写，主要用于描述处理器或芯片在满负荷运行时产生的热量指标，单位为瓦特（W）</blockquote><p>nVIDIA GeForce GT 650M 1GB<h2 id=MacBook-Pro（13-英寸，2017，两个-Thunderbolt-3-端口）><a title="MacBook Pro（13 英寸，2017，两个 Thunderbolt 3 端口）" class=headerlink href=#MacBook-Pro（13-英寸，2017，两个-Thunderbolt-3-端口）></a><a href=https://support.apple.com/zh-cn/111951>MacBook Pro（13 英寸，2017，两个 Thunderbolt 3 端口）</a></h2><p>Intel Core i5-7360U 2300 MHz (2 cores)<p>Single-Core Score 1195 Multi-Core Score 2569，TDP15w<h2 id=小米-mi8，2018><a title="小米 mi8，2018" class=headerlink href=#小米-mi8，2018></a>小米 mi8，2018</h2><p>Snapdragon 845 2649 MHz (8 cores)<p>Single-Core Score 474 Multi-Core Score 1921<h2 id=ipad-mini5，2019><a title="ipad mini5，2019" class=headerlink href=#ipad-mini5，2019></a>ipad mini5，2019</h2><p>Apple A12 Bionic 2490 MHz (6 cores)<p>Single-Core Score 1294 Multi-Core Score 2662<h2 id=iphone14，2022><a class=headerlink href=#iphone14，2022 title=iphone14，2022></a>iphone14，2022</h2><p>Apple A15 Bionic 3230 MHz (6 cores)<p>Single-Core Score 2222 Multi-Core Score 5538</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2024/04/13/%E5%86%99%E5%86%99GBDT%E5%90%A7/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2024/04/13/%E5%86%99%E5%86%99GBDT%E5%90%A7/ itemprop=url>GBDT和xgboost</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2024-04-13 12:05:02" datetime=2024-04-13T12:05:02+00:00>2024-04-13</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2025-10-26 07:33:23" datetime=2025-10-26T07:33:23+00:00 itemprop=dateModified>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E6%8E%A8%E8%8D%90/ itemprop=url rel=index><span itemprop=name>推荐</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><blockquote><p>在浮躁的LLM时代，仍然坚持古法建模，致敬xgb匠人</blockquote><h1 id=单棵树><a class=headerlink href=#单棵树 title=单棵树></a>单棵树</h1><ul><li>ID3 算法中根据特征选择和信息增益评估，每次选择信息增益最大的特征作为分支标准<li>C4.5 使用“增益率”（gain ratio）来选择最优的分支标准<li>CART 的分支标准建立在 GINI 指数上，GINI 值越大表明样本集合的类别越杂乱</ul><h1 id=GBDT><a class=headerlink href=#GBDT title=GBDT></a>GBDT</h1><ul><li>先有BT（boosting tree）（相比随机森林是stacking）<li>随后有了GBT，gradient boosting tree，又可分为GBDT和GBRT，分类数和回归树<li>核心思想是<strong>利用损失函数的负梯度在当前模型的值作为残差的近似值</strong>，本质上是对损失函数进行一阶泰勒展开，从而拟合一个回归树</ul><p>$$<br>L(y,f_t) = L(y,f_{t-1}+h_t)=L(y,f_{t-1})+\frac{\partial L(y, f_{t-1})}{\partial f_{t-1}}h_t<br>$$<ul><li>对于mse loss，$\Delta L=L(y,f_t)-L(y,f_{t-1})=\frac{\partial L(y, f_{t-1})}{\partial f_{t-1}}h_k$ ，所以$h_k=-\frac{\partial L(y, f_{t-1})}{\partial f_{t-1}}$，负梯度也就是残差<li>对于log loss，<a href=https://zhuanlan.zhihu.com/p/388225723>我没看懂</a></ul><h1 id=xgboost><a class=headerlink href=#xgboost title=xgboost></a>xgboost</h1><blockquote><p>主要<del>参考</del>自<a href=https://juejin.cn/post/6963993583217016869>这里</a>，<a href=https://arxiv.org/pdf/1603.02754.pdf>原论文</a></blockquote><p>然后才进化出了xgb，有几个改进点<ul><li>加了正则项，包含树的节点数，权重<li>一阶泰勒变成了二阶<li>一些实现上的优化，缺失值、分裂点</ul><p>损失函数定位为：<br>$$<br>L = \sum_il(f_i,y_i)+\sum\Omega(f) \<br>\Omega(f)= \gamma T+\frac{1}{2}\lambda \lVert \omega \rVert ^2<br>$$<br>$\Omega$中，$T$表示节点个数，$\omega$表示叶子节点的值，loss里直接包含了正则想，相比GBDT更不同意过拟合<p>对$L$进行二阶展开，<br>$$<br>L=\sum_i[l(y_i,f_i^{t-1})+g_if_i^t+\frac{1}{2}h_i(f_i^t)^2]+\sum\Omega(f)<br>$$<br>这里$g_i=\frac{\partial l(y_i,f_i^{t-1})}{\partial f_i^{t-1}}$，$h_i=\frac{\partial ^2 l(y_i,f_i^{t-1})}{\partial ^2 f_i^{t-1}}$，即$l(y_i,f_i^{t-1})$对$ f_i^{t-1}$的一阶导数和二阶导数。利用泰勒展开式，这里将损失函数转化成了一个二次函数，而且这里二次项的系数为正，可以很方便的求得函数的最小值<p>简单一点，相对于$ f^{t}$是常数项的部分去掉<br>$$<br>L=\sum_i[g_if_i^t+\frac{1}{2}h_i(f_i^t)^2]+\sum\Omega(f^t)<br>$$<br>决定$ f^{t}$的主要是两个纬度，一是这颗树的形态，二是树的叶子节点的权重。这里用数学表达式来表示就是<br>$$<br>\sum_if_i^t=\sum_{j=1}^T\sum _{i\in I_j} \omega_j<br>$$<br>等式左边的意义很明显，就是所有样本在第$t$棵树上输出的和，等式右边用另一种方式表达了这个值，第一个求和符号表示所有的叶子节点，第二个求和符号表示被分到每个叶子节点的样本集合，$i\in I_j$表示被分到第$j$个叶子节点的样本集合。$\omega_j$代表第$j$个叶子节点的权重。可以这么理解，样本分到哪一个叶子节点上表示了树的结构。<p>把这个细化的表达式带入到泰勒展开近似的损失函数中得到，<br>$$<br>L=\sum_{j=1}^T[(\sum _{i\in I_j} g_i)\omega_j+\frac{1}{2}(\sum _{i\in I_j}h_i+\lambda)\omega_j^2]+\gamma T<br>$$<br>给定树的结构下<br>$$<br>\omega_j^*=\frac{\sum _{i\in I_j} g_i}{\sum _{i\in I_j}h_i+\lambda}<br>$$<h2 id=怎么确定树的结构><a class=headerlink href=#怎么确定树的结构 title=怎么确定树的结构></a>怎么确定树的结构</h2><p>答案是枚举，在一个节点那里想要做分裂节点的操作，哪些样本要分到左边，哪些节点要分到右边，XGBoost就把所有的样本按某个特征排序，然后切分，以此确定树的结构，枚举下来算出最小损失值，就作为最优结构。<ul><li><p>当新引入的一次分裂所带来的增益Gain&LT0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。</p><li><p>当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。</p><li><p>当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。</p></ul><h2 id=实现上的一些优化（xgb为什么快）：><a class=headerlink href=#实现上的一些优化（xgb为什么快）： title=实现上的一些优化（xgb为什么快）：></a>实现上的一些优化（xgb为什么快）：</h2><ul><li><p>对每个特征的分割决策使用并行策略：首先把每个特征都排序，因为对特征在不同的位置进行分割是独立的，所以可以使用并行的线程进行计算，从而加速训练的速度。</p><li><p>梯度数据缓存策略：会把需要的梯度数据放到一个额外的内存里，使用预取和缓存的方式来提高缓存的命中率，从而提升数据IO的速度。</p><li><p>去中心化内存策略：为了实现去中心化的计算，将数据分割成不同的块，然后将所有块存储在磁盘上。在计算过程中，利用一个单独的线程来预取磁盘中的数据，保证运算和取数据可以同时发生。</p></ul><h2 id=怎么方式过拟合><a class=headerlink href=#怎么方式过拟合 title=怎么方式过拟合></a>怎么方式过拟合</h2><ul><li>正则项：叶子节点个数+叶子节点权重的L2正则化<li>列抽样：训练的时候只用一部分特征(只考虑一个block,不考虑剩余的Block块即可)<li>子采样：每轮计算可以不使用全部样本，随机抽取部分样本，因此算法鲁棒性更强<li>系数衰减：学习率/步长,为了给后面的训练留出更多的学习空间。</ul><h2 id=和GBDT的差别><a class=headerlink href=#和GBDT的差别 title=和GBDT的差别></a>和GBDT的差别</h2><ul><li><strong>基分类器</strong>：传统GBDT以<a href=https://link.zhihu.com/?target=https://www.cnblogs.com/wqbin/p/11689709.html>CART</a>树作为基分类器，xgboost还支持线性分类器。<li><strong>导数</strong>：传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。同时xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。<li>正则项/列抽样/系数衰减的防止过拟合方法<li><strong>并行</strong>：xgboost的并行不是树粒度的并行，而是在特征粒度上的。决策树的学习最耗时步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。<li><strong>可并行的近似直方图算法</strong>。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</ul><h2 id=为什么有时候不如LR><a class=headerlink href=#为什么有时候不如LR title=为什么有时候不如LR></a>为什么有时候不如LR</h2><ul><li>在高维稀疏特征的时候，线性模型会比非线性模型好：<strong>带正则化的线性模型比较不容易对稀疏特征过拟合。</strong></ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><nav class=pagination><span class="page-number current">1</span><a class=page-number href=/page/2/>2</a><span class=space>…</span><a class=page-number href=/page/8/>8</a><a class="extend next" aria-label=下一页 href=/page/2/ rel=next title=下一页><i class="fa fa-angle-right"></i></a></nav></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>翟大翟</span></div><div class=powered-by>由 <a href=https://hexo.io/ rel=noopener target=_blank>Hexo</a> & <a href=https://theme-next.js.org/ rel=noopener target=_blank>NexT.Gemini</a> 强力驱动</div></div></footer><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script crossorigin integrity=sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY= src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script crossorigin integrity=sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8= src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js></script><script crossorigin integrity=sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc= src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script src=/js/comments.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/next-boot.js></script><script crossorigin integrity=sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc= src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script src=/js/third-party/search/local-search.js></script><script class=next-config data-name=enableMath type=application/json>true</script><script class=next-config data-name=mathjax type=application/json>{"enable":true,"tags":"none","single_dollars":true,"normal_width":0.6,"cjk_width":0.9,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src=/js/third-party/math/mathjax.js></script>