<!doctypehtml><html lang=zh-CN><meta charset=UTF-8><meta content=width=device-width name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.0.0" name=generator><link href=/images/apple-touch-icon-next.png rel=apple-touch-icon sizes=180x180><link href=/images/favicon-32x32-next.png rel=icon sizes=32x32 type=image/png><link href=/images/favicon-16x16-next.png rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg rel=mask-icon><style>:root{--body-bg-color:#eee;--content-bg-color:#fff;--card-bg-color:#f5f5f5;--text-color:#555;--blockquote-color:#666;--link-color:#555;--link-hover-color:#222;--brand-color:#fff;--brand-hover-color:#fff;--table-row-odd-bg-color:#f9f9f9;--table-row-hover-bg-color:#f5f5f5;--menu-item-bg-color:#f5f5f5;--theme-color:#222;--btn-default-bg:#fff;--btn-default-color:#555;--btn-default-border-color:#555;--btn-default-hover-bg:#222;--btn-default-hover-color:#fff;--btn-default-hover-border-color:#222;--highlight-background:#f3f3f3;--highlight-foreground:#444;--highlight-gutter-background:#e1e1e1;--highlight-gutter-foreground:#555;color-scheme:light}html{line-height:1.15;-webkit-text-size-adjust:100%}details,main{display:block}pre{font-size:1em;overflow:auto;padding:10px}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}.table-container,textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}summary{display:list-item}[hidden],template{display:none}::selection{background:#262a30;color:#eee}body,html{height:100%}body{margin:0;background:var(--body-bg-color);box-sizing:border-box;color:var(--text-color);font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1em;line-height:2;min-height:100%;position:relative;transition:padding .2s ease-in-out}h1,h2,h3,h4,h5,h6{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-weight:700;line-height:1.5;margin:30px 0 15px}h1{font-size:1.5em}h2{font-size:1.375em}h3{font-size:1.25em}h4{font-size:1.125em}h5{font-size:1em}h6{font-size:.875em}p{margin:0 0 20px}a{background:0 0;border-bottom:1px solid #999;color:var(--link-color);cursor:pointer;outline:0;text-decoration:none;overflow-wrap:break-word}a:hover{border-bottom-color:var(--link-hover-color);color:var(--link-hover-color)}embed,iframe,img,video{display:block;margin-left:auto;margin-right:auto;max-width:100%}hr{box-sizing:content-box;overflow:visible;background-image:repeating-linear-gradient(-45deg,#ddd,#ddd 4px,transparent 4px,transparent 8px);border:0;height:3px;margin:40px 0}blockquote{border-left:4px solid #ddd;color:var(--blockquote-color);margin:0;padding:0 15px}blockquote cite::before{content:'-';padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}table{border-collapse:collapse;border-spacing:0;font-size:.875em;margin:0 0 20px;width:100%}tbody tr:nth-of-type(odd){background:var(--table-row-odd-bg-color)}tbody tr:hover{background:var(--table-row-hover-bg-color)}caption,td,th{padding:8px}td,th{border:1px solid #ddd;border-bottom:3px solid #ddd}th{font-weight:700;padding-bottom:10px}td{border-bottom-width:1px}.btn{background:var(--btn-default-bg);border:2px solid var(--btn-default-border-color);border-radius:2px;color:var(--btn-default-color);display:inline-block;font-size:.875em;line-height:2;padding:0 20px;transition:background-color .2s ease-in-out}.btn:hover{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{text-align:left;width:1.285714285714286em}.toggle{line-height:0}.toggle .toggle-line{background:#fff;display:block;height:2px;left:0;position:relative;top:0;transition:.4s;width:100%}.toggle .toggle-line:first-child{margin-top:1px}.toggle .toggle-line:not(:first-child){margin-top:4px}.toggle.toggle-arrow :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}.toggle.toggle-arrow :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}.toggle.toggle-close :nth-child(2){opacity:0}.toggle.toggle-close :first-child{top:6px;transform:rotate(45deg)}.toggle.toggle-close :last-child{top:-6px;transform:rotate(-45deg)}/*!
  Theme: Default
  Description: Original highlight.js style
  Author: (c) Ivan Sagalaev <maniac@softwaremaniacs.org>
  Maintainer: @highlightjs/core-team
  Website: https://highlightjs.org/
  License: see project LICENSE
  Touched: 2021
*/pre code.hljs{display:block;overflow-x:auto;padding:1em}code.hljs{padding:3px 5px}.hljs{background:#f3f3f3;color:#444}.hljs-comment{color:#697070}.hljs-punctuation,.hljs-tag{color:#444a}.hljs-tag .hljs-attr,.hljs-tag .hljs-name{color:#444}.hljs-attribute,.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-name,.hljs-selector-tag{font-weight:700}.hljs-deletion,.hljs-number,.hljs-quote,.hljs-selector-class,.hljs-selector-id,.hljs-string,.hljs-template-tag,.hljs-type{color:#800}.hljs-section,.hljs-title{color:#800;font-weight:700}.hljs-link,.hljs-operator,.hljs-regexp,.hljs-selector-attr,.hljs-selector-pseudo,.hljs-symbol,.hljs-template-variable,.hljs-variable{color:#ab5656}.hljs-literal{color:#695}.hljs-addition,.hljs-built_in,.hljs-bullet,.hljs-code{color:#397300}.hljs-meta{color:#1f7199}.hljs-meta .hljs-string{color:#38a}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}code,figure.highlight,kbd,pre{background:var(--highlight-background);color:var(--highlight-foreground)}figure.highlight,pre{line-height:1.6;margin:0 auto 20px}figure.highlight figcaption,pre .caption,pre figcaption{background:var(--highlight-gutter-background);color:var(--highlight-foreground);display:flow-root;font-size:.875em;line-height:1.2;padding:.5em}figure.highlight figcaption a,pre .caption a,pre figcaption a{color:var(--highlight-foreground);float:right}figure.highlight figcaption a:hover,pre .caption a:hover,pre figcaption a:hover{border-bottom-color:var(--highlight-foreground)}code,pre{font-family:consolas,Menlo,monospace,'PingFang SC','Microsoft YaHei'}code{border-radius:3px;font-size:.875em;padding:2px 4px;overflow-wrap:break-word}kbd{border:2px solid #ccc;border-radius:.2em;box-shadow:.1em .1em .2em rgba(0,0,0,.1);font-family:inherit;padding:.1em .3em;white-space:nowrap}figure.highlight{overflow:auto;position:relative}figure.highlight pre{border:0;margin:0;padding:10px 0}figure.highlight table{border:0;margin:0;width:auto}figure.highlight td{border:0;padding:0}figure.highlight .gutter{-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none}figure.highlight .gutter pre{background:var(--highlight-gutter-background);color:var(--highlight-gutter-foreground);padding-left:10px;padding-right:10px;text-align:right}figure.highlight .code pre{padding-left:10px;width:100%}figure.highlight .marked{background:rgba(0,0,0,.3)}pre .caption,pre figcaption{margin-bottom:10px}.gist table{width:auto}.gist table td{border:0}pre code{background:0 0;padding:0;text-shadow:none}.blockquote-center{border-left:0;margin:40px 0;padding:0;position:relative;text-align:center}.blockquote-center::after,.blockquote-center::before{left:0;line-height:1;opacity:.6;position:absolute;width:100%}.blockquote-center::before{border-top:1px solid #ccc;text-align:left;top:-20px;content:'\f10d';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center::after{border-bottom:1px solid #ccc;bottom:-20px;text-align:right;content:'\f10e';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center div,.blockquote-center p{text-align:center}.group-picture{margin-bottom:20px}.group-picture .group-picture-row{display:flex;gap:3px;margin-bottom:3px}.group-picture .group-picture-column{flex:1}.group-picture .group-picture-column img{height:100%;margin:0;object-fit:cover;width:100%}.post-body .label{color:#555;padding:0 2px}.post-body .label.default{background:#f0f0f0}.post-body .label.primary{background:#efe6f7}.post-body .label.info{background:#e5f2f8}.post-body .label.success{background:#e7f4e9}.post-body .label.warning{background:#fcf6e1}.post-body .label.danger{background:#fae8eb}.post-body .link-grid{display:grid;grid-gap:1.5rem;gap:1.5rem;grid-template-columns:1fr 1fr;margin-bottom:20px;padding:1rem}.post-body .link-grid .link-grid-container{border:solid #ddd;box-shadow:1rem 1rem .5rem rgba(0,0,0,.5);min-height:5rem;min-width:0;padding:.5rem;position:relative;transition:background .3s}.post-body .link-grid .link-grid-container:hover{animation:.5s next-shake;background:var(--card-bg-color)}.post-body .link-grid .link-grid-container:active{box-shadow:.5rem .5rem .25rem rgba(0,0,0,.5);transform:translate(.2rem,.2rem)}.post-body .link-grid .link-grid-container .link-grid-image{border:1px solid #ddd;border-radius:50%;box-sizing:border-box;height:5rem;padding:3px;position:absolute;width:5rem}.post-body .link-grid .link-grid-container p{margin:0 1rem 0 6rem}.post-body .link-grid .link-grid-container p:first-of-type{font-size:1.2em}.post-body .link-grid .link-grid-container p:last-of-type{font-size:.8em;line-height:1.3rem;opacity:.7}.post-body .link-grid .link-grid-container a{border:0;height:100%;left:0;position:absolute;top:0;width:100%}@keyframes next-shake{0%{transform:translate(1pt,1pt) rotate(0)}10%{transform:translate(-1pt,-2pt) rotate(-1deg)}20%{transform:translate(-3pt,0) rotate(1deg)}30%{transform:translate(3pt,2pt) rotate(0)}40%{transform:translate(1pt,-1pt) rotate(1deg)}50%{transform:translate(-1pt,2pt) rotate(-1deg)}60%{transform:translate(-3pt,1pt) rotate(0)}70%{transform:translate(3pt,1pt) rotate(-1deg)}80%{transform:translate(-1pt,-1pt) rotate(1deg)}90%{transform:translate(1pt,2pt) rotate(0)}100%{transform:translate(1pt,-2pt) rotate(-1deg)}}.post-body .note{border-radius:3px;margin-bottom:20px;padding:1em;position:relative;border:1px solid #eee;border-left-width:5px}.post-body .note summary{cursor:pointer;outline:0}.post-body .note summary p{display:inline}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{border-bottom:initial;margin:0;padding-top:0}.post-body .note :first-child{margin-top:0}.post-body .note :last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .tabs{margin-bottom:20px}.post-body .tabs,.tabs-comment{padding-top:10px}.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{background:var(--content-bg-color);display:flex;display:flex;flex-wrap:wrap;justify-content:center;margin:0;padding:0;position:-webkit-sticky;position:sticky;top:0;z-index:5}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid #ddd;border-left:1px solid transparent;border-right:1px solid transparent;border-radius:0;border-top:3px solid transparent;flex-grow:1;list-style-type:none}@media (max-width:413px){.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{display:block;margin-bottom:5px}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid transparent;border-left:3px solid transparent;border-right:1px solid transparent;border-top:1px solid transparent;border-radius:0}}.post-body .tabs ul.nav-tabs li.tab a,.tabs-comment ul.nav-tabs li.tab a{border-bottom:initial;display:block;line-height:1.8;padding:.25em .75em;text-align:center;transition:.2s ease-out}.post-body .tabs ul.nav-tabs li.tab a i[class^=fa],.tabs-comment ul.nav-tabs li.tab a i[class^=fa]{width:1.285714285714286em}.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#fc6423 #ddd transparent}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#ddd #ddd #ddd #fc6423}}.post-body .tabs ul.nav-tabs li.tab.active a,.tabs-comment ul.nav-tabs li.tab.active a{cursor:default}.post-body .tabs .tab-content,.tabs-comment .tab-content{border:1px solid #ddd;border-radius:0;border-top-color:transparent}@media (max-width:413px){.post-body .tabs .tab-content,.tabs-comment .tab-content{border-radius:0;border-top-color:#ddd}}.post-body .tabs .tab-content .tab-pane,.tabs-comment .tab-content .tab-pane{padding:20px 20px 0}.post-body .tabs .tab-content .tab-pane:not(.active),.tabs-comment .tab-content .tab-pane:not(.active){display:none}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{display:inline-block;margin:-1px 10px 0;padding:0 10px}.pagination .page-number.current{background:#ccc;border-color:#ccc;color:var(--content-bg-color)}.pagination{border-top:1px solid #eee;margin:120px 0 0;text-align:center}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:0;border-top:1px solid #eee;transition:border-color .2s ease-in-out}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:var(--link-hover-color)}@media (max-width:767px){.post-body .link-grid{grid-template-columns:1fr}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}.pagination{border-top:0}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:1px solid #eee;border-top:0}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:var(--link-hover-color)}.site-meta{text-align:center}}.pagination .space{margin:0;padding:0}.comments{margin-top:60px;overflow:hidden}.comment-button-group{display:flex;display:flex;flex-wrap:wrap;justify-content:center;justify-content:center;margin:1em 0}.comment-button-group .comment-button{margin:.1em .2em}.comment-button-group .comment-button.active{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.comment-position{display:none}.comment-position.active{display:block}.tabs-comment{margin-top:4em;padding-top:0}.tabs-comment .comments{margin-top:0;padding-top:0}.headband{background:var(--theme-color);height:3px}@media (max-width:991px){.headband{display:none}}.site-brand-container{display:flex;flex-shrink:0;padding:0 10px}.use-motion .column,.use-motion .site-brand-container .toggle{opacity:0}.site-meta{flex-grow:1;text-align:center}.custom-logo-image{margin-top:20px}@media (max-width:991px){.custom-logo-image{display:none}}.brand{border-bottom:0;color:var(--brand-color);display:inline-block;padding:0}.brand:hover{color:var(--brand-hover-color)}.site-title{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1.375em;font-weight:400;line-height:1.5;margin:0}.site-subtitle{color:#ddd;font-size:.8125em;margin:10px 10px 0}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-right,.site-nav-toggle{display:none}.site-nav-right .toggle,.site-nav-toggle .toggle{color:var(--text-color);padding:10px;width:22px}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:var(--text-color);border-radius:1px}@media (max-width:767px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu{margin:0;padding:1em 0;text-align:center}.menu-item{display:inline-block;list-style:none;margin:0 10px}@media (max-width:767px){.menu-item{display:block;margin-top:10px}.menu-item.menu-item-search{display:none}}.menu-item a{border-bottom:0;display:block;font-size:.8125em;transition:border-color .2s ease-in-out}.menu-item a.menu-item-active,.menu-item a:hover{background:var(--menu-item-bg-color)}.menu-item i[class^=fa]{margin-right:8px}.menu-item .badge{display:inline-block;font-weight:700;line-height:1;margin-left:.35em;margin-top:.35em;text-align:center;white-space:nowrap}.use-motion .menu-item{visibility:hidden}.sidebar-inner{color:#999;padding:18px 10px;text-align:center;display:flex;flex-direction:column;justify-content:center}.cc-license .cc-opacity{border-bottom:0;opacity:.7}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}.site-author-image{border:1px solid #eee;max-width:120px;padding:2px}.site-author-name{color:var(--text-color);font-weight:600;margin:0}.site-description{color:#999;font-size:.8125em;margin-top:0}.links-of-author a{font-size:.8125em}.links-of-author i[class^=fa]{margin-right:2px}.sidebar .sidebar-button:not(:first-child){margin-top:15px}.sidebar .sidebar-button button{background:0 0;cursor:pointer;line-height:2;padding:0 15px;border-radius:4px}.sidebar .sidebar-button button i[class^=fa]{margin-right:5px}.links-of-blogroll{font-size:.8125em}.links-of-blogroll-title{font-size:.875em;font-weight:600}.links-of-blogroll-list{list-style:none;margin:0;padding:0}.sidebar-nav{font-size:.875em;height:0;margin:0;overflow:hidden;padding-left:0;pointer-events:none;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}.sidebar-nav-active .sidebar-nav{height:calc(2em + 1px);pointer-events:unset;visibility:unset}.sidebar-nav li{border-bottom:1px solid transparent;color:var(--text-color);cursor:pointer;display:inline-block;transition:border-bottom-color .2s ease-in-out,color .2s ease-in-out}.sidebar-nav li.sidebar-nav-overview{margin-left:10px}.sidebar-nav li:hover{color:#fc6423}.sidebar-overview-active .sidebar-nav-overview,.sidebar-toc-active .sidebar-nav-toc{border-bottom-color:#fc6423;color:#fc6423;transition-delay:0.2s}.sidebar-overview-active .sidebar-nav-overview:hover,.sidebar-toc-active .sidebar-nav-toc:hover{color:#fc6423}.sidebar-panel-container{align-items:start;display:grid;flex:1;overflow-x:hidden;overflow-y:auto;padding-top:0;transition:padding-top .2s ease-in-out}.sidebar-nav-active .sidebar-panel-container{padding-top:20px}.sidebar-panel{animation:.2s ease-in-out deactivate-sidebar-panel;grid-area:1/1;height:0;opacity:0;overflow:hidden;pointer-events:none;transform:translateY(0);transition:.2s ease-in-out;transition-property:opacity,transform,visibility;visibility:hidden}.sidebar-nav-active .sidebar-panel,.sidebar-overview-active .sidebar-panel.post-toc-wrap{transform:translateY(-20px)}.sidebar-overview-active:not(.sidebar-nav-active) .sidebar-panel.post-toc-wrap{transition-delay:0s,0.2s,0s}.sidebar-overview-active .sidebar-panel.site-overview-wrap,.sidebar-toc-active .sidebar-panel.post-toc-wrap{animation-name:activate-sidebar-panel;height:auto;opacity:1;pointer-events:unset;transform:translateY(0);transition-delay:0.2s,0.2s,0s;visibility:unset}.sidebar-panel.site-overview-wrap{display:flex;flex-direction:column;justify-content:center;gap:10px;justify-content:flex-start}@keyframes deactivate-sidebar-panel{from{height:var(--inactive-panel-height,0)}to{height:var(--active-panel-height,0)}}@keyframes activate-sidebar-panel{from{height:var(--inactive-panel-height,auto)}to{height:var(--active-panel-height,auto)}}.sidebar-toggle{bottom:61px;height:16px;padding:5px;width:16px;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;right:30px}.sidebar-toggle:hover{opacity:.8}@media (max-width:991px){.sidebar-toggle{right:20px;opacity:.8}}.sidebar-toggle:hover .toggle-line{background:#fc6423}@media (any-hover:hover){body:not(.sidebar-active) .sidebar-toggle:hover :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}body:not(.sidebar-active) .sidebar-toggle:hover :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}}.sidebar-active .sidebar-toggle :nth-child(2){opacity:0}.sidebar-active .sidebar-toggle :first-child{top:6px;transform:rotate(45deg)}.sidebar-active .sidebar-toggle :last-child{top:-6px;transform:rotate(-45deg)}.post-toc{font-size:.875em}.post-toc ol{list-style:none;margin:0;padding:0 2px 0 10px;text-align:left}.post-toc ol>:last-child{margin-bottom:5px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition:.2s ease-in-out}.post-toc .nav-item{line-height:1.8;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.post-toc .nav .nav-child{--height:0;height:0;opacity:0;overflow:hidden;transition:.2s ease-in-out;visibility:hidden}.post-toc .nav .active>.nav-child{height:var(--height,auto);opacity:1;visibility:unset}.post-toc .nav .active>a{border-bottom-color:#fc6423;color:#fc6423}.post-toc .nav .active-current>a,.post-toc .nav .active-current>a:hover{color:#fc6423}.site-state{display:flex;flex-wrap:wrap;justify-content:center;line-height:1.4}.site-state-item a{border-bottom:0;display:block}.site-state-item-count{display:block;font-size:1em;font-weight:600}.site-state-item-name{color:#999;font-size:.8125em}.footer{color:#999;font-size:.875em;padding:20px 0;transition:left .2s ease-in-out,right .2s ease-in-out}.footer.footer-fixed{bottom:0;left:0;position:absolute;right:0}.footer-inner{box-sizing:border-box;text-align:center;display:flex;flex-direction:column;justify-content:center;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.menu-item .badge{float:right;margin-left:0}.footer-inner{width:auto}}@media (min-width:1200px){.footer-inner{width:1160px}}@media (min-width:1600px){.footer-inner{width:73%}}.use-motion .footer{opacity:0}.languages{display:inline-block;font-size:1.125em;position:relative}.languages .lang-select-label span{margin:0 .5em}.languages .lang-select{height:100%;left:0;opacity:0;position:absolute;top:0;width:100%}.with-love{color:red;display:inline-block;margin:0 5px}@keyframes icon-animate{0%,100%{transform:scale(1)}10%,30%{transform:scale(.9)}20%,40%,50%,60%,70%,80%{transform:scale(1.1)}}.back-to-top{font-size:12px;align-items:center;bottom:-100px;color:#fff;display:flex;height:26px;transition:bottom .2s ease-in-out;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;right:30px}.back-to-top span{margin-right:8px;display:none}.back-to-top .fa{text-align:center;width:26px}.back-to-top:hover{opacity:.8;color:#fc6423}.back-to-top.back-to-top-on{bottom:30px}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.post-button{margin-top:40px;text-align:center}.use-motion .collection-header,.use-motion .comments,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{visibility:hidden}.posts-collapse .post-content{margin-bottom:35px;margin-left:35px;position:relative}@media (max-width:767px){.posts-collapse .post-content{margin-left:0;margin-right:0}}.posts-collapse .post-content .collection-title{font-size:1.125em;position:relative}.posts-collapse .post-content .collection-title::before{background:#999;border:1px solid #fff;margin-left:-6px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:10px;width:10px}.posts-collapse .post-content .collection-year{font-size:1.5em;font-weight:700;margin:60px 0;position:relative}.posts-collapse .post-content .collection-year::before{background:#bbb;margin-left:-4px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:8px;width:8px}.posts-collapse .post-content .collection-header{display:block;margin-left:20px}.posts-collapse .post-content .collection-header small{color:#bbb;margin-left:5px}.posts-collapse .post-content .post-header{border-bottom:1px dashed #ccc;margin:30px 2px 0;padding-left:15px;position:relative;transition:border .2s ease-in-out}.posts-collapse .post-content .post-header::before{background:#bbb;border:1px solid #fff;left:-6px;position:absolute;top:.75em;transition:background .2s ease-in-out;border-radius:50%;content:' ';height:6px;width:6px}.posts-collapse .post-content .post-header:hover{border-bottom-color:#666}.posts-collapse .post-content .post-header:hover::before{background:#222}.posts-collapse .post-content .post-meta-container{display:inline;font-size:.75em;margin-right:10px}.posts-collapse .post-content .post-title{display:inline}.posts-collapse .post-content .post-title a{border-bottom:0;color:var(--link-color)}.posts-collapse .post-content::before{background:#f5f5f5;content:' ';height:100%;margin-left:-2px;position:absolute;top:1.25em;width:4px}.post-body{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;overflow-wrap:break-word}@media (min-width:1200px){.post-body{font-size:1.125em}}@media (min-width:992px){.post-body{text-align:justify}}.post-body h1 .header-anchor,.post-body h1 .headerlink,.post-body h2 .header-anchor,.post-body h2 .headerlink,.post-body h3 .header-anchor,.post-body h3 .headerlink,.post-body h4 .header-anchor,.post-body h4 .headerlink,.post-body h5 .header-anchor,.post-body h5 .headerlink,.post-body h6 .header-anchor,.post-body h6 .headerlink{border-bottom-style:none;color:inherit;float:right;font-size:.875em;margin-left:10px;opacity:0}.post-body h1 .header-anchor::before,.post-body h1 .headerlink::before,.post-body h2 .header-anchor::before,.post-body h2 .headerlink::before,.post-body h3 .header-anchor::before,.post-body h3 .headerlink::before,.post-body h4 .header-anchor::before,.post-body h4 .headerlink::before,.post-body h5 .header-anchor::before,.post-body h5 .headerlink::before,.post-body h6 .header-anchor::before,.post-body h6 .headerlink::before{content:'\f0c1';font-family:'Font Awesome 6 Free';font-weight:900}.post-body h1:hover .header-anchor,.post-body h1:hover .headerlink,.post-body h2:hover .header-anchor,.post-body h2:hover .headerlink,.post-body h3:hover .header-anchor,.post-body h3:hover .headerlink,.post-body h4:hover .header-anchor,.post-body h4:hover .headerlink,.post-body h5:hover .header-anchor,.post-body h5:hover .headerlink,.post-body h6:hover .header-anchor,.post-body h6:hover .headerlink{opacity:.5}.post-body h1:hover .header-anchor:hover,.post-body h1:hover .headerlink:hover,.post-body h2:hover .header-anchor:hover,.post-body h2:hover .headerlink:hover,.post-body h3:hover .header-anchor:hover,.post-body h3:hover .headerlink:hover,.post-body h4:hover .header-anchor:hover,.post-body h4:hover .headerlink:hover,.post-body h5:hover .header-anchor:hover,.post-body h5:hover .headerlink:hover,.post-body h6:hover .header-anchor:hover,.post-body h6:hover .headerlink:hover{opacity:1}.post-body .exturl .fa{font-size:.875em;margin-left:4px}.post-body .fancybox+figcaption,.post-body img+figcaption{color:#999;font-size:.875em;font-weight:700;line-height:1;margin:-15px auto 15px;text-align:center}.post-body embed,.post-body iframe,.post-body img,.post-body video{margin-bottom:20px}.post-body .video-container{height:0;margin-bottom:20px;overflow:hidden;padding-top:75%;position:relative;width:100%}.post-body .video-container embed,.post-body .video-container iframe,.post-body .video-container object{height:100%;left:0;margin:0;position:absolute;top:0;width:100%}.post-gallery{display:flex;min-height:200px}.post-gallery .post-gallery-image{flex:1}.post-gallery .post-gallery-image:not(:first-child){clip-path:polygon(40px 0,100% 0,100% 100%,0 100%);margin-left:-20px}.post-gallery .post-gallery-image:not(:last-child){margin-right:-20px}.post-gallery .post-gallery-image img{height:100%;object-fit:cover;opacity:1;width:100%}.posts-expand .post-gallery{margin-bottom:60px}.posts-collapse .post-gallery{margin:15px 0}.posts-expand .post-header{font-size:1.125em;margin-bottom:60px;text-align:center}.posts-expand .post-title{font-size:1.5em;font-weight:400;margin:initial;overflow-wrap:break-word}.posts-expand .post-title-link{border-bottom:0;color:var(--link-color);display:inline-block;position:relative}.posts-expand .post-title-link::before{background:var(--link-color);bottom:0;content:'';height:2px;left:0;position:absolute;transform:scaleX(0);transition:transform .2s ease-in-out;width:100%}.posts-expand .post-title-link:hover::before{transform:scaleX(1)}.posts-expand .post-title-link .fa{font-size:.875em;margin-left:5px}.post-sticky-flag{display:inline-block;margin-right:8px;transform:rotate(30deg)}.posts-expand .post-meta-container{color:#999;font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:.75em;margin-top:3px}.posts-expand .post-meta-container .post-description{font-size:.875em;margin-top:2px}.posts-expand .post-meta-container time{border-bottom:1px dashed #999}.post-meta{display:flex;flex-wrap:wrap;justify-content:center}:not(.post-meta-break)+.post-meta-item::before{content:'|';margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (max-width:991px){.back-to-top{right:20px;opacity:.8}.post-body{text-align:justify}.post-meta-item-text{display:none}}.post-meta-break{flex-basis:100%;height:0}.post-nav{border-top:1px solid #eee;display:flex;gap:30px;justify-content:space-between;margin-top:1em;padding:10px 5px 0}.post-nav-item{flex:1}.post-nav-item a{border-bottom:0;display:block;font-size:.875em;line-height:1.6}.post-nav-item a:active{top:2px}.post-nav-item .fa{font-size:.75em}.post-nav-item:first-child .fa{margin-right:5px}.post-nav-item:last-child{text-align:right}.post-nav-item:last-child .fa{margin-left:5px}.post-footer{display:flex;flex-direction:column;justify-content:center}.post-eof{background:#ccc;height:1px;margin:80px auto 60px;width:8%}.post-block:last-of-type .post-eof{display:none}.post-tags{margin-top:40px;text-align:center}.post-tags a{display:inline-block;font-size:.8125em}.post-tags a:not(:last-child){margin-right:10px}.social-like{border-top:1px solid #eee;font-size:.875em;margin-top:1em;padding-top:1em;display:flex;flex-wrap:wrap;justify-content:center}.social-like a{border-bottom:none}.reward-container{margin:1em 0 0;padding:1em 0;text-align:center}.reward-container button{background:0 0;color:#fc6423;cursor:pointer;line-height:2;padding:0 15px;border:2px solid #fc6423;border-radius:2px;outline:0;transition:.2s ease-in-out;vertical-align:text-top}.reward-container button:hover{background:#fc6423;color:#fff}.post-reward{display:none;padding-top:20px}.post-reward.active{display:block}.post-reward div{display:inline-block}.post-reward div span{display:block}.post-reward img{display:inline-block;margin:.8em 2em 0;max-width:100%;width:180px}@keyframes next-roll{from{transform:rotateZ(30deg)}to{transform:rotateZ(-30deg)}}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{list-style:none;margin:0;padding:0}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{color:#bbb}.category-all-page .category-list-count::before{content:' ('}.category-all-page .category-list-count::after{content:') '}.category-all-page .category-list-child{padding-left:10px}.event-list hr{background:#222;margin:20px 0 45px}.event-list hr::after{background:#222;color:#fff;content:'NOW';display:inline-block;font-weight:700;padding:0 5px}.event-list .event{--event-background:#222;--event-foreground:#bbb;--event-title:#fff;background:var(--event-background);padding:15px}.event-list .event .event-summary{border-bottom:0;color:var(--event-title);margin:0;padding:0 0 0 35px;position:relative}.event-list .event .event-summary::before{animation:1s ease-in-out infinite alternate dot-flash;background:var(--event-title);left:0;margin-top:-6px;position:absolute;top:50%;border-radius:50%;content:' ';height:12px;width:12px}.event-list .event:nth-of-type(odd) .event-summary::before{animation-delay:.5s}.event-list .event:not(:last-child){margin-bottom:20px}.event-list .event .event-relative-time{color:var(--event-foreground);display:inline-block;font-size:12px;font-weight:400;padding-left:12px}.event-list .event .event-details{color:var(--event-foreground);display:block;line-height:18px;padding:6px 0 6px 35px}.event-list .event .event-details::before{color:var(--event-foreground);display:inline-block;margin-right:9px;width:14px;font-family:'Font Awesome 6 Free';font-weight:900}.event-list .event .event-details.event-location::before{content:'\f041'}.event-list .event .event-details.event-duration::before{content:'\f017'}.event-list .event .event-details.event-description::before{content:'\f024'}.event-list .event-past{--event-background:#f5f5f5;--event-foreground:#999;--event-title:#222}@keyframes dot-flash{from{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}ul.breadcrumb{font-size:.75em;list-style:none;margin:1em 0;padding:0 2em;text-align:center}ul.breadcrumb li{display:inline}ul.breadcrumb li:not(:first-child)::before{content:'/\00a0';font-weight:400;padding:.5em}ul.breadcrumb li:last-child{font-weight:700}.tag-cloud{text-align:center}.tag-cloud a{display:inline-block;margin:10px}.tag-cloud-0{border-bottom-color:#aaa;color:#aaa}.tag-cloud-1{border-bottom-color:#9a9a9a;color:#9a9a9a}.tag-cloud-2{border-bottom-color:#8b8b8b;color:#8b8b8b}.tag-cloud-3{border-bottom-color:#7c7c7c;color:#7c7c7c}.tag-cloud-4{border-bottom-color:#6c6c6c;color:#6c6c6c}.tag-cloud-5{border-bottom-color:#5d5d5d;color:#5d5d5d}.tag-cloud-6{border-bottom-color:#4e4e4e;color:#4e4e4e}.tag-cloud-7{border-bottom-color:#3e3e3e;color:#3e3e3e}.tag-cloud-8{border-bottom-color:#2f2f2f;color:#2f2f2f}.tag-cloud-9{border-bottom-color:#202020;color:#202020}.tag-cloud-10{border-bottom-color:#111;color:#111}.search-active{overflow:hidden}.search-pop-overlay{background:rgba(0,0,0,0);display:flex;height:100%;left:0;position:fixed;top:0;transition:visibility .4s,background .4s;visibility:hidden;width:100%;z-index:40}.search-active .search-pop-overlay{background:rgba(0,0,0,.3);visibility:visible}.search-popup{background:var(--card-bg-color);border-radius:5px;height:80%;margin:auto;transform:scale(0);transition:transform .4s;width:700px}.search-active .search-popup{transform:scale(1)}@media (max-width:767px){.search-popup{border-radius:0;height:100%;width:100%}}.search-popup .popup-btn-close,.search-popup .search-icon{color:#999;font-size:18px;padding:0 10px}.search-popup .popup-btn-close{cursor:pointer}.search-popup .popup-btn-close:hover .fa{color:#222}.search-popup .search-header{background:#eee;border-top-left-radius:5px;border-top-right-radius:5px;display:flex;padding:5px}.search-popup input.search-input{background:0 0;border:0;outline:0;width:100%}.search-popup input.search-input::-webkit-search-cancel-button{display:none}.search-popup .search-result-container{height:calc(100% - 55px);overflow:auto;padding:5px 25px}.search-popup .search-result-container hr{margin:5px 0 10px}.search-popup .search-result-container hr:first-child{display:none}.search-popup .search-result-list{margin:0 5px;padding:0;width:100%}.search-popup a.search-result-title{font-weight:700}.search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.search-popup .search-input-container{flex-grow:1;padding:2px}.search-popup .no-result{display:flex}.search-popup .search-result-icon{color:#ccc;margin:auto}mark.search-keyword{background:0 0;border-bottom:1px dashed #ff2a2a;color:#ff2a2a;font-weight:700}.has-jax,mjx-container[jax=CHTML][display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}.use-motion .animated{animation-fill-mode:none;visibility:inherit}.use-motion .sidebar .animated{animation-fill-mode:both}header.header{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12)}.main{align-items:stretch;display:flex;justify-content:space-between;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.main{width:auto}}@media (min-width:1200px){.main{width:1160px}}@media (min-width:1600px){.main{width:73%}}@media (max-width:991px){header.header{border-radius:initial}.main{display:block;width:auto}}.main-inner{border-radius:initial;box-sizing:border-box;width:calc(100% - 252px)}.footer-inner{padding-left:252px}@media (max-width:991px){.main-inner{border-radius:initial;width:100%}.footer-inner{padding-left:0;padding-right:0;width:auto}}.column{width:240px}.site-brand-container{background:var(--theme-color)}.site-meta{padding:20px 0}.site-nav-right .toggle,.site-nav-toggle .toggle{color:#fff}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:#fff}@media (min-width:768px) and (max-width:991px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu .menu-item{display:block;margin:0}.menu .menu-item a{padding:5px 20px;position:relative;text-align:left;transition-property:background-color}.menu .menu-item .badge{background:#ccc;border-radius:10px;color:var(--content-bg-color);float:right;padding:2px 5px;text-shadow:1px 1px 0 rgba(0,0,0,.1)}.main-menu .menu-item-active::after{background:#bbb;border-radius:50%;content:' ';height:6px;margin-top:-3px;position:absolute;right:15px;top:50%;width:6px}.sub-menu{margin:0;padding:6px 0}.sub-menu .menu-item{display:inline-block}.sub-menu .menu-item a{background:0 0;margin:5px 10px;padding:initial}.sub-menu .menu-item a:hover{background:0 0;color:#fc6423}.sub-menu .menu-item-active{border-bottom-color:#fc6423;color:#fc6423}.sub-menu .menu-item-active:hover{border-bottom-color:#fc6423}.sidebar{position:-webkit-sticky;position:sticky;top:12px}@media (max-width:991px){.column{width:auto}.site-nav-on .site-brand-container{box-shadow:0 0 16px rgba(0,0,0,.5)}.menu .menu-item.menu-item-search,.sidebar{display:none}}.sidebar-inner{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);box-sizing:border-box;color:var(--text-color);margin-top:12px;max-height:calc(100vh - 24px);visibility:hidden}.site-state-item{padding:0 10px}.sidebar .sidebar-button{border-bottom:1px dotted #ccc;border-top:1px dotted #ccc}.sidebar .sidebar-button button{border:0;color:#fc6423;display:block;width:100%}.sidebar .sidebar-button button:hover{background:0 0;border:0;color:#e34603}.links-of-author{display:flex;flex-wrap:wrap;justify-content:center}.links-of-author-item{margin:5px 0 0;width:50%}.links-of-author-item a{box-sizing:border-box;max-width:100%;overflow:hidden;padding:0 5px;text-overflow:ellipsis;white-space:nowrap;border-bottom:0;border-radius:4px;display:block}.links-of-author-item a:hover{background:var(--body-bg-color)}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .post-block,.main-inner .sub-menu,.main-inner .tabs-comment,.main-inner>.comments{background:var(--content-bg-color);border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12)}.main-inner .post-block:not(:first-child):not(:first-child){border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);margin-top:12px}@media (min-width:768px) and (max-width:991px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:10px}}@media (max-width:767px){.main-inner .post-block:not(:first-child):not(:first-child){margin-top:8px}}.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{border-radius:initial;box-shadow:0 2px 2px 0 rgba(0,0,0,.12),0 3px 1px -2px rgba(0,0,0,.06),0 1px 5px 0 rgba(0,0,0,.12),0 -1px .5px 0 rgba(0,0,0,.09);margin-top:12px}@media (min-width:768px) and (max-width:991px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:10px}}@media (max-width:767px){.main-inner .comment-position .comments,.main-inner .pagination,.main-inner .tabs-comment,.main-inner>.comments{margin-top:8px}}.comments,.post-block{padding:40px}.post-eof{display:none}.pagination{border-top:initial;padding:10px 0}.post-body h1,.post-body h2{border-bottom:1px solid #eee}.post-body h3{border-bottom:1px dotted #eee}@media (min-width:768px) and (max-width:991px){.main-inner{padding:10px}.posts-expand .post-button{margin-top:20px}.post-block{padding:20px}.comments{padding:10px 20px}}@media (max-width:767px){.main-inner{padding:8px}.posts-expand .post-button{margin:12px 0}.post-block{padding:12px}.comments{padding:10px 12px}}</style><link crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css integrity=sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU= rel=stylesheet><link crossorigin href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css integrity=sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE= rel=stylesheet><script class=next-config data-name=main type=application/json>{"hostname":"zjyfdu.coding.me","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}}</script><script src=/js/config.js></script><meta content=website property=og:type><meta content=努力～奋斗～ property=og:title><meta content=https://zjyfdu.coding.me/index.html property=og:url><meta content=努力～奋斗～ property=og:site_name><meta content=zh_CN property=og:locale><meta content=翟大翟 property=article:author><meta content=summary name=twitter:card><link href=https://zjyfdu.coding.me/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script><script class=next-config data-name=calendar type=application/json>""</script><title>努力～奋斗～</title><noscript><link href=/css/noscript.css rel=stylesheet></noscript><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <h1 class=site-title>努力～奋斗～</h1> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-about"><a href=/about/ rel=section><i class="user fa-fw"></i>关于</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="tags fa-fw"></i>标签</a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section><i class="th fa-fw"></i>分类</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="archive fa-fw"></i>归档</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-overview-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=翟大翟 class=site-author-image itemprop=image src=/images/11989810.jpg><p class=site-author-name itemprop=name>翟大翟<div class=site-description itemprop=description></div></div><div class="site-state-wrap animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>74</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/> <span class=site-state-item-count>17</span> <span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>57</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author animated"><span class=links-of-author-item> <a rel="noopener me" title="Github → https://github.com/zjyfdu" href=https://github.com/zjyfdu target=_blank><i class="github fa-fw"></i>Github</a> </span></div></div></div></div></aside></div><div class="main-inner index posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2026/01/02/langchain/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2026/01/02/langchain/ itemprop=url>未命名</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00>2026-01-02</time> </span></div></div></header><div class=post-body itemprop=articleBody></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2026/01/01/longcat-video/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2026/01/01/longcat-video/ itemprop=url>longcat video</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2026-01-01 16:17:46" datetime=2026-01-01T16:17:46+00:00>2026-01-01</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=LongCat-Video技术报告总结><a class=headerlink href=#LongCat-Video技术报告总结 title=LongCat-Video技术报告总结></a>LongCat-Video技术报告总结</h1><p>美团LongCat团队发布的LongCat-Video，是一款参数规模达136亿的视频生成基础模型，核心目标是突破长视频生成的技术瓶颈，为世界模型（World Models）的构建奠定关键能力。该模型通过统一任务架构、优化长视频生成机制、提升推理效率及强化多奖励对齐，在文本转视频（Text-to-Video）、图像转视频（Image-to-Video）、视频续生（Video-Continuation）三大任务中表现优异，尤其能生成数分钟级、无色彩偏移与画质下降的长视频，相关代码与模型权重已开源（GitHub：<a href=https://github.com/meituan-longcat/LongCat-Video%EF%BC%89%E3%80%82>https://github.com/meituan-longcat/LongCat-Video）。</a><h2 id=一、核心背景与技术挑战><a class=headerlink href=#一、核心背景与技术挑战 title=一、核心背景与技术挑战></a>一、核心背景与技术挑战</h2><p>世界模型的核心是理解、模拟并预测复杂现实环境，而视频生成模型通过压缩几何、语义、物理等知识，成为构建世界模型的关键路径。当前视频生成领域虽有Veo（Google）、Sora（OpenAI）等商业模型及Wanx、HunyuanVideo等开源模型，但长视频生成仍面临两大核心挑战：<ul><li><strong>时序一致性缺失</strong>，生成误差随时间累积，导致长视频出现色彩漂移、动作断裂；<li><strong>推理效率低下</strong>，高分辨率（如720p）、高帧率（如30fps）视频的注意力计算复杂度随token数量呈二次增长，难以平衡质量与速度。</ul><h2 id=二、模型核心设计与关键技术><a class=headerlink href=#二、模型核心设计与关键技术 title=二、模型核心设计与关键技术></a>二、模型核心设计与关键技术</h2><h3 id=1-统一任务架构：单模型支持多任务><a title="1. 统一任务架构：单模型支持多任务" class=headerlink href=#1-统一任务架构：单模型支持多任务></a>1. 统一任务架构：单模型支持多任务</h3><p>LongCat-Video基于扩散Transformer（DiT）框架构建，通过“条件帧数量区分任务类型”，实现三大任务的统一：<ul><li>文本转视频（Text-to-Video）：条件帧数量为0，仅依赖文本指令生成视频；<li>图像转视频（Image-to-Video）：条件帧数量为1，基于单张参考图像生成动态视频；<li>视频续生（Video-Continuation）：条件帧数量为多，基于已有视频片段续生长视频。</ul><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br></pre><td class=code><pre><span class=line>┌─────────────────────────────────────────────────────────────────────────┐</span><br><span class=line>│  输入层（Input Layer）                                                   │</span><br><span class=line>│  ├─────────────────────────┬─────────────────────────────────────────────┤</span><br><span class=line>│  │ 视觉输入（Video/Image） │ 文本输入（Text Prompt）                     │</span><br><span class=line>│  │ ┌─────────────────────┐ │ ┌─────────────────────────────────────────┐ │</span><br><span class=line>│  │ │ 1. VAE编码（WAN2.1） │ │ │ 1. 多语言文本编码器（umT5）            │ │</span><br><span class=line>│  │ │ - 像素→ latent tokens │ │ │ - 支持中英双语，输出文本嵌入向量       │ │</span><br><span class=line>│  │ │ - 压缩比：4×8×8（时/高/宽）│ │ │ 2. 文本条件注入：跨注意力层（Cross-Attention） │ │</span><br><span class=line>│  │ │ 2. 二次Patchify压缩    │ │ └─────────────────────────────────────────┘ │</span><br><span class=line>│  │ │ - 压缩比：1×2×2（时/高/宽）│                                        │</span><br><span class=line>│  │ │ - 总压缩比：4×16×16    │                                            │</span><br><span class=line>│  │ └─────────────────────┘                                                │</span><br><span class=line>│  └───────────────────────────────────────────────────────────────────────┘</span><br><span class=line>├─────────────────────────────────────────────────────────────────────────┤</span><br><span class=line>│  位置编码（Positional Encoding）                                         │</span><br><span class=line>│  └───────────────────────────────────────────────────────────────────────┤</span><br><span class=line>│  - 3D RoPE（Rotary Position Embedding）                                  │</span><br><span class=line>│  - 作用于视觉Latent Tokens，捕捉时空维度的位置信息                       │</span><br><span class=line>├─────────────────────────────────────────────────────────────────────────┤</span><br><span class=line>│  核心Transformer块（48层，表1参数）                                      │</span><br><span class=line>│  ┌─────────────────────────────────────────────────────────────────────┐ │</span><br><span class=line>│  │ 单Transformer块结构（循环48次）                                      │ │</span><br><span class=line>│  │ ├─────────────────────────────────────────────────────────────────┤ │ │</span><br><span class=line>│  │ │ 1. 3D自注意力层（3D Self-Attention）                             │ │ │</span><br><span class=line>│  │ │ - 支持Block Sparse Attention（高效推理扩展）                      │ │ │</span><br><span class=line>│  │ │ - 归一化：RMSNorm（QKNorm模式）                                  │ │ │</span><br><span class=line>│  │ ├─────────────────────────────────────────────────────────────────┤ │ │</span><br><span class=line>│  │ │ 2. 跨注意力层（Cross-Attention）                                 │ │ │</span><br><span class=line>│  │ │ - 文本嵌入向量 → 视觉Latent Tokens的条件引导                      │ │ │</span><br><span class=line>│  │ │ - 归一化：RMSNorm（QKNorm模式）                                  │ │ │</span><br><span class=line>│  │ ├─────────────────────────────────────────────────────────────────┤ │ │</span><br><span class=line>│  │ │ 3. 前馈网络（FFN）                                               │ │ │</span><br><span class=line>│  │ │ - 激活函数：SwiGLU                                                │ │ │</span><br><span class=line>│  │ │ - 隐藏层维度：16384（表1参数）                                    │ │ │</span><br><span class=line>│  │ ├─────────────────────────────────────────────────────────────────┤ │ │</span><br><span class=line>│  │ │ 4. 调制模块（Modulation）                                          │ │ │</span><br><span class=line>│  │ │ - 采用AdaLN-Zero（Adaptive Layer Norm-Zero）                       │ │ │</span><br><span class=line>│  │ │ - 每个Transformer块配专属调制MLP，增强任务适应性                   │ │ │</span><br><span class=line>│  │ └─────────────────────────────────────────────────────────────────┘ │ │</span><br><span class=line>│  └─────────────────────────────────────────────────────────────────────┘ │</span><br><span class=line>├─────────────────────────────────────────────────────────────────────────┤</span><br><span class=line>│  输出层（Output Layer）                                                  │</span><br><span class=line>│  ├─────────────────────────────────────────────────────────────────────┤</span><br><span class=line>│  │ 1. 速度场预测（Flow Matching目标）                                    │</span><br><span class=line>│  │ - 预测Latent Tokens的去噪速度vₜ（vₜ = x₀ - ε，x₀为无噪视频，ε为噪声） │</span><br><span class=line>│  │ 2. VAE解码                                                           │</span><br><span class=line>│  │ - Latent Tokens → 像素级视频（720p/30fps等分辨率）                  │</span><br><span class=line>│  └─────────────────────────────────────────────────────────────────────┘</span><br><span class=line>└─────────────────────────────────────────────────────────────────────────┘</span><br></pre></table></figure><p>模型输入由“无噪声条件序列 $X_{cond} \in \mathbb{R}^{B \times N_{cond} \times H \times W \times C}$ 与待去噪噪声序列<br>$X_{noisy} \in \mathbb{R}^{B \times N_{noisy} \times H \times W \times C}$沿时间轴拼接而成，即：<br>$X=[X_{cond}, X_{noisy}]$<br>其中$N_{cond}$、$N_{noisy}$分别为条件帧与噪声帧长度，$B$为批次大小，$H$、$W$为空间维度，$C$为通道数。<br>同时，时间步$t$也对应划分为$t=[t_{cond}, t_{noisy}]$，$t_{cond}$固定为$0$以注入无损信息，$t_{noisy}$采样自$[0,1]$，训练时仅计算噪声序列的损失，确保任务区分与训练效率。<p><img alt=image-20260101185041616 data-src=/images/image-20260101185041616.png><br>$$<br>X_{\text{cond}} = \text{Attention}\left(Q_{\text{cond}}, K_{\text{cond}}, V_{\text{cond}}\right)<br>\<br>X_{\text{noisy}} = \text{Attention}\left(Q_{\text{noisy}}, \left[K_{\text{cond}}, K_{\text{noisy}}\right], \left[V_{\text{cond}}, V_{\text{noisy}}\right]\right)<br>$$<h3 id=2-长视频生成：视频续生预训练与时序一致性保障><a title="2. 长视频生成：视频续生预训练与时序一致性保障" class=headerlink href=#2-长视频生成：视频续生预训练与时序一致性保障></a>2. 长视频生成：视频续生预训练与时序一致性保障</h3><p>为解决长视频生成的误差累积问题，模型未采用“微调现有基础模型”的常规思路，而是<strong>原生基于视频续生任务预训练</strong>：通过学习“基于已有视频片段预测后续帧”的能力，天然具备长时序建模能力，可生成数分钟级视频且无质量退化。<p>同时，模型在注意力机制中引入“块注意力与 KVCache”：条件帧的注意力计算仅依赖自身，噪声帧的注意力则结合条件帧与自身的键值对，具体表示为下面的展示公式：<p>$$<br>X_{\mathrm{cond}}=\mathrm{Attention}\left(Q_{\mathrm{cond}},;K_{\mathrm{cond}},;V_{\mathrm{cond}}\right)<br>$$<p>$$<br>X_{\mathrm{noisy}}=\mathrm{Attention}\left(Q_{\mathrm{noisy}},;[K_{\mathrm{cond}},;K_{\mathrm{noisy}}],;[V_{\mathrm{cond}},;V_{\mathrm{noisy}}]\right)<br>$$<p>这种设计既避免条件帧受噪声干扰，又能通过缓存条件帧的 KV 特征复用计算，保障长视频生成的时序连贯性。<h3 id=3-高效推理：粗精生成与块稀疏注意力><a title="3. 高效推理：粗精生成与块稀疏注意力" class=headerlink href=#3-高效推理：粗精生成与块稀疏注意力></a>3. 高效推理：粗精生成与块稀疏注意力</h3><p>为降低高分辨率视频的推理成本，模型采用两大优化策略：<ul><li><p><strong>粗到精（Coarse-to-Fine）生成</strong>：先生成480p、15fps的低分辨率视频，再通过三线性插值 upscale 至720p、30fps，并由LoRA训练的精修专家模型优化细节。精修阶段基于流匹配（Flow Matching）建模低分辨率与高分辨率视频分布的映射，输入噪声帧定义为：<br>$$<br>x_{t’} = x_{0} + (x_{thresh} - x_{0}) \cdot \frac{t’}{t_{thresh}},\qquad t’\in[0,,t_{thresh}]<br>$$</p> <p>其中<br>$$<br>x_{thresh} = (1 - t_{thresh})\cdot x_{up} + t_{thresh}\cdot \epsilon,\qquad \epsilon \sim \mathcal{N}(0,I)<br>$$</p> <p>说明：x_{up} 为低分辨率视频上采样后的 latent 特征；t_{thresh} 通常设为 0.5，以在噪声注入与细节保留之间取得平衡。精修阶段基于此噪声调度仅需约 5 步采样完成细节恢复与增强。</p></ul><h2 id=三、训练数据与评估><a class=headerlink href=#三、训练数据与评估 title=三、训练数据与评估></a>三、训练数据与评估</h2><h3 id=1-数据筛选与标注><a title="1. 数据筛选与标注" class=headerlink href=#1-数据筛选与标注></a>1. 数据筛选与标注</h3><p>模型构建了“数据预处理-标注”全流程 pipeline：预处理阶段通过多源采集、MD5去重、PySceneDetect+TransNetV2分割视频、FFmpeg裁剪黑边，得到有效片段；标注阶段则标注基础元数据（时长、分辨率）、质量指标（美学评分、模糊度）、运动信息（光流）及文本描述（基于微调的LLaVA-Video生成多风格字幕），形成支持多阶段训练的元数据库。<h3 id=2-评估结果><a title="2. 评估结果" class=headerlink href=#2-评估结果></a>2. 评估结果</h3><ul><li>内部基准：在1628个样本的测试集中，文本转视频任务的“视觉质量”评分接近Wan2.2，“整体质量”超越PixVerse-V5与Wan2.2；图像转视频任务的“视觉质量”（3.27分）排名第一，但“图像对齐”需进一步优化。<li>公共基准：VBench 2.0总得分（62.11%）仅次于Veo3（66.72%）与Vidu Q1（62.70%），“常识性”维度（70.94%）领先所有模型。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/12/13/%E4%B8%80%E4%B8%AAai%E7%BC%96%E7%A8%8B%E6%B5%8B%E8%AF%95%E9%A2%98/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/12/13/%E4%B8%80%E4%B8%AAai%E7%BC%96%E7%A8%8B%E6%B5%8B%E8%AF%95%E9%A2%98/ itemprop=url>一个AI编程测试题</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-12-13 14:19:52" datetime=2025-12-13T14:19:52+00:00>2025-12-13</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E5%8F%91%E7%96%AF%E6%96%87%E5%AD%A6/ itemprop=url rel=index><span itemprop=name>发疯文学</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>我以前（大概2016到2020年吧）挺想当前端的，但苦于当时前端技术太纷繁复杂了，没圈内人指导，也没太多时间自己钻研，也就不了了之了。<p>但遗留下来的一个一直想做的项目。<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>做一个中国地图游戏，给地形图，可以包括山川河流，但不能有行政区划，地图可以放大缩小。然后出地级市，让用户用鼠标点击，点对加分。</span><br></pre></table></figure><p>其实我自己也写过一两次，<a href=https://github.com/zjyfdu/geo_game/tree/master%EF%BC%8C%E5%8A%9F%E8%83%BD%E8%83%BD%E5%AE%9E%E7%8E%B0%EF%BC%8C%E4%BD%86%E6%98%AF%E7%A6%BB%E2%80%9C%E5%A5%BD%E7%8E%A9%E2%80%9D%E8%BF%98%E5%B7%AE%E5%BE%97%E6%AF%94%E8%BE%83%E8%BF%9C%E3%80%82>https://github.com/zjyfdu/geo_game/tree/master，功能能实现，但是离“好玩”还差得比较远。</a><p>现在AI大有取代前端的趋势，我就喜欢拿这个项目导出去找AI去测试，效果都不尽如人意，这里权当记录一下吧。<h2 id=Google-AI-Studio><a title="Google AI Studio" class=headerlink href=#Google-AI-Studio></a>Google AI Studio</h2><p>Gemini 3 Pro确实可以，首先产品视角很好，完善了一些需求。<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br></pre><td class=code><pre><span class=line>为中国地图游戏设计一个成就系统。设计至少三个成就，例如“初窥门径”（成功识别10个城市）、“城市通”（成功识别50个城市）和“地图大师”（在挑战模式中获得1000分）。当玩家达成这些目标时，在游戏中给予他们视觉上的提示和成就图标。</span><br><span class=line>为中国地图游戏中的每个地级市添加详细信息。当用户成功点击一个城市时，弹出一个窗口显示该城市的名称、人口、地理位置和一段关于该城市历史或文化的简短描述。</span><br><span class=line>为中国地图游戏创建一个挑战模式。在该模式下，地图上会随机出现若干个地级市的标记，用户必须在60秒内尽可能多地正确点击它们。每成功点击一个城市，获得10分，超时则挑战结束。请为玩家显示剩余时间和得分。</span><br></pre></table></figure><p>代码看着好像能运行，但地图加载不出来。感觉是最接近解决的模型了。<h2 id=Trae><a class=headerlink href=#Trae title=Trae></a>Trae</h2><p>也是辣鸡，地图是自己编的svg，也不是不能理解，交互也没做出来，点击没反应。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/26/VL%E6%A8%A1%E5%9E%8BAPI%E7%9A%84token%E6%80%8E%E4%B9%88%E7%AE%97/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/26/VL%E6%A8%A1%E5%9E%8BAPI%E7%9A%84token%E6%80%8E%E4%B9%88%E7%AE%97/ itemprop=url>VL模型API的token怎么算</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-26 15:09:20" datetime=2025-10-26T15:09:20+00:00>2025-10-26</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>梳理从 GPT-4.1 到 GPT-5，再到 Qwen3-VL 的核心 API 知识点，帮助你真正驾驭这些强大的工具。<h3 id=1-API-的第一课：Token，以及那个神秘的-reasoning-tokens><a title="1. API 的第一课：Token，以及那个神秘的 reasoning_tokens" class=headerlink href=#1-API-的第一课：Token，以及那个神秘的-reasoning-tokens></a>1. API 的第一课：Token，以及那个神秘的 <code>reasoning_tokens</code></h3><p>你的每一次 API 调用都会返回一个 <code>usage</code> 对象，理解它就是理解你账单的第一步：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    "id": "chatcmpl-xxx",</span><br><span class=line>    "object": "chat.completion",</span><br><span class=line>    "created": xxx,</span><br><span class=line>    "model": "gpt-4.1-2025-04-14",</span><br><span class=line>    "choices": [</span><br><span class=line>        {</span><br><span class=line>            "index": 0,</span><br><span class=line>            "message": {</span><br><span class=line>                "role": "assistant",</span><br><span class=line>                "content": "xxx",</span><br><span class=line>                "refusal": null,</span><br><span class=line>                "annotations": []</span><br><span class=line>            },</span><br><span class=line>            "logprobs": null,</span><br><span class=line>            "finish_reason": "stop"</span><br><span class=line>        }</span><br><span class=line>    ],</span><br><span class=line>    "usage": {</span><br><span class=line>        "prompt_tokens": 11840,</span><br><span class=line>        "completion_tokens": 489,</span><br><span class=line>        "total_tokens": 12329,</span><br><span class=line>        "prompt_tokens_details": {</span><br><span class=line>            "cached_tokens": 0,</span><br><span class=line>            "audio_tokens": 0</span><br><span class=line>        },</span><br><span class=line>        "completion_tokens_details": {</span><br><span class=line>            "reasoning_tokens": 0,</span><br><span class=line>            "audio_tokens": 0,</span><br><span class=line>            "accepted_prediction_tokens": 0,</span><br><span class=line>            "rejected_prediction_tokens": 0</span><br><span class=line>        }</span><br><span class=line>    },</span><br><span class=line>    "service_tier": "default",</span><br><span class=line>    "system_fingerprint": "xxx"</span><br><span class=line>}</span><br></pre></table></figure><ul><li><strong><code>prompt_tokens</code> (输入 Token):</strong> 你<strong>发送给模型</strong>的所有内容的成本。这<strong>不是</strong>指你刚刚输入的那句话，而是你 <code>messages</code> 数组中的<strong>全部内容</strong>，包括：<ol><li>系统提示 (System Prompt)<li>所有的历史对话 (如果你为了保持上下文而传入了)<li>你当前发送的所有文本<li>你当前发送的所有<strong>图片</strong>（这往往是大头！）</ol><li><strong><code>completion_tokens</code> (输出 Token):</strong> 模型<strong>生成并返回给</strong>你的内容的成本。<li><strong><code>total_tokens</code> (总 Token):</strong> <code>prompt</code> + <code>completion</code>，你本次调用的总计费 Token。</ul><p><strong>那么 <code>reasoning_tokens</code> (思考 Token) 是什么？</strong><p>在 <code>gpt-4.1</code> 调用中，这个值是 <code>0</code>。这并不代表模型“没有思考”，而是代表它的架构是一站式生成最终答案的。<p>这个字段是为 <strong>GPT-5</strong> 这样的新模型准备的。GPT-5 引入了“思考深度”机制。当它处理复杂问题时，会先“打草稿”或进行中间推理，这个过程消耗的 Token 就算作 <code>reasoning_tokens</code>。在 GPT-5 的计费中，总输出成本 = <code>completion_tokens</code> + <code>reasoning_tokens</code>。<h3 id=2-API-的核心原则：它是“无状态”的><a title="2. API 的核心原则：它是“无状态”的" class=headerlink href=#2-API-的核心原则：它是“无状态”的></a>2. API 的核心原则：它是“无状态”的</h3><p>这是新手最容易犯的错误：<strong>API 调用本身不具备上下文记忆。</strong><p>你不能像在 ChatGPT 网页版那样，先问“这是什么？”，再问“它是什么颜色的？”。服务器不会“记住”你上一次的调用。<p><strong>“上下文”是你作为开发者“手动”实现的。</strong><p>你必须在你的程序中维护一个 <code>messages</code> 列表（即对话历史），并且在<strong>每一次</strong>新请求中，都把<strong>完整的历史记录</strong>再次发送给 API。<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br></pre><td class=code><pre><span class=line><span class=comment># 你的程序需要自己维护这个列表</span></span><br><span class=line>messages = [</span><br><span class=line>    {<span class=string>"role"</span>: <span class=string>"system"</span>, <span class=string>"content"</span>: <span class=string>"你是一个助手。"</span>}</span><br><span class=line>]</span><br><span class=line></span><br><span class=line><span class=comment># 第一次提问</span></span><br><span class=line>messages.append({<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>"你好，GPT-4.1 的上下文窗口多大？"</span>})</span><br><span class=line>response = client.chat.completions.create(model=<span class=string>"gpt-4.1"</span>, messages=messages)</span><br><span class=line>messages.append(response.choices[<span class=number>0</span>].message) <span class=comment># 把 AI 的回答也存入历史</span></span><br><span class=line></span><br><span class=line><span class=comment># 第二次提问</span></span><br><span class=line>messages.append({<span class=string>"role"</span>: <span class=string>"user"</span>, <span class=string>"content"</span>: <span class=string>"那 GPT-5 呢？"</span>})</span><br><span class=line><span class=comment># 这一次，你发送的是包含前 3 条消息的完整列表</span></span><br><span class=line>response = client.chat.completions.create(model=<span class=string>"gpt-4.1"</span>, messages=messages)</span><br><span class=line><span class=comment># AI 现在才能理解 "那 GPT-5 呢？" 是在和上一句做对比</span></span><br></pre></table></figure><h3 id=3-SDK-vs-手动请求：为什么你应该用-SDK><a title="3. SDK vs. 手动请求：为什么你应该用 SDK" class=headerlink href=#3-SDK-vs-手动请求：为什么你应该用-SDK></a>3. SDK vs. 手动请求：为什么你应该用 SDK</h3><p>使用 <code>openai</code> 官方库（SDK）远优于自己用 <code>requests</code> 库手搓 HTTP 请求：<ul><li><strong>流式处理 (Streaming):</strong> SDK 将复杂的 SSE (Server-Sent Events) 数据流自动转换成一个简单的 Python 生成器，你只需一个 <code>for</code> 循环就能处理。<li><strong>错误处理 (Error Handling):</strong> SDK 会将 API 的错误（如 <code>429</code> 速率限制、<code>401</code> 密钥错误）自动转换成明确的 Python 异常（如 <code>openai.RateLimitError</code>），方便你用 <code>try...except</code> 捕获。<li><strong>类型安全 (Type Safety):</strong> SDK 返回的是 Pydantic 对象 (如 <code>response.choices[0].message.content</code>)，而不是字典 (如 <code>resp_dict['choices'][0]['message']['content']</code>)。这能享受 IDE 自动补全，避免拼写错误。<li><strong>自动重试 (Auto-Retry):</strong> SDK 内置了对瞬时错误的指数退避重试逻辑。</ul><h3 id=4-深度指南：图片如何变成-Token><a title="4. 深度指南：图片如何变成 Token" class=headerlink href=#4-深度指南：图片如何变成-Token></a>4. 深度指南：图片如何变成 Token</h3><p>这可能是多模态 API 中最复杂的部分。图片 Token <strong>不看文件大小 (KB/MB)<strong>，而是看</strong>分辨率 (像素)</strong> 和<strong>你的设置</strong>。<h4 id=A-OpenAI-的可变成本-GPT-4-1-4o-5><a title="A. OpenAI 的可变成本 (GPT-4.1 / 4o / 5)" class=headerlink href=#A-OpenAI-的可变成本-GPT-4-1-4o-5></a>A. OpenAI 的可变成本 (GPT-4.1 / 4o / 5)</h4><p>通过 <code>detail</code> 参数控制成本：<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>"image_url": {</span><br><span class=line>    "url": f"data:image/jpeg;base64,{base64_image}",</span><br><span class=line>    "detail": "low"</span><br><span class=line>}</span><br></pre></table></figure><ul><li><p><strong><code>detail: "low"</code> (低细节模式)</strong></p> <ul><li><strong>成本：</strong> 固定的 85 Token。<li><strong>原理：</strong> 无论图片多大，API 都会将其强制缩放到 512x512 像素再分析。<li><strong>适用：</strong> 识别主要物体、场景（“这是一只猫”）。</ul><li><p><strong><code>detail: "high"</code> (高细节模式)</strong></p> <ul><li><strong>成本：</strong> 可变，<code>85 + (170 * N)</code> 个 Token，<code>N</code> 是“瓦片”数量。<li><strong>原理：</strong><ol><li>API 先将图片缩放，使其最长边不超过 2048px (或放大到 512x512)。<li>然后用 512x512 的“瓦片”去切割这张缩放后的图片。<li>一张 1024x1800 的图片可能会被切成 2x3=6 个瓦片，成本就是 <code>85 + (170 * 6) = 1105</code> Token。</ol><li><strong>适用：</strong> 识别图表文字、精细细节。</ul></ul><h4 id=B-终极技巧：如何处理超长图片（如网页截图）><a title="B. 终极技巧：如何处理超长图片（如网页截图）" class=headerlink href=#B-终极技巧：如何处理超长图片（如网页截图）></a>B. 终极技巧：如何处理超长图片（如网页截图）</h4><p>如果你有一张 <code>1200 x 9000</code> 像素的长图，直接用 <code>detail: "high"</code> 发送会<strong>导致失败</strong>。API 会将其压缩成 <code>246 x 2048</code> 像素，所有细节都会丢失。<p><strong>正确的方法是“客户端手动切片”：</strong><ol><li><strong>在你的程序里</strong>，将 <code>1200 x 9000</code> 的长图切割成 8 张图（7 张 <code>1200x1200</code> + 1 张 <code>1200x600</code>）。<li>在<strong>同一次 API 调用</strong>中，按顺序传入这 8 张图片切片。<li>在<strong>文本提示</strong>中明确告知 AI：<code>"我提供了一张长图，已按顺序切成8片，请你按顺序分析..."</code>。</ol><h4 id=C-URL-vs-Base64：如何传入图片><a title="C. URL vs. Base64：如何传入图片" class=headerlink href=#C-URL-vs-Base64：如何传入图片></a>C. URL vs. Base64：如何传入图片</h4><p>API 两种都支持：<table><thead><tr><th align=left>方式<th align=left>优点<th align=left>缺点<tbody><tr><td align=left><strong>URL 链接</strong><td align=left>简单，API 请求体小<td align=left>图片必须是<strong>公网可访问</strong>的<tr><td align=left><strong>Base64 编码</strong><td align=left><strong>可以处理本地/私有图片</strong><td align=left>请求体变大 (数据膨胀约33%)</table><p><strong>Base64 格式：</strong> <code>url</code> 字段必须是 <code>data:[MIME_TYPE];base64,[你的Base64字符串]</code><h3 id=5-高级策略：如何区分不同角色的图片><a title="5. 高级策略：如何区分不同角色的图片" class=headerlink href=#5-高级策略：如何区分不同角色的图片></a>5. 高级策略：如何区分不同角色的图片</h3><p>假设你有一批“商品介绍图”（用来理解）和一批“备选缩略图”（用来选择）。你不能把它们混在一起丢给 AI。<ul><li><p><strong>方法一 (最可靠)：两次 API 调用</strong></p> <ol><li><strong>调用 1：</strong> 只发送“介绍图”，Prompt 是“请详细总结这个商品”。<li>拿到总结 <code>summary</code>。<li><strong>调用 2：</strong> 发送 <code>summary</code> 文本 + “备选缩略图”，Prompt 是“根据这份总结，请在以下图片中选出最好的缩略图”。</ol><li><p><strong>方法二 (最高效)：单次调用 + 文本图片交错</strong><br>利用 <code>messages</code> 数组可以混合 <code>text</code> 和 <code>image</code> 的特性，为图片“打标签”：</p> <figure class="highlight json"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br></pre><td class=code><pre><span class=line><span class=attr>"content"</span><span class=punctuation>:</span> <span class=punctuation>[</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 第一部分：商品介绍图 (用于理解) ---"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  </span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 第二部分：备选缩略图 (用于选择) ---"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"【备选缩略图 1】:"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"【备选缩略图 2】:"</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"image_url"</span><span class=punctuation>,</span> <span class=attr>"image_url"</span><span class=punctuation>:</span> <span class=punctuation>{</span><span class=attr>"url"</span><span class=punctuation>:</span> <span class=string>"..."</span><span class=punctuation>}</span><span class=punctuation>}</span><span class=punctuation>,</span></span><br><span class=line>  </span><br><span class=line>  <span class=punctuation>{</span><span class=attr>"type"</span><span class=punctuation>:</span> <span class=string>"text"</span><span class=punctuation>,</span> <span class=attr>"text"</span><span class=punctuation>:</span> <span class=string>"--- 最终任务 --- \n 请根据第一部分的信息，从第二部分选择..."</span><span class=punctuation>}</span></span><br><span class=line><span class=punctuation>]</span></span><br></pre></table></figure></ul><h3 id=6-模型对比：GPT-vs-Qwen><a title="6. 模型对比：GPT vs. Qwen" class=headerlink href=#6-模型对比：GPT-vs-Qwen></a>6. 模型对比：GPT vs. Qwen</h3><p>最后，不同的模型家族有截然不同的特性：<table><thead><tr><th align=left>特性<th align=left>GPT-4.1<th align=left>GPT-5<th align=left>Qwen3-VL-30B<tbody><tr><td align=left><strong>最大上下文</strong><td align=left><strong>1,000,000</strong> (1M)<td align=left><strong>400,000</strong> (400K)<td align=left><strong>262,144</strong> (256K)<tr><td align=left><strong>思考机制</strong><td align=left>一站式生成<td align=left><strong>Reasoning 机制</strong> (自动/手动调节)<td align=left>一站式生成<tr><td align=left><strong>模型家族</strong><td align=left>单一模型<td align=left><strong>家族</strong> (Pro, Standard, Mini, Nano)<td align=left><strong>家族</strong> (Instruct, Thinking 等)<tr><td align=left><strong>图片计费</strong><td align=left><strong>可变</strong> (Low: 85, High: 1000+)<td align=left><strong>可变</strong> (类似 4.1，但成本更低)<td align=left><strong>固定</strong> (约 <strong>1,224</strong> Token/每张)<tr><td align=left><strong>图片限制</strong><td align=left>总 Token 限制<td align=left>总 Token 限制<td align=left>总 Token + <strong>50 张图片</strong>数量限制</table><p><strong>核心差异：</strong> OpenAI 的 <code>detail: "high"</code> 允许你通过消耗更多 Token 来获取超高图片细节，而 Qwen3-VL 采取了<strong>固定 1224 Token</strong> 的策略，这让成本非常可预测，但代价是（在 API 层面）无法对单张图片投入更多 Token 去“看清”微小细节。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/25/%E7%94%A8llama-cpp%E5%9C%A8mac%E4%B8%8A%E9%83%A8%E7%BD%B2qwen3vl-30B/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/25/%E7%94%A8llama-cpp%E5%9C%A8mac%E4%B8%8A%E9%83%A8%E7%BD%B2qwen3vl-30B/ itemprop=url>用llama.cpp在mac上部署qwen3vl-30B</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-25 14:44:31" datetime=2025-10-25T14:44:31+00:00>2025-10-25</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=引言：一个报错><a class=headerlink href=#引言：一个报错 title=引言：一个报错></a>引言：一个报错</h2><p>我目标是本地运行强大的 <strong>Qwen3-VL-30B</strong> 模型。我下载了编译了llama.cpp，但现在还不支持Qwen3系列<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>llama_model_load: error loading model: error loading model architecture: <span class=string>'qwen3vlmoe'</span></span><br></pre></table></figure><p>一个 <code>unknown model architecture</code> 报错。这意味着我的 <code>llama.cpp</code> 版本太老，还不认识这个新模型的架构。幸运的是，开源社区的行动总是神速，我很快找到了一个社区提供的解决方案，而这个修复过程，也带我进行了一次关于软件工程和模型架构的深度探索。<h2 id=1-解决方案-——-如何“打补丁”跑通-Qwen3-VL><a title="1: 解决方案 —— 如何“打补丁”跑通 Qwen3-VL" class=headerlink href=#1-解决方案-——-如何“打补丁”跑通-Qwen3-VL></a>1: 解决方案 —— 如何“打补丁”跑通 Qwen3-VL</h2><p>我找到的解决方案在 Hugging Face 的 <code>yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF</code> 仓库中。它的核心不是一个新程序，而是一个名为 <code>qwen3vl-implementation.patch</code> 的文件。<p>这个 <code>.patch</code> 文件就是“补丁”，它包含了让标准 <code>llama.cpp</code> 源代码支持 <code>qwen3vlmoe</code> 架构所需的所有代码更改。<p>以下是我的完整操作步骤：<p><strong>1. 下载并应用补丁</strong><p>先cd到llama.cpp目录下，<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>git <span class=built_in>clone</span> https://github.com/ggerganov/llama.cpp.git</span><br><span class=line><span class=built_in>cd</span> llama.cpp</span><br></pre></table></figure><p>我从社区仓库下载了 <code>.patch</code> 文件，并使用 <code>patch</code> 命令将其应用到刚克隆的源代码上：<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=comment># 下载补丁</span></span><br><span class=line>wget https://huggingface.co/yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF/raw/main/qwen3vl-implementation.patch</span><br><span class=line></span><br><span class=line><span class=comment># 应用补丁</span></span><br><span class=line>patch -p1 < qwen3vl-implementation.patch</span><br></pre></table></figure><p><code>patch -p1</code> 命令会智能地读取“更改说明书”，并自动修改我本地的源代码。<p><strong>3. 重新编译 <code>llama.cpp</code></strong><p>源代码更新后，必须重新编译。因为我用的是 Mac，所以我开启了 Metal GPU 加速：<figure class="highlight bash"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>cmake --build build --config Release -j 8</span><br></pre></table></figure><p><strong>4. 运行！</strong><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>build/bin/llama-server -hf yairpatch/Qwen3-VL-30B-A3B-Thinking-GGUF:Q4_K_S</span><br></pre></table></figure><p>运行后，会模型下载<strong>两个</strong> GGUF 文件：<ul><li><strong>主模型 (17.5 GB):</strong> <code>Qwen3-VL-30B-A3B-Q4_K_S.gguf</code><li><strong>多模态投影文件 (1.08 GB):</strong> <code>mmproj-Qwen3-VL-30B-A3B-F16.gguf</code></ul><p>这个命令同时会启动gui界面和api。<hr><h2 id=2-深入探索-——-Patch-和-mmproj-究竟是什么？><a title="2: 深入探索 —— Patch 和 mmproj 究竟是什么？" class=headerlink href=#2-深入探索-——-Patch-和-mmproj-究竟是什么？></a>2: 深入探索 —— Patch 和 mmproj 究竟是什么？</h2><h3 id=patch：一个-40-岁的“新”技术><a title="patch：一个 40 岁的“新”技术" class=headerlink href=#patch：一个-40-岁的“新”技术></a><code>patch</code>：一个 40 岁的“新”技术</h3><p><code>patch</code>（补丁）的概念几乎和编程一样古老。<ul><li><strong>物理起源 (1940s-1970s):</strong> 在使用“打孔卡片”编程的时代，修复 bug 意味着用胶带**物理地“贴住”（patch）**卡片上打错的孔。<li><strong>软件诞生 (1980s):</strong><ol><li><strong><code>diff</code> (1974年):</strong> Unix 系统诞生了 <code>diff</code> 命令，它可以比较两个文本文件并<strong>输出差异</strong>。<li><strong><code>patch</code> (1985年):</strong> 传奇程序员 <strong>Larry Wall</strong>（Perl 语言之父）发明了 <code>patch</code> 命令。它可以读取 <code>diff</code> 生成的“差异文件”，并<strong>自动将这些差异应用</strong>到旧文件上，将其“升级”成新版本。</ol></ul><p>所以，我刚才用的 <code>patch -p1</code> 命令，是一个在开源世界流传了近 40 年的经典工具，是软件协作和版本管理的基石。<h3 id=mmproj：连接视觉和语言的“翻译官”><a class=headerlink href=#mmproj：连接视觉和语言的“翻译官” title=mmproj：连接视觉和语言的“翻译官”></a><code>mmproj</code>：连接视觉和语言的“翻译官”</h3><p>为什么模型要分成两个文件（一个 17.5 GB 的主模型和一个 1.08 GB 的 <code>mmproj</code>）？为什么不合成一个？<p>答案在于<strong>模块化设计</strong>和<strong>效率</strong>。<p>一个视觉-语言模型（VLM）通常由两个“大脑”拼装而成：<ol><li><strong>视觉编码器 (Vision Encoder)：</strong> 专门“看”图片，把像素转换成一串复杂的数字（图像嵌入）。<li><strong>语言模型 (LLM)：</strong> 专门“思考和说”文本，它只懂语言。</ol><p>这两个“大脑”说的是不同的“语言”。而 <strong><code>mmproj</code> (Multi-Modal Projector，多模态投影器)</strong> 的唯一工作，就是充当它们之间的“翻译官”。<p>它是一个小型的神经网络，负责把“视觉编码器”输出的“图像语言”翻译成“LLM”能听懂的“文本语言”。<p><strong>为什么不合到一起？</strong><ul><li><strong>节省资源，按需加载：</strong> 这是最大的好处。如果我只想用 Qwen3-VL 聊天（纯文本），我<strong>不需要</strong>加载那 1.08 GB 的 <code>mmproj</code> 翻译官，从而节省了宝贵的 VRAM/RAM。只有当我需要处理图像时，我才通过 <code>--mmproj</code> 参数把它“插”上。<li><strong>训练和实验效率：</strong> 开发者可以“冻结”昂贵的 LLM，只单独训练和迭代这个小小的 <code>mmproj</code> 翻译官，极大降低了成本。</ul><hr><h2 id=Part-3-架构揭秘-——-Qwen3-VL-的“特殊”-RoPE><a title="Part 3: 架构揭秘 —— Qwen3-VL 的“特殊” RoPE" class=headerlink href=#Part-3-架构揭秘-——-Qwen3-VL-的“特殊”-RoPE></a>Part 3: 架构揭秘 —— Qwen3-VL 的“特殊” RoPE</h2><p>解决了运行问题，我开始好奇它的架构 <code>qwen3vlmoe</code> 到底特殊在哪。我了解到，它的核心优势之一在于使用了一种特殊的**旋转位置编码 (RoPE)**。<h3 id=为什么-RoPE-需要升级？><a title="为什么 RoPE 需要升级？" class=headerlink href=#为什么-RoPE-需要升级？></a>为什么 RoPE 需要升级？</h3><p>标准的 RoPE 是为<strong>一维 (1D)</strong> 文本设计的，它只关心“单词A在单词B前面多远”。<p>但是 <strong>Qwen3-VL 是一个视频-语言模型</strong>，它必须处理<strong>三维 (3D)</strong> 的数据块：<ol><li>$h$ (高度)<li>$w$ (宽度)<li>$t$ (时间，即视频的第几帧)</ol><p>早期的多模态模型 (如 Qwen2-VL) 使用 <strong>MRoPE</strong> (Multimodal RoPE)，它简单地把特征维度“分块”，比如：<ul><li>高频特征 $\leftarrow$ [所有时间 $t$ 的信息]<li>中频特征 $\leftarrow$ [所有高度 $h$ 的信息]<li>低频特征 $\leftarrow$ [所有宽度 $w$ 的信息]</ul><p>这种设计的<strong>致命缺陷</strong>是，所有“时间”信息都被困在了高频区，导致模型很难理解长距离的时间依赖（比如视频开头和结尾的联系），严重限制了长视频的理解。<h3 id=Qwen3-VL-的答案：Interleaved-MRoPE-交错式><a title="Qwen3-VL 的答案：Interleaved-MRoPE (交错式)" class=headerlink href=#Qwen3-VL-的答案：Interleaved-MRoPE-交错式></a>Qwen3-VL 的答案：Interleaved-MRoPE (交错式)</h3><p>Qwen3-VL 采用了更先进的 **Interleaved-MRoPE (I-MRoPE)**。<p>它不再“分块”，而是像发牌一样，把 $t, h, w$ 三个维度的信息**“交错”<strong>地、均匀地</strong>“轮询”<strong>（Round-Robin）分配到</strong>所有**的频率通道中（高、中、低频）。<p>这意味着，无论是 $t, h, $ 还是 $w$，都能访问到<strong>完整的频率频谱</strong>。<p>这种“全频率覆盖”的设计，使得 Qwen3-VL 在处理长视频和复杂空间关系时，能力远超前代。<p><strong>我输入的是静态图片，哪来的时间 $t$？</strong><p>答案是：<strong>Qwen3-VL 的架构是为更复杂的“视频”任务而设计的。</strong><ul><li><strong>当我输入视频时：</strong> 它在 3D 模式 ($t, h, w$) 下全速运行。<li><strong>当我输入图片时：</strong> 它只是在 2D 模式 ($h, w$) 下运行，这可以被看作是 $t=1$ 的一种特例。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/19/sping%E9%80%9F%E9%80%9A/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/19/sping%E9%80%9F%E9%80%9A/ itemprop=url>sping速通</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-19 22:32:24" datetime=2025-10-19T22:32:24+00:00>2025-10-19</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/java/ itemprop=url rel=index><span itemprop=name>java</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=一、-Java-基础：从-Go-Python-到-JVM><a title="一、 Java 基础：从 Go/Python 到 JVM" class=headerlink href=#一、-Java-基础：从-Go-Python-到-JVM></a>一、 Java 基础：从 Go/Python 到 JVM</h2><h3 id=1-语言范式的根本区别><a title="1. 语言范式的根本区别" class=headerlink href=#1-语言范式的根本区别></a>1. 语言范式的根本区别</h3><table><thead><tr><th align=left>特性<th align=left>C++/Python/Go 的习惯<th align=left>Java 的要求<th align=left>关键点<tbody><tr><td align=left><strong>代码结构</strong><td align=left>允许全局函数、模块级函数。<td align=left>所有的可执行代码（方法/逻辑）<strong>必须</strong>封装在一个 <code>class</code> (类) 或 <code>interface</code> (接口) 中。<td align=left>Java 是“纯血”的面向对象语言。你不能写一个脱离类的函数。<tr><td align=left><strong>数据类型</strong><td align=left>Python (动态)，Go (静态但有类型推断)。<td align=left><strong>强类型、静态类型</strong>。所有变量必须显式声明类型，一旦声明不能更改。<td align=left>避免 Go 语言中省略类型声明的习惯。<tr><td align=left><strong>内存管理</strong><td align=left>Go/Python 自动垃圾回收。<td align=left>**自动垃圾回收 (GC)**。无指针运算，内存错误率低。<td align=left>与 Go/Python 相似，无需手动管理内存。<tr><td align=left><strong>执行机制</strong><td align=left>编译成机器码 (Go/C++) 或解释执行 (Python)。<td align=left>编译成 **字节码 (<code>.class</code>)**，然后在 <strong>JVM (Java 虚拟机)</strong> 上运行。<td align=left>实现“一次编写，到处运行”。</table><h3 id=2-JDK-与版本生态><a title="2. JDK 与版本生态" class=headerlink href=#2-JDK-与版本生态></a>2. JDK 与版本生态</h3><ul><li>**Java 版本 (Specification) $\approx$ JDK 版本 (Implementation)**：Java SE 定义了语言特性和 API 规范。JDK (Java Development Kit) 是实现这些规范的工具包。<li><strong>多供应商实现 (OpenJDK):</strong> Java 规范由 <strong>JCP (Java Community Process)</strong> 维护。市面上的主流 JDK，如 <strong>Amazon Corretto</strong>、<strong>Eclipse Temurin</strong>、<strong>Oracle JDK</strong> 等，均基于开源的 <strong>OpenJDK</strong> 并通过兼容性测试 (TCK)。</ul><h2 id=二、构建工具对比：Gradle-的现代优势><a title="二、构建工具对比：Gradle 的现代优势" class=headerlink href=#二、构建工具对比：Gradle-的现代优势></a>二、构建工具对比：Gradle 的现代优势</h2><p>在 Java 世界中，构建工具负责依赖管理、编译、测试和打包。<table><thead><tr><th align=left>特性<th align=left>Maven (传统)<th align=left>Gradle (现代)<th align=left>优势点<tbody><tr><td align=left><strong>配置文件</strong><td align=left><code>pom.xml</code> (XML)<td align=left><code>build.gradle</code> (Groovy/Kotlin DSL)<td align=left><strong>可读性高，支持编程逻辑。</strong><tr><td align=left><strong>配置风格</strong><td align=left>纯声明式<td align=left><strong>编程式与声明式结合</strong><td align=left>极高的灵活性，可定义复杂的自定义任务。<tr><td align=left><strong>构建速度</strong><td align=left>每次执行全量构建<td align=left><strong>增量构建、构建缓存 (Cache)</strong><td align=left>对于大型和多模块项目，速度明显更快。</table><p><strong>结论：</strong> 对于 Spring Boot 新项目，<strong>Gradle</strong> 以其灵活性和性能优势，是更推荐的选择。<h2 id=三、-Spring-Boot-核心：依赖注入-DI-的魔法><a title="三、 Spring Boot 核心：依赖注入 (DI) 的魔法" class=headerlink href=#三、-Spring-Boot-核心：依赖注入-DI-的魔法></a>三、 Spring Boot 核心：依赖注入 (DI) 的魔法</h2><p>Spring Boot 的设计哲学是 <strong>“约定优于配置”</strong>，其核心是 **依赖注入 (DI)**。<h3 id=1-依赖注入-DI-与-IoC-容器><a title="1. 依赖注入 (DI) 与 IoC 容器" class=headerlink href=#1-依赖注入-DI-与-IoC-容器></a>1. 依赖注入 (DI) 与 IoC 容器</h3><table><thead><tr><th align=left>机制<th align=left>描述<th align=left>与传统开发的区别<tbody><tr><td align=left><strong>控制反转 (IoC)</strong><td align=left>将对象的创建、管理和生命周期的<strong>控制权</strong>交给 Spring 容器。<td align=left>你不再使用 <code>new MyService()</code> 手动创建对象。<tr><td align=left><strong>依赖注入 (DI)</strong><td align=left>应用程序所需的依赖（对象）由 Spring 容器自动<strong>注入</strong>到目标对象中。<td align=left>你只需声明你需要什么 (接口)，Spring 负责找到并提供具体的实现。</table><h3 id=2-核心注解速查><a title="2. 核心注解速查" class=headerlink href=#2-核心注解速查></a>2. 核心注解速查</h3><table><thead><tr><th align=left>注解<th align=left>作用范围<th align=left>功能描述<tbody><tr><td align=left><strong><code>@SpringBootApplication</code></strong><td align=left>主启动类<td align=left>整合配置、自动配置和组件扫描。<tr><td align=left><strong><code>@Autowired</code></strong><td align=left>构造函数/字段<td align=left>标记 Spring 容器应在此处自动注入依赖对象。<tr><td align=left><strong><code>@RestController</code></strong><td align=left>类<td align=left>标记为 Web 控制器，方法的返回值自动序列化为 JSON。<tr><td align=left><strong><code>@Service</code></strong><td align=left>类<td align=left>标记为业务逻辑组件 (Service Layer)。<tr><td align=left><strong><code>@Repository</code></strong><td align=left>类<td align=left>标记为数据访问组件 (DAO Layer)。</table><h2 id=四、-Spring-Boot-实战：分层与持久化-JPA><a title="四、 Spring Boot 实战：分层与持久化 (JPA)" class=headerlink href=#四、-Spring-Boot-实战：分层与持久化-JPA></a>四、 Spring Boot 实战：分层与持久化 (JPA)</h2><p>现代 Spring Boot 应用遵循经典的分层架构，DI 机制将它们解耦。<table><thead><tr><th align=left>层级<th align=left>技术/注解<th align=left>职责<th align=left>核心原理<tbody><tr><td align=left><strong>Controller (控制层)</strong><td align=left><code>@RestController</code>, <code>@RequestBody</code>, <code>@GetMapping</code><td align=left>接收 HTTP 请求，处理路由，调用 Service，序列化/反序列化 JSON。<td align=left>利用 <strong>Jackson</strong> 库自动完成 Java 对象与 JSON 格式的转换。<tr><td align=left><strong>Service (业务层)</strong><td align=left><code>@Service</code><td align=left>封装核心业务逻辑和事务管理。<td align=left>依赖注入 <code>Repository</code> 接口。<tr><td align=left><strong>Repository (数据层)</strong><td align=left><code>@Repository</code>, <code>JpaRepository</code><td align=left>与数据库交互。<td align=left>继承 <strong><code>JpaRepository&LTEntity, ID></code></strong> 后，Spring Data JPA 会在运行时自动生成基础的 CRUD (增删改查) 实现。<tr><td align=left><strong>Entity (数据模型)</strong><td align=left><code>@Entity</code>, <code>@Id</code>, <code>@GeneratedValue</code><td align=left>定义与数据库表对应的 Java 类。<td align=left>通过 <strong>JPA/Hibernate</strong> 实现 ORM (对象关系映射)。</table><h2 id=五、-配置管理与并发模型><a title="五、 配置管理与并发模型" class=headerlink href=#五、-配置管理与并发模型></a>五、 配置管理与并发模型</h2><h3 id=1-现代化配置：YAML-与-Profiles><a title="1. 现代化配置：YAML 与 Profiles" class=headerlink href=#1-现代化配置：YAML-与-Profiles></a>1. 现代化配置：YAML 与 Profiles</h3><ul><li><strong>YAML (Yet Another Markup Language):</strong> 使用 <strong><code>.yml</code></strong> 文件替代 <code>.properties</code>，利用缩进实现清晰的层次结构，例如：<figure class="highlight yaml"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br></pre><td class=code><pre><span class=line><span class=attr>spring:</span></span><br><span class=line>  <span class=attr>datasource:</span></span><br><span class=line>    <span class=attr>url:</span> <span class=comment># ...</span></span><br></pre></table></figure><li><strong>Profiles (环境配置):</strong> 通过创建 <code>application-{profile}.yml</code> 文件来隔离不同环境（dev/test/prod）的配置。<li><strong>激活方式:</strong> 启动时使用命令行参数激活特定环境：<code>--spring.profiles.active=prod</code></ul><h3 id=2-并发模型：Spring-MVC-vs-WebFlux><a title="2. 并发模型：Spring MVC vs. WebFlux" class=headerlink href=#2-并发模型：Spring-MVC-vs-WebFlux></a>2. 并发模型：Spring MVC vs. WebFlux</h3><table><thead><tr><th align=left>模型<th align=left>Spring MVC (默认)<th align=left>Spring WebFlux (响应式)<th align=left>建议<tbody><tr><td align=left><strong>底层架构</strong><td align=left>Servlet API, <strong>Thread-per-Request</strong> (每个请求一个 Java 线程等待)<td align=left><strong>非阻塞 I/O</strong>，基于 <strong>Reactor</strong> 库 (类似 Event Loop)。<td align=left>针对 <strong>I/O 密集型/高并发</strong> 场景，性能更优。<tr><td align=left><strong>适用性</strong><td align=left>易于理解，CPU 密集型或传统应用。<td align=left><strong>高吞吐量微服务</strong>，类似 Go 的 Goroutine 优势。<td align=left>随着 <strong>Java 虚拟线程 (Virtual Threads)</strong> 的引入，Java 的并发能力正在发生革命性变化。</table><h2 id=六、开发环境-IDE-推荐><a title="六、开发环境 (IDE) 推荐" class=headerlink href=#六、开发环境-IDE-推荐></a>六、开发环境 (IDE) 推荐</h2><p>对于 Java 和 Spring Boot 开发，推荐：<ul><li><strong>IntelliJ IDEA Community Edition (社区版):</strong> 免费且功能强大，提供对 Spring Boot 和 Gradle 最完善、最智能的集成支持，能极大地提高你的开发效率。</ul></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/10/07/claude-code/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/10/07/claude-code/ itemprop=url>claude code</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-10-07 20:07:06" datetime=2025-10-07T20:07:06+00:00>2025-10-07</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/claude/ itemprop=url rel=index><span itemprop=name>claude</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h1 id=claude-code命令行><a class=headerlink href=#claude-code命令行 title=claude-code命令行></a>claude-code命令行</h1><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>npm install -g @anthropic-ai/claude-code --registry=https://registry.npmmirror.com</span><br></pre></table></figure><p>通过环境变量修改成kimi的模型<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line>export ANTHROPIC_BASE_URL=https://api.moonshot.cn/anthropic</span><br><span class=line>export ANTHROPIC_AUTH_TOKEN=${YOUR_MOONSHOT_API_KEY}</span><br><span class=line>export ANTHROPIC_MODEL=kimi-k2-turbo-preview</span><br><span class=line>export ANTHROPIC_SMALL_FAST_MODEL=kimi-k2-turbo-preview</span><br></pre></table></figure><p>或者在claude配置文件中添加环境变量<br><code>~/.claude/settings.json</code><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    "env": {</span><br><span class=line>        "ANTHROPIC_BASE_URL": "https://www.sophnet.com/api/open-apis/7TxazXiOf8xHVzgbxY2o6w/anthropic",</span><br><span class=line>        "ANTHROPIC_AUTH_TOKEN": "${YOUR_API_KEY}",</span><br><span class=line>        "ANTHROPIC_MODEL": "Kimi-K2-0905",</span><br><span class=line>        "ANTHROPIC_SMALL_FAST_MODEL": "Kimi-K2-0905"</span><br><span class=line>    }</span><br><span class=line>}</span><br></pre></table></figure><p>添加mcp，<code>mcp-chrome-bridge</code>确实好用，就是费token<figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br></pre><td class=code><pre><span class=line>claude mcp add --transport http mcp-chrome-bridge http://127.0.0.1:12306/mcp</span><br></pre></table></figure><h1 id=claude-code的vscode插件><a class=headerlink href=#claude-code的vscode插件 title=claude-code的vscode插件></a>claude-code的vscode插件</h1><p>应用市场安装先安装一个<br>在设置中搜索<code>Claude Code: Environment Variables</code>，编辑<code>setting.json</code><figure class="highlight plaintext"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br></pre><td class=code><pre><span class=line>{</span><br><span class=line>    ...</span><br><span class=line>    "claude-code.environmentVariables": [</span><br><span class=line>        { "name": "ANTHROPIC_BASE_URL", "value": "https://www.sophnet.com/api/open-apis/7TxazXiOf8xHVzgbxY2o6w/anthropic" },</span><br><span class=line>        { "name": "ANTHROPIC_AUTH_TOKEN", "value": "${YOUR_API_KEY}" },</span><br><span class=line>        { "name": "ANTHROPIC_MODEL", "value": "Kimi-K2-0905" },</span><br><span class=line>        { "name": "ANTHROPIC_SMALL_FAST_MODEL", "value": "Kimi-K2-0905" }</span><br><span class=line>    ]</span><br><span class=line>}</span><br></pre></table></figure><p>vscode的ai插件真多啊，有官方copilot，有早期的cline，claude code也有了</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/09/27/AIGC%E5%BD%92%E7%BA%B3/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/09/27/AIGC%E5%BD%92%E7%BA%B3/ itemprop=url>AIGC归纳</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-09-27 18:42:24" datetime=2025-09-27T18:42:24+00:00>2025-09-27</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/AIGC/ itemprop=url rel=index><span itemprop=name>AIGC</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><blockquote><p>失业的第一天，把现有的关于AIGC的乱七八糟的东西归纳一下</blockquote><h1 id=AI大善人们><a class=headerlink href=#AI大善人们 title=AI大善人们></a>AI大善人们</h1><h2 id=GPU><a class=headerlink href=#GPU title=GPU></a>GPU</h2><h3 id=腾讯cloud-studio><a title="腾讯cloud studio" class=headerlink href=#腾讯cloud-studio></a>腾讯cloud studio</h3><p><a href=https://cloudstudio.net/my-app>https://cloudstudio.net/my-app</a><p>我主要用的是这个平台，每天签到有2核时，大概A10可以用40分钟。有256g的存储，放一些图片和模型文件也够用。有一些现成的comfyUI的应用，还比较好用。<p>但感觉像没啥人维护了，文档不太好，怎么自己创建应用，在哪里写配置文件没找到。<p><img data-src=/images/image1.png><h3 id=腾讯cnb><a class=headerlink href=#腾讯cnb title=腾讯cnb></a>腾讯cnb</h3><p><a href=https://cnb.cool/?type=activities>https://cnb.cool/?type=activities</a><p>应该和上面用法差不多，只是我没怎么用。<h3 id=谷歌colab><a class=headerlink href=#谷歌colab title=谷歌colab></a>谷歌colab</h3><p><a href=https://colab.research.google.com/>https://colab.research.google.com</a><p>免费用户可以用T4大概4小时，我这两天基本都有，好处是不用搞签到啥的，坏处是每次环境都是新的，重新安装依赖，下一遍模型。我试了index-tts是在这上面部署的。<h2 id=API><a class=headerlink href=#API title=API></a>API</h2><h3 id=硅基流动><a class=headerlink href=#硅基流动 title=硅基流动></a>硅基流动</h3><p><a href=https://cloud.siliconflow.cn/me/models>https://cloud.siliconflow.cn/me/models</a><p>硅基流动还是挺好的，送我的14块钱一直用不完，模型也比较全，唯独api base<br>url不好找，<a href=https://api.siliconflow.cn/v1>https://api.siliconflow.cn/v1</a><h3 id=SophNet><a class=headerlink href=#SophNet title=SophNet></a>SophNet</h3><p><a href=https://sophnet.com//#/model/overview>https://sophnet.com/\#/model/overview</a><p>和硅基流动差不多，开源的模型挺全的，而且api很快，我claude<br>code用的就是SophNet部署的kimi v2<h2 id=应用><a class=headerlink href=#应用 title=应用></a>应用</h2><h3 id=LibLibAI><a class=headerlink href=#LibLibAI title=LibLibAI></a>LibLibAI</h3><p><a href=https://www.liblib.art/inspiration>https://www.liblib.art/inspiration</a><p>主要是来这里学生图提示词的，lora模型比较丰富，还可以训练，但没试过。<h1 id=index-tts><a class=headerlink href=#index-tts title=index-tts></a>index-tts</h1><p>看了b站的index-tts，类似的能实现声音克隆的还有阿里的CosyVoice，社区的GPT-SoVITS。<p>index-tts最大特点在于他把音色和情绪解耦了，你可以单独控制声音的情绪。<p>github.com/index-tts/index-tts.git，可以直接在colab上部署。<p>做声音有个现成的方式是用minimax.io 可以克隆音色<h1 id=comfyUI><a class=headerlink href=#comfyUI title=comfyUI></a>comfyUI</h1><p>最近比较流行的生图工具了，支持的模型很多，最早我是想去试用qwen-image的。网页部署唯一比较麻烦的是下载模型，这里附上一些huggingface的命令。<figure class="highlight shell"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br></pre><td class=code><pre><span class=line>huggingface-cli list Kijai/flux-fp8\</span><br><span class=line>huggingface-cli download Kijai/flux-fp8 \--include flux1-dev-fp8.safetensor \--local-dir ./workspace/Comfyui/models/unet</span><br></pre></table></figure><p><img data-src=/images/image2.png><p>comfyUI也不用自己搭，有很多平台能用，阿里、LibLib、runninghub都有<p>对做视频比较好用的几个模型<ul><li><p><a href=https://wan.video/blog/wan2.2-animate>wan2.2-animate</a>，能做吴京视频。</p> <blockquote><p>Wan-Animate supports two modes: (1) Animation mode, which generates high-fidelity character animation videos by precisely replicating the facial expressions and body movements from the reference video; (2) Replacement mode, which seamlessly integrates the character into the reference video, replacing the original character while reproducing the scene’s lighting and color style to achieve natural environmental blending.</blockquote><li><p><a href=https://zhuanlan.zhihu.com/p/1949456021010510998>humo</a>，可以做数字人。</p></ul><h1 id=SillyTavern><a class=headerlink href=#SillyTavern title=SillyTavern></a>SillyTavern</h1><p><a href=https://github.com/SillyTavern/SillyTavern>https://github.com/SillyTavern/SillyTavern</a><p>这个就比较偏娱乐了，文字冒险游戏了，最基础的是对话，然后可以加入生图和tts，都是走api的，所以本地只有cpu的机器也可以跑。<p>角色卡可以自己捏，也可以到网上下，比如<a href=https://discord.com/channels/1124998756715216976/1165191657449332757>类脑</a>上的，大部分是NSFW。<p>要生图的话是走插件，需要安装这个插件<a href=https://github.com/wickedcode01/st-image-auto-generation%EF%BC%8C%E5%AE%89%E8%A3%85%E5%90%8E%E5%B0%B1%E4%BC%9A%E5%87%BA%E7%8E%B0%22Image>https://github.com/wickedcode01/st-image-auto-generation，安装后就会出现"Image</a><br>Auto<br>Generation”插件，这个插件会要求在每次生成内容后，再生成一段生图的prompt。<p>左侧我选的是ComfyUI，ComfyUI用的是前面腾讯cloud<br>studio部署的，也可以api调用。ComfyUI的dag图是这个json文件，我不太会改，只是把模型从sd1.5换到了3.5。<p>tts我没有配置。<p><img data-src=/images/image3.png><h1 id=CS336><a class=headerlink href=#CS336 title=CS336></a>CS336</h1><p>还是不能忘记学习，<a href=https://stanford-cs336.github.io/spring2025/%EF%BC%8C>https://stanford-cs336.github.io/spring2025/，</a><p><a href=https://www.bilibili.com/video/BV1YKhhzBE1M/?vd%5C_source=d4d45a41db226393d3b605dd30e2ffa8>https://www.bilibili.com/video/BV1YKhhzBE1M/?vd\_source=d4d45a41db226393d3b605dd30e2ffa8</a><h1 id=gemini的gem><a class=headerlink href=#gemini的gem title=gemini的gem></a>gemini的gem</h1><p><a href=https://gemini.google.com/gem/9c3b6882ff67?ref=jeffsu.org>Veo Visionary | Text-to-Video Generator</a><p><img alt=image-20251019112152102 data-src=/images/image-20251019112152102.png><p><img alt=image-20251019112549872 data-src=/images/image-20251019112549872.png></div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/09/20/diffusion/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/09/20/diffusion/ itemprop=url>diffusion模型基础</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-09-20 10:28:06" datetime=2025-09-20T10:28:06+00:00>2025-09-20</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/diffusion/ itemprop=url rel=index><span itemprop=name>diffusion</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><h2 id=auto-encoder><a title="auto encoder" class=headerlink href=#auto-encoder></a>auto encoder</h2><p>训练目标是：希望输入的图片经过两次转换和原来的图片越接近越好，也被称为“重构-reconstruction”(不需要有标签的数据)<br>常见的应用：原来的向量维度很高，经过encoder之后输出维度小的向量，再用这个低维度的向量去做后面的任务。<p>auto encoder严格来说不算生成模型，只是在重构，到VAE才算具备的生成能力。<p><img alt=img data-src=/images/v2-4fb6ce4972f4f716553b7d256a13c712_1440w.jpg><h2 id=VAE（变分自编码器）><a class=headerlink href=#VAE（变分自编码器） title=VAE（变分自编码器）></a>VAE（变分自编码器）</h2><p>VAE 是一种概率生成模型，通过编码器将输入数据映射到潜空间，再通过解码器从潜空间重构数据。<p>在VAE中，我们假设$p(Z|X)$后验分布是正态分布，给定一个真实的样本$X_k$，都有专属的分布$p(Z|X_k)$。训练生成器时，采样一个$Z_k$来还原$X_k$。<p>VAE 的损失函数由两部分组成：<ul><li>reconstruction loss（重构损失）：衡量重构输入 $\hat{X}$ 与原始输入 $X$ 的相似度，常用均方误差（MSE）：</ul><p>$$<br>\text{reconstruction loss} = | X - \hat{X} |^2<br>$$<p>其中 $\hat{X}$ 是解码器生成的重构结果。<ul><li>similarity loss（相似性损失）：即 KL 散度，衡量潜在分布 $\mathcal{N}(\mu, \sigma)$ 与标准正态分布 $\mathcal{N}(0, I)$ 的差异，可以当做是一个正则项。</ul><p>$$<br>\text{similarity loss} = D_{KL}(\mathcal{N}(\mu, \sigma) | \mathcal{N}(0, I)) \<br>=\frac{1}{2}(-log\sigma ^2+\mu ^2+\sigma ^ 2 - 1)<br>$$<p>VAE的训练过程本质上是重建损失和KL散度损失之间的权衡：重建损失希望编码器学习到区分度大、能精确重建的潜在表示，这可能倾向于让$\mu$分散、$\sigma$变小。KL散度损失则希望所有分布收缩到0和1，防止VAE退化成普通AE，失去生成新样本的能力。<p>$$<br>\text{loss} = \text{reconstruction loss} + \text{similarity loss}<br>$$<p><img alt=VAE结构与损失函数 data-src=/images/v2-36c7da0b2fe37bd021699532a2cff1e8_1440w.jpg><p><img alt=img data-src=/images/v2-784891edddff506ea1670c81767e993c_1440w.jpg><p>VAE存在一个固有问题，是用L2距离来衡量$\hat{X}$ 与 $X$ 的相似度，L2距离只是近似等于分布距离，会导致图片变得模糊（倾向于生成低频信号，这样L2 loss小）。<h2 id=GAN（生成对抗网络）><a class=headerlink href=#GAN（生成对抗网络） title=GAN（生成对抗网络）></a>GAN（生成对抗网络）</h2><p>GAN的思路是reconstruction loss不好衡量，我就用个模型来代替，多加了一个discriminator来判断图片是生成的还是真实的。训练过程是generator和discriminator交替进行。<p>我以前也写过<a href=/2019/01/27/GAN%E6%80%BB%E7%BB%93/ title=GAN总结>GAN</a>，当时GAN还很火。<p>$$<br>\min_G \max_D V(D,G) = E_{x \sim p_{\text{data}}(x)}[\log D(x)] + E_{z \sim p_{z}(z)}[\log(1 - D(G(z)))]<br>$$<p>这是<strong>生成对抗网络（GAN）</strong>的<strong>价值函数（Value Function）</strong>或<strong>目标函数（Objective Function）</strong>。<ul><li><strong>$G$</strong> 代表<strong>生成器（Generator）</strong>，其目标是<strong>最小化</strong>这个函数（$\min_G$）。<li><strong>$D$</strong> 代表<strong>判别器（Discriminator）</strong>，其目标是<strong>最大化</strong>这个函数（$\max_D$）。<li><strong>$V(D, G)$</strong> 是判别器 $D$ 和生成器 $G$ 之间的<strong>二人极小极大博弈</strong>的值。</ul><p><strong>公式组成部分：</strong><ol><li><p><strong>$E_{x \sim p_{\text{data}}(x)}[\log D(x)]$</strong>:</p> <ul><li>这是判别器<strong>正确判断真实数据</strong> $x$ 为真的期望。<li>$p_{\text{data}}(x)$ 是真实数据分布。<li>$D(x)$ 是判别器将真实数据 $x$ 判为真的概率。<li>判别器 $D$ 想要最大化这一项，使其接近 $1$（$\log(1)=0$）。</ul><li><p><strong>$E_{z \sim p_{z}(z)}[\log(1 - D(G(z)))]$</strong>:</p> <ul><li>这是判别器<strong>正确判断生成数据</strong> $G(z)$ 为假的期望。<li>$p_{z}(z)$ 是噪声输入 $z$ 的先验分布。<li>$G(z)$ 是生成器 $G$ 生成的假样本。<li>$D(G(z))$ 是判别器将假样本 $G(z)$ 判为真的概率。<li>判别器 $D$ 想要最大化这一项，即使 $D(G(z))$ 接近 $0$（$\log(1-0)=\log(1)=0$）。<li>生成器 $G$ 想要<strong>最小化</strong>这一项，即使 $D(G(z))$ 接近 $1$，从而骗过判别器。</ul></ol><h2 id=Diffusion（扩散模型）><a class=headerlink href=#Diffusion（扩散模型） title=Diffusion（扩散模型）></a>Diffusion（扩散模型）</h2><p>Diffusion 模型是一类基于概率扩散过程的生成模型。其核心思想是将数据逐步加噪声，最终变成纯噪声，然后训练一个模型学会如何一步步去噪，最终还原出原始数据。Diffusion 模型近年来在图像生成等任务上取得了极大成功，代表模型有 DDPM、Stable Diffusion 等。<p>Diffusion 模型包括两个过程：<strong>正向扩散过程（加噪声）</strong>和<strong>反向去噪过程（生成）</strong>。<h3 id=1-正向扩散（Forward-Process）><a title="1. 正向扩散（Forward Process）" class=headerlink href=#1-正向扩散（Forward-Process）></a>1. 正向扩散（Forward Process）</h3><p>正向过程将原始数据 $x_0$ 逐步加入高斯噪声，经过 $T$ 步后变成接近各向同性高斯分布的噪声 $x_T$。每一步的加噪过程如下：<p>$$<br>q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)<br>$$<p>其中 $\beta_t$ 是每一步的噪声强度。<h3 id=2-反向去噪（Reverse-Process）><a title="2. 反向去噪（Reverse Process）" class=headerlink href=#2-反向去噪（Reverse-Process）></a>2. 反向去噪（Reverse Process）</h3><p>反向过程的目标是从纯噪声 $x_T$ 开始，逐步去噪，最终还原出数据 $x_0$。反向过程同样是高斯过程，但均值和方差需要模型学习：<p>$$<br>p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))<br>$$<p>训练时，通常用一个神经网络（如 U-Net）预测噪声或数据的均值。<h3 id=Diffusion-模型的训练><a title="Diffusion 模型的训练" class=headerlink href=#Diffusion-模型的训练></a>Diffusion 模型的训练</h3><p>Diffusion 模型的训练目标是让模型学会在每一步准确地去噪。常见的训练方式是让模型预测每一步加到数据上的噪声 $\epsilon$，损失函数为：<p>$$<br>L_{simple} = E_{x_0, \epsilon, t} \left[ | \epsilon - \epsilon_\theta(x_t, t) |^2 \right]<br>$$<p>其中 $x_t$ 是在 $t$ 时刻加噪后的数据，$\epsilon$ 是实际加的噪声，$\epsilon_\theta$ 是模型预测的噪声。<p>训练流程如下：<ol><li>从数据集中采样一张图片 $x_0$。<li>随机采样一个时间步 $t$。<li>按照正向扩散公式加噪，得到 $x_t$。<li>用神经网络输入 $x_t$ 和 $t$，预测噪声 $\epsilon_\theta$。<li>计算损失并反向传播，更新模型参数。</ol><h3 id=Diffusion-模型的推理（采样）><a title="Diffusion 模型的推理（采样）" class=headerlink href=#Diffusion-模型的推理（采样）></a>Diffusion 模型的推理（采样）</h3><p>推理阶段，从高斯噪声 $x_T$ 开始，利用训练好的模型逐步去噪，最终生成一张图片。每一步的采样过程如下：<ol><li>初始化 $x_T \sim \mathcal{N}(0, I)$。<li>对 $t = T, T-1, …, 1$：<ul><li>用模型预测当前噪声 $\epsilon_\theta(x_t, t)$。<li>计算 $x_{t-1}$ 的均值和方差。<li>从高斯分布采样 $x_{t-1}$。</ul><li>最终得到 $x_0$，即生成的图片。</ol><p>推理过程可以理解为“逆过程”，逐步将噪声还原为清晰的样本。采样步数越多，生成质量越高，但速度越慢。近年来也有很多加速采样的改进方法。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article><link href=https://zjyfdu.coding.me/2025/06/02/BLEU%E5%92%8CGLUE/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/images/11989810.jpg itemprop=image> <meta content=翟大翟 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=努力～奋斗～ itemprop=name> <meta itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="undefined | 努力～奋斗～" itemprop=name> <meta itemprop=description> </span><header class=post-header><h2 itemprop="name headline" class=post-title><a class=post-title-link href=/2025/06/02/BLEU%E5%92%8CGLUE/ itemprop=url>BLEU和GLUE</a></h2><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2025-06-02 23:03:26" datetime=2025-06-02T23:03:26+00:00>2025-06-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar-check"></i> </span> <span class=post-meta-item-text>更新于</span> <time title="修改时间：2026-01-02 13:37:25" datetime=2026-01-02T13:37:25+00:00 itemprop=dateModified>2026-01-02</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-folder"></i> </span> <span class=post-meta-item-text>分类于</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E5%8F%91%E7%96%AF%E6%96%87%E5%AD%A6/ itemprop=url rel=index><span itemprop=name>发疯文学</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>攒了好多年的问题了，该了结一下了。<h1 id=BLEU-机器翻译指标><a title="BLEU 机器翻译指标" class=headerlink href=#BLEU-机器翻译指标></a>BLEU 机器翻译指标</h1><p>transormer那篇论文里提到了BLEU指标，但一直不知道这个指标是啥。<p>BLEU（Bilingual Evaluation Understudy），通过比较机器翻译的结果与<strong>参考译文</strong>之间的相似度来衡量翻译质量。<p>$$<br>BLEU=BP*exp(\sum_{n=1}^N\frac{1}{N}logP_n)<br>$$<ul><li><p>N取4，即最多4-gram</p><li><p>BP（Brevity Penalty）是长度惩罚因子，$l_c$代表表示机器翻译译文的长度，$l_s$表示参考答案的有效长度，避免机器翻译太短，hack了$P_n$指标，本质上还是$P_n$只考虑了准确率，没考虑召回率。<br>$$<br>BP = \begin{cases}<br>1 & l_c \ge l_s \<br>exp(1-\frac{l_c}{l_s}) & l_c < l_s<br>\end{cases}<br>$$</p><li><p>$P_n$，n-gram，比较译文和参考译文之间n组词的相似的占比。</p></ul><p>比较详细的可以参考<a href=https://www.cnblogs.com/by-dream/p/7679284.html>这里</a>。<h1 id=GLUE><a class=headerlink href=#GLUE title=GLUE></a>GLUE</h1><p>GLUE（General Language Understanding Evaluation）是一个综合性的GLU（自然语言理解）评估基准，通过9个英语任务测试模型的通用能力，取平均值。<ul><li><p>单句分类任务‌</p> <ul><li>CoLA‌：纽约大学发布的有关语法的数据集，该任务主要是对一个给定句子，判定其是否语法正确，因此CoLA属于单个句子的文本二分类任务<li>SST（情感分析）：是斯坦福大学发布的一个情感分析数据集，主要针对电影评论来做情感分类，因此SST属于单个句子的文本分类任务（SST-2是二分类，SST-5是五分类，SST-5的情感极性区分的更细致）</ul><li><p>相似性任务‌</p> <ul><li>MRPC/QQP‌（句子对语义等价判断）：判断两个给定句子，是否具有相同的语义，属于句子对的文本二分类任务<li>STS-B‌（句子相似度评分）：用1到5的分数来表征两个句子的语义相似性，本质上是一个回归问题，但依然可以用分类的方法做，因此可以归类为句子对的文本五分类任务</ul><li><p>推理任务‌</p> <ul><li>MNLI/QNLI/RTE/WNLI‌（文本蕴含与推理）</ul></ul><p>也是比较老的指标了，BERT、T5那个时代的。</div><footer class=post-footer><div class=post-eof></div></footer></article></div><nav class=pagination><span class="page-number current">1</span><a class=page-number href=/page/2/>2</a><span class=space>…</span><a class=page-number href=/page/8/>8</a><a class="extend next" aria-label=下一页 href=/page/2/ rel=next title=下一页><i class="fa fa-angle-right"></i></a></nav></div></main><footer class=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2026</span><span class=with-love> <i class="fa fa-heart"></i> </span><span class=author itemprop=copyrightHolder>翟大翟</span></div><div class=powered-by>由 <a href=https://hexo.io/ rel=noopener target=_blank>Hexo</a> & <a href=https://theme-next.js.org/ rel=noopener target=_blank>NexT.Gemini</a> 强力驱动</div></div></footer><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script crossorigin integrity=sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY= src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script crossorigin integrity=sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8= src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js></script><script crossorigin integrity=sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc= src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script src=/js/comments.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/next-boot.js></script><script crossorigin integrity=sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc= src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script src=/js/third-party/search/local-search.js></script><script class=next-config data-name=enableMath type=application/json>true</script><script class=next-config data-name=mathjax type=application/json>{"enable":true,"tags":"none","single_dollars":true,"normal_width":0.6,"cjk_width":0.9,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src=/js/third-party/math/mathjax.js></script>